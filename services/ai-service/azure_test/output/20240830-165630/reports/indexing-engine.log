16:56:30,755 graphrag.index.cli INFO Logging enabled at azure_test\output\20240830-165630\reports\indexing-engine.log
16:56:30,761 graphrag.index.cli INFO Starting pipeline run for: 20240830-165630, dryrun=False
16:56:30,764 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "azure_openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://startino-eastus.openai.azure.com",
        "api_version": "2023-03-15-preview",
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": "gpt-4o",
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "azure_test",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "none",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
16:56:30,838 asyncio DEBUG Using proactor: IocpProactor
16:56:30,860 graphrag.index.create_pipeline_config INFO skipping workflows 
16:56:30,860 graphrag.index.run INFO Running pipeline
16:56:30,860 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at azure_test\output\20240830-165630\artifacts
16:56:30,861 graphrag.index.input.load_input INFO loading input from root_dir=input
16:56:30,861 graphrag.index.input.load_input INFO using file storage for input
16:56:30,863 graphrag.index.storage.file_pipeline_storage INFO search azure_test\input for files matching .*\.txt$
16:56:30,864 graphrag.index.input.text INFO found text files from input, found [('Biwas _ Jorge - Pair Programming Transcript.txt', {}), ('comms management & adapt demo Transcript.txt', {}), ('Congent Vision & Mission Workshop Transcript.txt', {}), ('Discussing Graph Designs Transcript.txt', {}), ('Hasnain _ Jorge - Pair Programming Transcript.txt', {}), ('Will _ Jorge - Pair Programming Transcript.txt', {})]
16:56:30,934 graphrag.index.input.text INFO Found 6 files, loading 6
16:56:30,937 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
16:56:30,938 graphrag.index.run INFO Final # of rows loaded: 6
16:56:31,68 graphrag.index.run INFO Running workflow: create_base_text_units...
16:56:31,69 graphrag.index.run INFO dependencies for create_base_text_units: []
16:56:31,74 datashaper.workflow.workflow INFO executing verb orderby
16:56:31,82 datashaper.workflow.workflow INFO executing verb zip
16:56:31,86 datashaper.workflow.workflow INFO executing verb aggregate_override
16:56:31,96 datashaper.workflow.workflow INFO executing verb chunk
16:56:31,423 datashaper.workflow.workflow INFO executing verb select
16:56:31,429 datashaper.workflow.workflow INFO executing verb unroll
16:56:31,439 datashaper.workflow.workflow INFO executing verb rename
16:56:31,446 datashaper.workflow.workflow INFO executing verb genid
16:56:31,459 datashaper.workflow.workflow INFO executing verb unzip
16:56:31,469 datashaper.workflow.workflow INFO executing verb copy
16:56:31,481 datashaper.workflow.workflow INFO executing verb filter
16:56:31,506 graphrag.index.run DEBUG first row of create_base_text_units => {"id":"46062a85a4568aafcd4ec93d8ffddfbf","chunk":"Will \/ Jorge - Pair Programming \nWed, Aug 7, 2024\n\n0:04 - Jorge Lewis \nSo yeah, so let's do the, what do I wanna work on today? The signup stuff?\n\n0:09 - Will Vincent Parrone \nYeah, so wait, let me just finish this up. I'm just gonna be removing this.\n\n0:25 - Will Vincent Parrone \nYeah, so just a rundown on my code. So basically, this is a really simple prototype right now that I'm working on. In the sign-in, what was discussed is that we're going to be using passwordless kind of authentication.\n\n0:48 - Will Vincent Parrone \nassume that we're going to be using OTP. So the way I did it is I created basically the status.\n\n0:58 - Jorge Lewis \nBut have you discussed? So for each feature, we've kind of concluded that we should be discussing with the client for each small feature to make sure all these small things are clarified. Right.\n\n1:11 - Will Vincent Parrone \nAll right. We discussed this with Q1, I think.\n\n1:18 - Will Vincent Parrone \ndays ago before we even finished the scope. Basically, what Q1 wants here is that it's going to be passwordless and not done along with the chatbot, like a separate UI for the sign-in.\n\n1:38 - Jorge Lewis \nI don't want to interrupt the pair programming session, but just so that we make sure we don't work on something that we won't use. There's two sections to the user authentication with Adapt. The first one is the anonymous authentication where there's no required credentials or input from the user. And the second is a sign up page where after they've completed the workshop, they can sign up. Right? So far so good?\n\n2:14 - Will Vincent Parrone \nYep.\n\n2:18 - Jorge Lewis \nAnd then you're telling me that you guys said you're going to use single SSO for the signup page. Yeah.\n\n2:27 - Will Vincent Parrone \nYeah?\n\n2:31 - Unidentified Speaker \nYeah.\n\n2:37 - Jorge Lewis \nOkay.\n\n2:37 - Jorge Lewis \nBut what about, so has he said we, so are we not going to use Google authentication or Facebook authentication or?\n\n2:47 - Will Vincent Parrone \nActually, we haven't discussed this.\n\n2:49 - Jorge Lewis \nBecause Superbase gives those to us, and it's surprisingly easy to integrate. I think we should be- Okay, okay. Yeah, wait, I'll- No, no, I gotcha, I gotcha.\n\n3:01 - Jorge Lewis \nOkay, okay.\n\n3:02 - Jorge Lewis \nSo let's, let's, um...\n\n3:09 - Jorge Lewis \nLet's...\n\n3:11 - Jorge Lewis \nSee...\n\n3:13 - Jorge Lewis \nLet's ask him, then.\n\n3:18 - Jorge Lewis \nSo, ask him in AdaptDev at Kuen and say, hey, I'm working on the sign-up thing or the user authentication now. What do you want to include? So, the options are this, this, and this. Make sure to include kind of how the user experience is for each. So, for a Google sign-on, or Google sign up, what that means is that they can sign in, they click, maybe you can send some examples, kind of, you click the Google sign up, sign up with Google, it takes, it opens the pop up of Google and they click their Google account and it's in. Explain that to him, because I don't know, he probably knows, but I think it's good to illustrate with examples. Because like for example, JP probably won't know, so we want to kind of pretend Kuin doesn't know any technical things, but he does.\n\n4:18 - Will Vincent Parrone \nI'm messaging him right now.\n\n4:28 - Jorge Lewis \nHave you done any OAuth authentication with Superbase?\n\n4:34 - Will Vincent Parrone \nTo be honest, no.\n\n4:41 - Will Vincent Parrone \nI think the authentication that I did was on Firebase.\n\n4:48 - Jorge Lewis \nNo, it's fine, bro. Don't worry. I don't need know-it-alls. I need fast learn.\n\n4:56 - Jorge Lewis \nOK. And on Firebase, was that single sign-on or was that using Google or?\n\n5:07 - Will Vincent Parrone \nI did an option wherein I tried Google Authentication, and then what I'm slightly more familiar with is using the email and password to sign in.\n\n5:27 - Will Vincent Parrone \nHello? Sorry?\n\n5:27 - Jorge Lewis \nYeah, me too.\n\n5:31 - Jorge Lewis \nOk.\n\n5:32 - Jorge Lewis \nYeah, I've only done email and password and then I think anonymous as well. There's actually a project we, I've only done email and anonymous as well. We have a project, we have a project, IT, you know, actually, are you aware, like, do you know ITNO?\n\n6:00 - Will Vincent Parrone \nArtino, I saw it. Yeah, yeah, yeah, yeah. When I searched Artino, Artino came up.\n\n6:09 - Will Vincent Parrone \nRight there?\n\n6:10 - Will Vincent Parrone \nHello, hello. My mic is not picking up, but I saw Artino one time, I think, in the messages while searching for something.\n\n6:23 - Jorge Lewis \nYeah, so I, yeah, yeah.\n\n6:30 - Jorge Lewis \nAetino is our AI project we worked on before. It was kind of","chunk_id":"46062a85a4568aafcd4ec93d8ffddfbf","document_ids":["0939bd111ba4d0c5bc146d16ed11da6f"],"n_tokens":1200}
16:56:31,506 graphrag.index.emit.csv_table_emitter INFO emitting CSV table create_base_text_units.csv
16:56:31,739 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
16:56:31,745 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
16:56:31,746 graphrag.index.run ERROR error running workflow create_base_extracted_entities
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\run.py", line 322, in run_pipeline
    await inject_workflow_data_dependencies(workflow)
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\run.py", line 258, in inject_workflow_data_dependencies
    table = await load_table_from_storage(f"{id}.parquet")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\run.py", line 244, in load_table_from_storage
    raise ValueError(msg)
ValueError: Could not find create_base_text_units.parquet in storage!
16:56:31,747 graphrag.index.reporting.file_workflow_callbacks INFO Error running pipeline! details=None
16:56:31,789 graphrag.index.cli ERROR Errors occurred during the pipeline run, see logs for more details.
