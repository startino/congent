02:07:05,660 graphrag.index.cli INFO Logging enabled at pair_programming_kg\output\20240830-020705\reports\indexing-engine.log
02:07:05,670 graphrag.index.cli INFO Starting pipeline run for: 20240830-020705, dryrun=False
02:07:05,670 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "azure_openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://startino-eastus.openai.azure.com",
        "api_version": "2023-03-15-preview",
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": "gpt-4o",
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "pair_programming_kg",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://startino-eastus.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o",
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
02:07:05,675 graphrag.index.create_pipeline_config INFO skipping workflows 
02:07:05,676 graphrag.index.run INFO Running pipeline
02:07:05,676 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at pair_programming_kg\output\20240830-020705\artifacts
02:07:05,677 graphrag.index.input.load_input INFO loading input from root_dir=input
02:07:05,677 graphrag.index.input.load_input INFO using file storage for input
02:07:05,679 graphrag.index.storage.file_pipeline_storage INFO search pair_programming_kg\input for files matching .*\.txt$
02:07:05,680 graphrag.index.input.text INFO found text files from input, found [('Biwas _ Jorge - Pair Programming Transcript.txt', {}), ('comms management & adapt demo Transcript.txt', {}), ('Congent Vision & Mission Workshop Transcript.txt', {}), ('Discussing Graph Designs Transcript.txt', {}), ('Hasnain _ Jorge - Pair Programming Transcript.txt', {}), ('Will _ Jorge - Pair Programming Transcript.txt', {})]
02:07:05,692 graphrag.index.input.text INFO Found 6 files, loading 6
02:07:05,696 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
02:07:05,697 graphrag.index.run INFO Final # of rows loaded: 6
02:07:05,938 graphrag.index.run INFO Running workflow: create_base_text_units...
02:07:05,938 graphrag.index.run INFO dependencies for create_base_text_units: []
02:07:05,944 datashaper.workflow.workflow INFO executing verb orderby
02:07:05,949 datashaper.workflow.workflow INFO executing verb zip
02:07:05,953 datashaper.workflow.workflow INFO executing verb aggregate_override
02:07:05,959 datashaper.workflow.workflow INFO executing verb chunk
02:07:06,415 datashaper.workflow.workflow INFO executing verb select
02:07:06,437 datashaper.workflow.workflow INFO executing verb unroll
02:07:06,456 datashaper.workflow.workflow INFO executing verb rename
02:07:06,479 datashaper.workflow.workflow INFO executing verb genid
02:07:06,502 datashaper.workflow.workflow INFO executing verb unzip
02:07:06,517 datashaper.workflow.workflow INFO executing verb copy
02:07:06,559 datashaper.workflow.workflow INFO executing verb filter
02:07:06,588 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
02:07:06,872 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
02:07:06,873 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
02:07:06,873 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
02:07:06,911 datashaper.workflow.workflow INFO executing verb entity_extract
02:07:06,926 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://startino-eastus.openai.azure.com, deployment_name=gpt-4o
02:07:07,364 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o: TPM=0, RPM=0
02:07:07,364 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o: 25
02:07:09,106 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,114 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: , I use a NeoVim environment in my VS Code.\n\n39:00 - Jorge Lewis \nOh, really?\n\n39:04 - Jorge Lewis \nIt\'s a mentality that my friend told me while I was in Thailand. He\'s like one of the best engineers along with Jonas and Nazif that I\'ve met. It\'s a matter of, oh, don\'t use, well, why would you have to use one or two? Why do you have to use Linux or Windows? Why not use both? Why not use VS Code and Vim? Use both worlds.\n\n39:23 - Will Vincent Parrone \nOh, yeah, yeah, yeah. It\'s actually a good compromise.\n\n39:29 - Jorge Lewis \nBecause in today\'s world, where the influencers are saying a lot of true things, but people follow them blindly, it\'s a good kind of reminder. Oh, but trust me, I felt so cool using NeoVim in the airport. In the airplane, I was like, yeah, the people behind me can see me just using Vim. I bet they use Windows. I bet they use VS Code.\n\n40:00 - Will Vincent Parrone \nWhat\'s this? Exit your status entry.\n\n40:08 - Will Vincent Parrone \nWait, let me see the web and px super basic. Yeah, anyways, the problem that I\'m trying to fix is basically when determining whether the types here in the superbase.ts are accurate.\n\n40:32 - Jorge Lewis \nI would update them regardless.\n\n40:38 - Jorge Lewis \nThey should be, but just, yeah, never hurts. Actually, I can do it for you just to double check in case you\'re having too many problems.\n\n41:03 - Will Vincent Parrone \nI\'ll Shift-C, Alt-Tab, V, superbase.com, continue with GitHub.\n\n41:16 - Will Vincent Parrone \nWell done, now close this window. And then...\n\n41:26 - Will Vincent Parrone \nWe copy, exit, and then...\n\n41:33 - Will Vincent Parrone \nSo we go bash, update superbase tags.\n\n41:38 - Will Vincent Parrone \nHmm. Plus x.\n\n42:00 - Will Vincent Parrone \nThere we go. Packages.\n\n42:09 - Jorge Lewis \nLike one thing also that I\'ve noticed, I\'m not here to attack Linux users, I like Linux, I do. But one thing that I\'ve noticed is that for people using Vim and Linux, you\'re often fixing your operating system and your tools rather than developing. I think that\'s one of the biggest arguments.\n\n42:30 - Will Vincent Parrone \nIt\'s basically a personal attack, but it\'s accurate to...\n\n42:37 - Will Vincent Parrone \nLike, fuck you, but like, yeah, that is us.\n\n42:44 - Jorge Lewis \nOkay, the types are updated, so don\'t worry.\n\n42:48 - Will Vincent Parrone \nOkay, let me try to pull.\n\n42:50 - Jorge Lewis \nOh, actually, wait, let me push. I have changes here, though.\n\n43:00 - Jorge Lewis \nThere\'s quite a- Bewis is still learning. He\'s using a lot of tri-catches, so... Prepare your eyes. If you don\'t, yeah.\n\n43:10 - Will Vincent Parrone \nOh, don\'t worry, I also use tri-catch. If it works, it works.\n\n43:15 - Will Vincent Parrone \nThat has been my mentality. Wait, let me just...\n\n43:23 - Jorge Lewis \nI hate this saying because it\'s just so cliche, but everything\'s a balance.\n\n43:55 - Will Vincent Parrone \nWhat\'s happening with my... Ah, anyways.\n\n44:03 - Jorge Lewis \nLook at how inefficient you are, you don\'t have a shortcut to nvim, just vi. Come on.\n\n44:09 - Will Vincent Parrone \nNow my vim is lagging like crazy.\n\n44:14 - Jorge Lewis \nIt was a funny topic discussion we had, Jonas, with this Swedish developer that I told you about just now. Jonas didn\'t set up a shortcut to his neovim command, whereas the Swedish guy puts vi instead of envim. It was just funny because it\'s like two characters doesn\'t make you more efficient, but it\'s just so funny. I don\'t know. It\'s like the inside the head of a developer. We\'re going to spend 10 hours making that shortcut to save no time, but we\'re satisfied.\n\n44:47 - Will Vincent Parrone \nYes, that is us.\n\n44:54 - Will Vincent Parrone \nYeah, okay. I\'m just going to pull if there are any changes. Wow. Okay. This is from Alpha 2.\n\n45:08 - Will Vincent Parrone \nLet me see what has changed.\n\n45:14 - Will Vincent Parrone \nI\'m getting a bit dyslexic. Let\'s see. To do. What\'s the name of\n\n45:22 - Jorge Lewis \nI think it\'s done, done.\n\n45:24 - Will Vincent Parrone \nDone. Oh, okay, okay.\n\n45:33 - Jorge Lewis \nOh, wait. Actually, sorry, I think the table that you\'re, like the table that\'s showing on the front end there, that\'s actually the leaps table, not the evaluated submissions table. And I haven\'t added that done to, The leads table. So I\'m going to do that right now. So you\'re going to have to actually...\n\n45:54 - Will Vincent Parrone \nThat explains it. That explains the issues I\'m having. Okay.\n\n45:59 - Unidentified Speaker \nOh no.\n\n46:01 - Will Vincent Parrone \nIn my other laptop, I was trying\n######################\nOutput:'}
02:07:09,114 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,122 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ", I use a NeoVim environment in my VS Code.\n\n39:00 - Jorge Lewis \nOh, really?\n\n39:04 - Jorge Lewis \nIt's a mentality that my friend told me while I was in Thailand. He's like one of the best engineers along with Jonas and Nazif that I've met. It's a matter of, oh, don't use, well, why would you have to use one or two? Why do you have to use Linux or Windows? Why not use both? Why not use VS Code and Vim? Use both worlds.\n\n39:23 - Will Vincent Parrone \nOh, yeah, yeah, yeah. It's actually a good compromise.\n\n39:29 - Jorge Lewis \nBecause in today's world, where the influencers are saying a lot of true things, but people follow them blindly, it's a good kind of reminder. Oh, but trust me, I felt so cool using NeoVim in the airport. In the airplane, I was like, yeah, the people behind me can see me just using Vim. I bet they use Windows. I bet they use VS Code.\n\n40:00 - Will Vincent Parrone \nWhat's this? Exit your status entry.\n\n40:08 - Will Vincent Parrone \nWait, let me see the web and px super basic. Yeah, anyways, the problem that I'm trying to fix is basically when determining whether the types here in the superbase.ts are accurate.\n\n40:32 - Jorge Lewis \nI would update them regardless.\n\n40:38 - Jorge Lewis \nThey should be, but just, yeah, never hurts. Actually, I can do it for you just to double check in case you're having too many problems.\n\n41:03 - Will Vincent Parrone \nI'll Shift-C, Alt-Tab, V, superbase.com, continue with GitHub.\n\n41:16 - Will Vincent Parrone \nWell done, now close this window. And then...\n\n41:26 - Will Vincent Parrone \nWe copy, exit, and then...\n\n41:33 - Will Vincent Parrone \nSo we go bash, update superbase tags.\n\n41:38 - Will Vincent Parrone \nHmm. Plus x.\n\n42:00 - Will Vincent Parrone \nThere we go. Packages.\n\n42:09 - Jorge Lewis \nLike one thing also that I've noticed, I'm not here to attack Linux users, I like Linux, I do. But one thing that I've noticed is that for people using Vim and Linux, you're often fixing your operating system and your tools rather than developing. I think that's one of the biggest arguments.\n\n42:30 - Will Vincent Parrone \nIt's basically a personal attack, but it's accurate to...\n\n42:37 - Will Vincent Parrone \nLike, fuck you, but like, yeah, that is us.\n\n42:44 - Jorge Lewis \nOkay, the types are updated, so don't worry.\n\n42:48 - Will Vincent Parrone \nOkay, let me try to pull.\n\n42:50 - Jorge Lewis \nOh, actually, wait, let me push. I have changes here, though.\n\n43:00 - Jorge Lewis \nThere's quite a- Bewis is still learning. He's using a lot of tri-catches, so... Prepare your eyes. If you don't, yeah.\n\n43:10 - Will Vincent Parrone \nOh, don't worry, I also use tri-catch. If it works, it works.\n\n43:15 - Will Vincent Parrone \nThat has been my mentality. Wait, let me just...\n\n43:23 - Jorge Lewis \nI hate this saying because it's just so cliche, but everything's a balance.\n\n43:55 - Will Vincent Parrone \nWhat's happening with my... Ah, anyways.\n\n44:03 - Jorge Lewis \nLook at how inefficient you are, you don't have a shortcut to nvim, just vi. Come on.\n\n44:09 - Will Vincent Parrone \nNow my vim is lagging like crazy.\n\n44:14 - Jorge Lewis \nIt was a funny topic discussion we had, Jonas, with this Swedish developer that I told you about just now. Jonas didn't set up a shortcut to his neovim command, whereas the Swedish guy puts vi instead of envim. It was just funny because it's like two characters doesn't make you more efficient, but it's just so funny. I don't know. It's like the inside the head of a developer. We're going to spend 10 hours making that shortcut to save no time, but we're satisfied.\n\n44:47 - Will Vincent Parrone \nYes, that is us.\n\n44:54 - Will Vincent Parrone \nYeah, okay. I'm just going to pull if there are any changes. Wow. Okay. This is from Alpha 2.\n\n45:08 - Will Vincent Parrone \nLet me see what has changed.\n\n45:14 - Will Vincent Parrone \nI'm getting a bit dyslexic. Let's see. To do. What's the name of\n\n45:22 - Jorge Lewis \nI think it's done, done.\n\n45:24 - Will Vincent Parrone \nDone. Oh, okay, okay.\n\n45:33 - Jorge Lewis \nOh, wait. Actually, sorry, I think the table that you're, like the table that's showing on the front end there, that's actually the leaps table, not the evaluated submissions table. And I haven't added that done to, The leads table. So I'm going to do that right now. So you're going to have to actually...\n\n45:54 - Will Vincent Parrone \nThat explains it. That explains the issues I'm having. Okay.\n\n45:59 - Unidentified Speaker \nOh no.\n\n46:01 - Will Vincent Parrone \nIn my other laptop, I was trying"}
02:07:09,238 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,240 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: I searched Artino, Artino came up.\n\n6:09 - Will Vincent Parrone \nRight there?\n\n6:10 - Will Vincent Parrone \nHello, hello. My mic is not picking up, but I saw Artino one time, I think, in the messages while searching for something.\n\n6:23 - Jorge Lewis \nYeah, so I, yeah, yeah.\n\n6:30 - Jorge Lewis \nAetino is our AI project we worked on before. It was kind of a multi-agent builder kind of thing and it was actually a great idea. We were on the right track, definitely.\n\n6:42 - Will Vincent Parrone \nI would like to stop you first. I think I\'m hearing Jonas in Gather.\n\n6:48 - Jorge Lewis \nIt was just, yeah. Unfortunately, we couldn\'t finish it. But actually, fortunately, yeah.\n\n6:56 - Jorge Lewis \nOkay. Oh, he\'s here, yeah.\n\n7:03 - Jorge Lewis \nI\'m a me and Google me. You you Alright, alright. I\'m back. He\'s gone.\n\n10:26 - Will Vincent Parrone \nYeah, alright. Okay, okay. Wait. I\'ll be... I\'ll just finish messaging Kuan\'s sign-in with one-time email. Password userwillsprofile and set the Half of our programming one-on-one is just basically consulting with other people.\n\n15:25 - Jorge Lewis \nHopefully people stop joining us now.\n\n15:34 - Will Vincent Parrone \nYou were saying something?\n\n15:35 - Jorge Lewis \nNo, no. Go on.\n\n15:41 - Will Vincent Parrone \nAnyways, so maybe we can put this on hold. I still have one issue that I\'m working on, though, related to the anonymous sign-ins that I might need some help with.\n\n15:57 - Will Vincent Parrone \nMaybe that\'s something I can do other than the sign-up page while clarifying some things with Q1.\n\n16:03 - Jorge Lewis \nYeah, I mean, what would be good is if you send a video, a little short video, Google, for example. You don\'t have to make one, but just searching online.\n\n16:29 - Jorge Lewis \nSo we can see the user flow.\n\n16:35 - Will Vincent Parrone \nYeah, anyways, sorry. There was some noise out there.\n\n16:55 - Will Vincent Parrone \nGoogle search a video on how the user flow works, right? I think it\'s going to be a bit easier. Yeah.\n\n17:04 - Will Vincent Parrone \nYeah, I\'ll just search on YouTube right now.\n\n17:10 - Jorge Lewis \nYeah, I\'m trying to find one as well.\n\n17:37 - Jorge Lewis \nI think I found a good example. Could you also edit your message to mention that we can include multiple of the options.\n\n17:56 - Will Vincent Parrone \nYeah, thank you. Including this right now, yes, we can have multiple options.\n\n18:14 - Will Vincent Parrone \nOh, there we go.\n\n18:20 - Will Vincent Parrone \nWhere did you find this? Just Google Images?\n\n18:24 - Jorge Lewis \nYeah, I just searched Google OAuth example. Oh, nice.\n\n18:30 - Will Vincent Parrone \nYeah, I think with the exception of Google Auth and Meta Auth, everything\'s self-explanatory already.\n\n18:40 - Jorge Lewis \nYeah. Okay, so, but what I actually think is we\'re going to put yourself in his shoes. We ask him, hey, do you want this or this or this or do you want all of them? He\'s going to say, why would I, why would I not? Yeah, exactly. Why would he not say all of them for him? It costs the same. Um, since for us, like realistically the time to implement more than one should maybe take one or two more hours. Um, which should be a positive, um, ROI for us since the client gets to be really happy and, um, and we can reuse that code. So, sorry, sorry. Not reuse his code. Um, create it from scratch.\n\n19:24 - Will Vincent Parrone \nOur meetings aren\'t going to be read by him anyways, it\'s okay. We can...\n\n19:30 - Jorge Lewis \nCode like this isn\'t his IP actually, or the client\'s IP, because it\'s so generic that it\'s used in every single SaaS project, so it\'s not exactly his IP. So we can reuse the code.\n\n19:47 - Will Vincent Parrone \nYeah, I think only the workshops might be a little bit... On the gray area of what\'s good and what\'s not.\n\n19:56 - Jorge Lewis \nYeah, for sure.\n\n19:58 - Will Vincent Parrone \nYeah. Okay.\n\n20:01 - Will Vincent Parrone \nWhile we\'re waiting, go on.\n\n20:04 - Jorge Lewis \nWe can get into making all the authentication options, I think.\n\n20:09 - Will Vincent Parrone \nOkay. Wait.\n\n20:13 - Jorge Lewis \nIf you can share your whole screen and we can, because you\'re using the documentation on a browser here.\n\n20:22 - Unidentified Speaker \nMm-hmm.\n\n20:23 - Jorge Lewis \nYeah, so you can share your whole screen. I can follow along with the docs that you\'re looking at.\n\n20:29 - Jorge Lewis \nOK.\n\n20:32 - Will Vincent Parrone \nWait, let me just clean up my tabs.\n\n20:39 - Will Vincent Parrone \nThere we go, all nice and clean. Mm-hmm.\n\n20:51 - Will Vincent Parrone \nStop presenting.\n\n20:58 - Will Vincent Parrone\n######################\nOutput:'}
02:07:09,240 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,246 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "I searched Artino, Artino came up.\n\n6:09 - Will Vincent Parrone \nRight there?\n\n6:10 - Will Vincent Parrone \nHello, hello. My mic is not picking up, but I saw Artino one time, I think, in the messages while searching for something.\n\n6:23 - Jorge Lewis \nYeah, so I, yeah, yeah.\n\n6:30 - Jorge Lewis \nAetino is our AI project we worked on before. It was kind of a multi-agent builder kind of thing and it was actually a great idea. We were on the right track, definitely.\n\n6:42 - Will Vincent Parrone \nI would like to stop you first. I think I'm hearing Jonas in Gather.\n\n6:48 - Jorge Lewis \nIt was just, yeah. Unfortunately, we couldn't finish it. But actually, fortunately, yeah.\n\n6:56 - Jorge Lewis \nOkay. Oh, he's here, yeah.\n\n7:03 - Jorge Lewis \nI'm a me and Google me. You you Alright, alright. I'm back. He's gone.\n\n10:26 - Will Vincent Parrone \nYeah, alright. Okay, okay. Wait. I'll be... I'll just finish messaging Kuan's sign-in with one-time email. Password userwillsprofile and set the Half of our programming one-on-one is just basically consulting with other people.\n\n15:25 - Jorge Lewis \nHopefully people stop joining us now.\n\n15:34 - Will Vincent Parrone \nYou were saying something?\n\n15:35 - Jorge Lewis \nNo, no. Go on.\n\n15:41 - Will Vincent Parrone \nAnyways, so maybe we can put this on hold. I still have one issue that I'm working on, though, related to the anonymous sign-ins that I might need some help with.\n\n15:57 - Will Vincent Parrone \nMaybe that's something I can do other than the sign-up page while clarifying some things with Q1.\n\n16:03 - Jorge Lewis \nYeah, I mean, what would be good is if you send a video, a little short video, Google, for example. You don't have to make one, but just searching online.\n\n16:29 - Jorge Lewis \nSo we can see the user flow.\n\n16:35 - Will Vincent Parrone \nYeah, anyways, sorry. There was some noise out there.\n\n16:55 - Will Vincent Parrone \nGoogle search a video on how the user flow works, right? I think it's going to be a bit easier. Yeah.\n\n17:04 - Will Vincent Parrone \nYeah, I'll just search on YouTube right now.\n\n17:10 - Jorge Lewis \nYeah, I'm trying to find one as well.\n\n17:37 - Jorge Lewis \nI think I found a good example. Could you also edit your message to mention that we can include multiple of the options.\n\n17:56 - Will Vincent Parrone \nYeah, thank you. Including this right now, yes, we can have multiple options.\n\n18:14 - Will Vincent Parrone \nOh, there we go.\n\n18:20 - Will Vincent Parrone \nWhere did you find this? Just Google Images?\n\n18:24 - Jorge Lewis \nYeah, I just searched Google OAuth example. Oh, nice.\n\n18:30 - Will Vincent Parrone \nYeah, I think with the exception of Google Auth and Meta Auth, everything's self-explanatory already.\n\n18:40 - Jorge Lewis \nYeah. Okay, so, but what I actually think is we're going to put yourself in his shoes. We ask him, hey, do you want this or this or this or do you want all of them? He's going to say, why would I, why would I not? Yeah, exactly. Why would he not say all of them for him? It costs the same. Um, since for us, like realistically the time to implement more than one should maybe take one or two more hours. Um, which should be a positive, um, ROI for us since the client gets to be really happy and, um, and we can reuse that code. So, sorry, sorry. Not reuse his code. Um, create it from scratch.\n\n19:24 - Will Vincent Parrone \nOur meetings aren't going to be read by him anyways, it's okay. We can...\n\n19:30 - Jorge Lewis \nCode like this isn't his IP actually, or the client's IP, because it's so generic that it's used in every single SaaS project, so it's not exactly his IP. So we can reuse the code.\n\n19:47 - Will Vincent Parrone \nYeah, I think only the workshops might be a little bit... On the gray area of what's good and what's not.\n\n19:56 - Jorge Lewis \nYeah, for sure.\n\n19:58 - Will Vincent Parrone \nYeah. Okay.\n\n20:01 - Will Vincent Parrone \nWhile we're waiting, go on.\n\n20:04 - Jorge Lewis \nWe can get into making all the authentication options, I think.\n\n20:09 - Will Vincent Parrone \nOkay. Wait.\n\n20:13 - Jorge Lewis \nIf you can share your whole screen and we can, because you're using the documentation on a browser here.\n\n20:22 - Unidentified Speaker \nMm-hmm.\n\n20:23 - Jorge Lewis \nYeah, so you can share your whole screen. I can follow along with the docs that you're looking at.\n\n20:29 - Jorge Lewis \nOK.\n\n20:32 - Will Vincent Parrone \nWait, let me just clean up my tabs.\n\n20:39 - Will Vincent Parrone \nThere we go, all nice and clean. Mm-hmm.\n\n20:51 - Will Vincent Parrone \nStop presenting.\n\n20:58 - Will Vincent Parrone"}
02:07:09,321 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,322 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'ve been making some changes. Alright, so I\'m saying Google Meets. There\'s just one more variable.\n\n32:57 - Will Vincent Parrone \nOkay. I\'m in Alpha.\n\n33:01 - Will Vincent Parrone \nUm...\n\n33:07 - Will Vincent Parrone \nOkay, public base URL localhost 8080, okay.\n\n33:12 - Jorge Lewis \nYeah, viewers had a little bit of a confusion with some of the variables and what they were doing, but yeah.\n\n33:20 - Will Vincent Parrone \nOkay, I think this can work now.\n\n33:26 - Will Vincent Parrone \nOkay, let\'s see.\n\n33:32 - Jorge Lewis \nActually, you might need...\n\n33:38 - Will Vincent Parrone \nHmm.\n\n33:39 - Will Vincent Parrone \nGo to app. Oh, now it works.\n\n33:46 - Will Vincent Parrone \nLet\'s see.\n\n33:47 - Will Vincent Parrone \nLet\'s see indeed. OK.\n\n33:58 - Jorge Lewis \nAnd one thing I\'ve actually noticed that I\'m not going to make a conclusion yet or an opinion on yet, I think a hypothesis I have is that people use Vim and Linux to be more efficient. But what I\'ve noticed is that it\'s contrary because when I\'m watching people code on Windows and code on Linux, the people that code on Windows are less flashy, they\'re using their mouse, maybe they type a little bit slower, but they\'re more efficient. So it\'s a hypothesis that I have that people that use Linux blindly because it\'s better or it\'s more efficient end up kind of shooting themselves in the foot. It\'s a hypothesis I have.\n\n34:42 - Will Vincent Parrone \nI think it\'s because the value is so like, like the learning curve is a lot, lot harder than it looks. That\'s why you have to spend literally like two to three years. In order to actually be 1.5 times better than the average dev.\n\n35:06 - Jorge Lewis \nMost people, the best companies in the world don\'t use Linux, they use Windows.\n\n35:13 - Jorge Lewis \nUsing Linux doesn\'t make you a better developer, doesn\'t make you a better engineer. It\'s supposed to make you more efficient but what do engineers need to be more efficient? They don\'t need to type 1.5 times faster, typing isn\'t the problem. CDing into the right repository isn\'t the problem. Using a text-only IDE isn\'t the problem.\n\n35:35 - Will Vincent Parrone \nActually, that\'s something I think that\'s where we would disagree. However, something we could agree on is that if you just follow trends blindly without considering your personal circumstances, you\'re really going to shoot yourself in the foot. And also, what\'s the key? I mean, like, yeah, for some people, VS Code works for them. For some, doing Linux, Vim, and all that stuff works for them, because they\'ve custom made it for their specific circumstances. So it makes perfect sense that they\'re going to be better developers.\n\n36:22 - Jorge Lewis \nBut it\'s interesting. Go on.\n\n36:27 - Will Vincent Parrone \nBasically, I see a lot of people just use Vim, use Linux for the reason that their influencers did it without much research and they\'re having plenty of problems because they did not expect that they\'re going to be making some sacrifices along the way.\n\n36:52 - Jorge Lewis \nThat\'s a good reason. I agree with that. To get good at Linux, you need to dedicate specific time to be good at Linux and Vim and stuff like that. It\'s not something that you learn over time, it\'s something that you need to learn, you need to actually do it. And which most people don\'t do because they have other things to do. For me, I can\'t spend time, me personally, it\'s on a person-to-person basis. I have business calls to get to, I can\'t be saying, sorry, let me SSH into my Google Meet server or something like that.\n\n37:28 - Jorge Lewis \nFor me, it doesn\'t work. For me, I\'m a unique person, but for other unique people, it also doesn\'t work for them. They have to work. If you\'re in school, I would definitely recommend learning Linux because why not? That\'s growth. You don\'t have to end up using it in your career, but learning it is great. Learning things is always great.\n\n37:52 - Will Vincent Parrone \nWhat did I do here again? So basically, we\'re just going to add another column here, right?\n\n38:00 - Jorge Lewis \nYeah, pretty much add a column and then connect it to the database.\n\n38:05 - Will Vincent Parrone \nWait, I remember, let me just review the super base types again. Oops.\n\n38:23 - Will Vincent Parrone \nSo where is to do?\n\n38:32 - Will Vincent Parrone \nOne is to one.\n\n38:36 - Will Vincent Parrone \nIs this updated? I don\'t think so.\n\n38:46 - Jorge Lewis \nAlso, sometimes it\'s not a matter of this or that. Sometimes it\'s a matter of this and that. Like, I use a Vim, I use a NeoVim environment in my VS Code.\n\n39:00 - Jorge Lewis \nOh, really?\n\n39:04 - Jorge Lewis \nIt\'s a mentality that my friend told me while I was in Thailand. He\'s like one of the best engineers along with Jonas and Nazif that I\'ve met. It\'s a matter of, oh, don\'t use, well, why would you have to use one or two? Why do you have to use Linux or Windows? Why\n######################\nOutput:'}
02:07:09,323 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,326 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'ve been making some changes. Alright, so I'm saying Google Meets. There's just one more variable.\n\n32:57 - Will Vincent Parrone \nOkay. I'm in Alpha.\n\n33:01 - Will Vincent Parrone \nUm...\n\n33:07 - Will Vincent Parrone \nOkay, public base URL localhost 8080, okay.\n\n33:12 - Jorge Lewis \nYeah, viewers had a little bit of a confusion with some of the variables and what they were doing, but yeah.\n\n33:20 - Will Vincent Parrone \nOkay, I think this can work now.\n\n33:26 - Will Vincent Parrone \nOkay, let's see.\n\n33:32 - Jorge Lewis \nActually, you might need...\n\n33:38 - Will Vincent Parrone \nHmm.\n\n33:39 - Will Vincent Parrone \nGo to app. Oh, now it works.\n\n33:46 - Will Vincent Parrone \nLet's see.\n\n33:47 - Will Vincent Parrone \nLet's see indeed. OK.\n\n33:58 - Jorge Lewis \nAnd one thing I've actually noticed that I'm not going to make a conclusion yet or an opinion on yet, I think a hypothesis I have is that people use Vim and Linux to be more efficient. But what I've noticed is that it's contrary because when I'm watching people code on Windows and code on Linux, the people that code on Windows are less flashy, they're using their mouse, maybe they type a little bit slower, but they're more efficient. So it's a hypothesis that I have that people that use Linux blindly because it's better or it's more efficient end up kind of shooting themselves in the foot. It's a hypothesis I have.\n\n34:42 - Will Vincent Parrone \nI think it's because the value is so like, like the learning curve is a lot, lot harder than it looks. That's why you have to spend literally like two to three years. In order to actually be 1.5 times better than the average dev.\n\n35:06 - Jorge Lewis \nMost people, the best companies in the world don't use Linux, they use Windows.\n\n35:13 - Jorge Lewis \nUsing Linux doesn't make you a better developer, doesn't make you a better engineer. It's supposed to make you more efficient but what do engineers need to be more efficient? They don't need to type 1.5 times faster, typing isn't the problem. CDing into the right repository isn't the problem. Using a text-only IDE isn't the problem.\n\n35:35 - Will Vincent Parrone \nActually, that's something I think that's where we would disagree. However, something we could agree on is that if you just follow trends blindly without considering your personal circumstances, you're really going to shoot yourself in the foot. And also, what's the key? I mean, like, yeah, for some people, VS Code works for them. For some, doing Linux, Vim, and all that stuff works for them, because they've custom made it for their specific circumstances. So it makes perfect sense that they're going to be better developers.\n\n36:22 - Jorge Lewis \nBut it's interesting. Go on.\n\n36:27 - Will Vincent Parrone \nBasically, I see a lot of people just use Vim, use Linux for the reason that their influencers did it without much research and they're having plenty of problems because they did not expect that they're going to be making some sacrifices along the way.\n\n36:52 - Jorge Lewis \nThat's a good reason. I agree with that. To get good at Linux, you need to dedicate specific time to be good at Linux and Vim and stuff like that. It's not something that you learn over time, it's something that you need to learn, you need to actually do it. And which most people don't do because they have other things to do. For me, I can't spend time, me personally, it's on a person-to-person basis. I have business calls to get to, I can't be saying, sorry, let me SSH into my Google Meet server or something like that.\n\n37:28 - Jorge Lewis \nFor me, it doesn't work. For me, I'm a unique person, but for other unique people, it also doesn't work for them. They have to work. If you're in school, I would definitely recommend learning Linux because why not? That's growth. You don't have to end up using it in your career, but learning it is great. Learning things is always great.\n\n37:52 - Will Vincent Parrone \nWhat did I do here again? So basically, we're just going to add another column here, right?\n\n38:00 - Jorge Lewis \nYeah, pretty much add a column and then connect it to the database.\n\n38:05 - Will Vincent Parrone \nWait, I remember, let me just review the super base types again. Oops.\n\n38:23 - Will Vincent Parrone \nSo where is to do?\n\n38:32 - Will Vincent Parrone \nOne is to one.\n\n38:36 - Will Vincent Parrone \nIs this updated? I don't think so.\n\n38:46 - Jorge Lewis \nAlso, sometimes it's not a matter of this or that. Sometimes it's a matter of this and that. Like, I use a Vim, I use a NeoVim environment in my VS Code.\n\n39:00 - Jorge Lewis \nOh, really?\n\n39:04 - Jorge Lewis \nIt's a mentality that my friend told me while I was in Thailand. He's like one of the best engineers along with Jonas and Nazif that I've met. It's a matter of, oh, don't use, well, why would you have to use one or two? Why do you have to use Linux or Windows? Why"}
02:07:09,513 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,514 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: front end there, that\'s actually the leaps table, not the evaluated submissions table. And I haven\'t added that done to, The leads table. So I\'m going to do that right now. So you\'re going to have to actually...\n\n45:54 - Will Vincent Parrone \nThat explains it. That explains the issues I\'m having. Okay.\n\n45:59 - Unidentified Speaker \nOh no.\n\n46:01 - Will Vincent Parrone \nIn my other laptop, I was trying to forcibly justify the leads. I was forcibly trying to justify the done table. Okay. I\'ll wait for it.\n\n46:11 - Jorge Lewis \nOkay, I\'ve added it Let me do you have the super base generate command a hand or should I do and push?\n\n46:21 - Jorge Lewis \nCan you do it?\n\n46:23 - Jorge Lewis \nYeah, I got it. Thanks. All right All right, I think I sent it or I pushed it Okay.\n\n46:48 - Will Vincent Parrone \nSpace BD.\n\n46:50 - Jorge Lewis \nI\'m actually going to paste the command in the project so that we have it at hand.\n\n46:57 - Will Vincent Parrone \nLeads. We have done. Okay. There we go. Lovely.\n\n47:05 - Will Vincent Parrone \nI think it is in project. No, no, not projects.\n\n47:11 - Will Vincent Parrone \nResizable panel, data table, lead data, deeds.\n\n47:16 - Jorge Lewis \nSo where we want to move the button to, so okay, so actually let\'s think about this. So I actually thought about this as well. What\'s the, let\'s take a look at the front end real quick. And instead of trying, there\'s an easy way and there\'s a hard way, I realized. So the left side there is a data table. It\'s using ChefCN. It\'s pretty complex compared to the right side, which is straight up just very simple stuff. So I realized if we move the button or the toggle to the right side, it\'ll make things a lot easier. We don\'t have to worry about the data table stuff.\n\n47:50 - Jorge Lewis \nBut if you want to learn more about the data table and how it works, I\'m more than happy to.\n\n47:58 - Will Vincent Parrone \nYes, cool. I already suffered.\n\n48:03 - Jorge Lewis \nI need to learn a bit more about it as well. But the only thing is I haven\'t had the time to learn it properly.\n\n48:12 - Will Vincent Parrone \nYeah, me too. Let me try to remember the last thing I did. Okay, here we go. Basically, I\'m going to be copy pasting this.\n\n48:27 - Will Vincent Parrone \nSince this is a boolean one, create render.\n\n48:32 - Will Vincent Parrone \nRelative dates. And I\'m going to be Copying this one.\n\n48:43 - Will Vincent Parrone \nCopy relative date. So let\'s call this relative to do.\n\n48:49 - Jorge Lewis \nOh, actually, it\'s actually already there. It\'s started, I think. Dang it. Okay.\n\n49:03 - Jorge Lewis \nOn a general note, I wonder if it\'s a good practice to suffix the files that are cells, like with a dash cell, I wonder. I don\'t know.\n\n49:12 - Will Vincent Parrone \nI mean, it\'s for readability purposes. It\'s always a good thing.\n\n49:20 - Will Vincent Parrone \nLet\'s call this then. Let\'s call the done button. Let\'s see what happens.\n\n49:27 - Will Vincent Parrone \nRelative.\n\n49:38 - Jorge Lewis \nLike, see, for... Do you have GitHub Copilot in general, or...?\n\n49:41 - Unidentified Speaker \nHuh?\n\n49:43 - Jorge Lewis \nSorry?\n\n49:44 - Jorge Lewis \nDo you have GitHub Copilot?\n\n49:48 - Will Vincent Parrone \nNo.\n\n49:51 - Will Vincent Parrone \nI am only using a language server here.\n\n50:01 - Will Vincent Parrone \nRelativeDateCell... RelativeDateCell... What\'s the name of this again? DoneButton... ItemValue...\n\n50:18 - Will Vincent Parrone \nWhat\'s the, uh... Okay, ID...\n\n50:27 - Will Vincent Parrone \nItem.ID...\n\n50:38 - Will Vincent Parrone \nI\'m not sure if actually this is correct.\n\n50:52 - Will Vincent Parrone \nOkay, I think this is lead.\n\n50:57 - Will Vincent Parrone \nNo, what is this?\n\n50:59 - Jorge Lewis \nSo I actually tried working on this at some point, but I don\'t know what happens.\n\n51:16 - Will Vincent Parrone \nOkay, let\'s see. What is data body cell? Data body cell.\n\n51:25 - Will Vincent Parrone \nTable color, I know you\'re rendering an item, so the thing I would have to do is find out what contains the lead.\n\n51:37 - Will Vincent Parrone \nOkay.\n\n51:42 - Will Vincent Parrone \nYeah.\n\n51:46 - Will Vincent Parrone \nNevermind, that\'s a dead end. Insert columns, table, create columns, status, assessor, status. Property done does not exist.\n\n51:57 - Unidentified Speaker \nData.\n\n51:59 - Jorge Lewis \nSo what\'s item.value?\n\n52:01 - Jorge Lewis \nWhat is it? What is...\n\n52:06 - Jorge Lewis \nOh, wait. Have you... No, you just... I think it\'s because you haven\'t... It hasn\'t updated your types yet, your ID.\n\n52:\n######################\nOutput:'}
02:07:09,514 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,517 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "front end there, that's actually the leaps table, not the evaluated submissions table. And I haven't added that done to, The leads table. So I'm going to do that right now. So you're going to have to actually...\n\n45:54 - Will Vincent Parrone \nThat explains it. That explains the issues I'm having. Okay.\n\n45:59 - Unidentified Speaker \nOh no.\n\n46:01 - Will Vincent Parrone \nIn my other laptop, I was trying to forcibly justify the leads. I was forcibly trying to justify the done table. Okay. I'll wait for it.\n\n46:11 - Jorge Lewis \nOkay, I've added it Let me do you have the super base generate command a hand or should I do and push?\n\n46:21 - Jorge Lewis \nCan you do it?\n\n46:23 - Jorge Lewis \nYeah, I got it. Thanks. All right All right, I think I sent it or I pushed it Okay.\n\n46:48 - Will Vincent Parrone \nSpace BD.\n\n46:50 - Jorge Lewis \nI'm actually going to paste the command in the project so that we have it at hand.\n\n46:57 - Will Vincent Parrone \nLeads. We have done. Okay. There we go. Lovely.\n\n47:05 - Will Vincent Parrone \nI think it is in project. No, no, not projects.\n\n47:11 - Will Vincent Parrone \nResizable panel, data table, lead data, deeds.\n\n47:16 - Jorge Lewis \nSo where we want to move the button to, so okay, so actually let's think about this. So I actually thought about this as well. What's the, let's take a look at the front end real quick. And instead of trying, there's an easy way and there's a hard way, I realized. So the left side there is a data table. It's using ChefCN. It's pretty complex compared to the right side, which is straight up just very simple stuff. So I realized if we move the button or the toggle to the right side, it'll make things a lot easier. We don't have to worry about the data table stuff.\n\n47:50 - Jorge Lewis \nBut if you want to learn more about the data table and how it works, I'm more than happy to.\n\n47:58 - Will Vincent Parrone \nYes, cool. I already suffered.\n\n48:03 - Jorge Lewis \nI need to learn a bit more about it as well. But the only thing is I haven't had the time to learn it properly.\n\n48:12 - Will Vincent Parrone \nYeah, me too. Let me try to remember the last thing I did. Okay, here we go. Basically, I'm going to be copy pasting this.\n\n48:27 - Will Vincent Parrone \nSince this is a boolean one, create render.\n\n48:32 - Will Vincent Parrone \nRelative dates. And I'm going to be Copying this one.\n\n48:43 - Will Vincent Parrone \nCopy relative date. So let's call this relative to do.\n\n48:49 - Jorge Lewis \nOh, actually, it's actually already there. It's started, I think. Dang it. Okay.\n\n49:03 - Jorge Lewis \nOn a general note, I wonder if it's a good practice to suffix the files that are cells, like with a dash cell, I wonder. I don't know.\n\n49:12 - Will Vincent Parrone \nI mean, it's for readability purposes. It's always a good thing.\n\n49:20 - Will Vincent Parrone \nLet's call this then. Let's call the done button. Let's see what happens.\n\n49:27 - Will Vincent Parrone \nRelative.\n\n49:38 - Jorge Lewis \nLike, see, for... Do you have GitHub Copilot in general, or...?\n\n49:41 - Unidentified Speaker \nHuh?\n\n49:43 - Jorge Lewis \nSorry?\n\n49:44 - Jorge Lewis \nDo you have GitHub Copilot?\n\n49:48 - Will Vincent Parrone \nNo.\n\n49:51 - Will Vincent Parrone \nI am only using a language server here.\n\n50:01 - Will Vincent Parrone \nRelativeDateCell... RelativeDateCell... What's the name of this again? DoneButton... ItemValue...\n\n50:18 - Will Vincent Parrone \nWhat's the, uh... Okay, ID...\n\n50:27 - Will Vincent Parrone \nItem.ID...\n\n50:38 - Will Vincent Parrone \nI'm not sure if actually this is correct.\n\n50:52 - Will Vincent Parrone \nOkay, I think this is lead.\n\n50:57 - Will Vincent Parrone \nNo, what is this?\n\n50:59 - Jorge Lewis \nSo I actually tried working on this at some point, but I don't know what happens.\n\n51:16 - Will Vincent Parrone \nOkay, let's see. What is data body cell? Data body cell.\n\n51:25 - Will Vincent Parrone \nTable color, I know you're rendering an item, so the thing I would have to do is find out what contains the lead.\n\n51:37 - Will Vincent Parrone \nOkay.\n\n51:42 - Will Vincent Parrone \nYeah.\n\n51:46 - Will Vincent Parrone \nNevermind, that's a dead end. Insert columns, table, create columns, status, assessor, status. Property done does not exist.\n\n51:57 - Unidentified Speaker \nData.\n\n51:59 - Jorge Lewis \nSo what's item.value?\n\n52:01 - Jorge Lewis \nWhat is it? What is...\n\n52:06 - Jorge Lewis \nOh, wait. Have you... No, you just... I think it's because you haven't... It hasn't updated your types yet, your ID.\n\n52:"}
02:07:09,545 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,547 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: an error. Error when evaluating SSR module.\n\n1:06:48 - Unidentified Speaker \nHmm.\n\n1:06:54 - Will Vincent Parrone \nInteresting. Evaluation.\n\n1:07:05 - Will Vincent Parrone \nI need to use another PC for this.\n\n1:07:10 - Will Vincent Parrone \nso Okay, I have no idea what\'s happening Okay.\n\n1:09:48 - Jorge Lewis \nWhat a strange issue.\n\n1:09:50 - Will Vincent Parrone \nYeah.\n\n1:09:53 - Will Vincent Parrone \nHow about we settle for...\n\n1:09:57 - Jorge Lewis \nActually?\n\n1:09:58 - Jorge Lewis \nGo on.\n\n1:09:59 - Jorge Lewis \nHuh. It was running a second ago, right? Like...\n\n1:10:03 - Will Vincent Parrone \nYeah.\n\n1:10:06 - Jorge Lewis \nOkay. I have an inkling into what it might be. Nope, wasn\'t it? Yeah, nope.\n\n1:10:17 - Jorge Lewis \nNo, it doesn\'t work on mine either. Wait, what? So it\'s something to do with this new typefile that CibaBase has given us.\n\n1:10:31 - Jorge Lewis \nThat\'s kind of broken something.\n\n1:10:34 - Will Vincent Parrone \nOh, at least that\'s a clue. That\'s a clue.\n\n1:10:39 - Jorge Lewis \nAlthough it\'s weirder is that it was working just like a second ago we didn\'t make any changes on it or we made like a change that I have removed and it\'s so wait what if we\'re all back into another\n\n1:11:01 - Will Vincent Parrone \nwhat if you\'re all back to the previous commit and then just do a git div.\n\n1:11:10 - Jorge Lewis \nTry that.\n\n1:11:13 - Will Vincent Parrone \nYeah, git div previews.\n\n1:11:32 - Will Vincent Parrone \nLet\'s see.\n\n1:11:36 - Will Vincent Parrone \ngit div next, git div head with head thing.\n\n1:12:07 - Will Vincent Parrone \nYeah, but like, I want a good comparison.\n\n1:12:40 - Will Vincent Parrone \nNo, the only thing different from the previous commit is the done.\n\n1:12:44 - Unidentified Speaker \nSorry?\n\n1:12:48 - Will Vincent Parrone \nThe only thing different from the previous commit is the inclusion of done.\n\n1:12:51 - Jorge Lewis \nBut like, I shouldn\'t do anything.\n\n1:13:04 - Jorge Lewis \nTry deleting it, I guess? Maybe we\'re like, maybe just, maybe we\'re just tripping and it\'s like, just doesn\'t want to work. It\'s like, you know, guys.\n\n1:13:15 - Will Vincent Parrone \nWait, let me try it. Okay.\n\n1:13:39 - Jorge Lewis \nNo, I deleted done and it doesn\'t work.\n\n1:13:43 - Jorge Lewis \nIt\'s not that, huh?\n\n1:13:45 - Jorge Lewis \nIt\'s not that, it\'s like, it\'s just so weird.\n\n1:13:52 - Will Vincent Parrone \nWait, maybe I\'ll do a blind research of which commit is working.\n\n1:14:00 - Jorge Lewis \nBut what it looks like, so the error also says, error when evaluating SSR module, the server file for the home page but I ain\'t got a clue bro all right well into your trusty hands.\n\n1:14:39 - Will Vincent Parrone \nOh, by the way, do we have the scope already for the Read.AI tool? A what? A scope.\n\n1:14:46 - Jorge Lewis \nScope?\n\n1:14:47 - Will Vincent Parrone \nYeah, like inclusion of the to-do, like the backlogs.\n\n1:14:53 - Jorge Lewis \nNo, no, no. I mean, it\'s just in my head.\n\n1:14:56 - Jorge Lewis \nOkay.\n\n1:14:57 - Jorge Lewis \nI use this on a daily basis for reaching out to people for sales.\n\n1:15:03 - Jorge Lewis \nYeah, there\'s quite a few things that I would like, but they\'re all kind of nice to have. It\'s not really too important. Okay, okay.\n\n1:15:13 - Will Vincent Parrone \nI\'ll try to fix this, if ever, during my date. But it looks like Q1 wants to...\n\n1:15:21 - Jorge Lewis \nYeah, I think it\'s more important we go back to work on that. And hopefully, next time we attack this issue on rest, it\'s gone.\n\n1:15:29 - Will Vincent Parrone \nYeah. Wait, wait. Before you go, Q1 said that they\'re going to be signing up for the newsletter before the Y experience, so most likely, the users have an account. They\'re probably going to transfer the account from the newsletter to us. I\'m not sure about this.\n\n1:15:49 - Will Vincent Parrone \nSorry, say that again?\n\n1:15:52 - Will Vincent Parrone \nI\'ll say this. This is what Q1 had said. Remember, in terms of sequence, they could have signed up for the newsletter before the Y experience. And they can call to the mobile app. Try the Y experience and want to sign up. So basically, people from the newsletter would be signing in. Should we do some kind of creating an account if a person came from the newsletter, like the workflow of it?\n\n1:16:25 -\n######################\nOutput:'}
02:07:09,547 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,550 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "an error. Error when evaluating SSR module.\n\n1:06:48 - Unidentified Speaker \nHmm.\n\n1:06:54 - Will Vincent Parrone \nInteresting. Evaluation.\n\n1:07:05 - Will Vincent Parrone \nI need to use another PC for this.\n\n1:07:10 - Will Vincent Parrone \nso Okay, I have no idea what's happening Okay.\n\n1:09:48 - Jorge Lewis \nWhat a strange issue.\n\n1:09:50 - Will Vincent Parrone \nYeah.\n\n1:09:53 - Will Vincent Parrone \nHow about we settle for...\n\n1:09:57 - Jorge Lewis \nActually?\n\n1:09:58 - Jorge Lewis \nGo on.\n\n1:09:59 - Jorge Lewis \nHuh. It was running a second ago, right? Like...\n\n1:10:03 - Will Vincent Parrone \nYeah.\n\n1:10:06 - Jorge Lewis \nOkay. I have an inkling into what it might be. Nope, wasn't it? Yeah, nope.\n\n1:10:17 - Jorge Lewis \nNo, it doesn't work on mine either. Wait, what? So it's something to do with this new typefile that CibaBase has given us.\n\n1:10:31 - Jorge Lewis \nThat's kind of broken something.\n\n1:10:34 - Will Vincent Parrone \nOh, at least that's a clue. That's a clue.\n\n1:10:39 - Jorge Lewis \nAlthough it's weirder is that it was working just like a second ago we didn't make any changes on it or we made like a change that I have removed and it's so wait what if we're all back into another\n\n1:11:01 - Will Vincent Parrone \nwhat if you're all back to the previous commit and then just do a git div.\n\n1:11:10 - Jorge Lewis \nTry that.\n\n1:11:13 - Will Vincent Parrone \nYeah, git div previews.\n\n1:11:32 - Will Vincent Parrone \nLet's see.\n\n1:11:36 - Will Vincent Parrone \ngit div next, git div head with head thing.\n\n1:12:07 - Will Vincent Parrone \nYeah, but like, I want a good comparison.\n\n1:12:40 - Will Vincent Parrone \nNo, the only thing different from the previous commit is the done.\n\n1:12:44 - Unidentified Speaker \nSorry?\n\n1:12:48 - Will Vincent Parrone \nThe only thing different from the previous commit is the inclusion of done.\n\n1:12:51 - Jorge Lewis \nBut like, I shouldn't do anything.\n\n1:13:04 - Jorge Lewis \nTry deleting it, I guess? Maybe we're like, maybe just, maybe we're just tripping and it's like, just doesn't want to work. It's like, you know, guys.\n\n1:13:15 - Will Vincent Parrone \nWait, let me try it. Okay.\n\n1:13:39 - Jorge Lewis \nNo, I deleted done and it doesn't work.\n\n1:13:43 - Jorge Lewis \nIt's not that, huh?\n\n1:13:45 - Jorge Lewis \nIt's not that, it's like, it's just so weird.\n\n1:13:52 - Will Vincent Parrone \nWait, maybe I'll do a blind research of which commit is working.\n\n1:14:00 - Jorge Lewis \nBut what it looks like, so the error also says, error when evaluating SSR module, the server file for the home page but I ain't got a clue bro all right well into your trusty hands.\n\n1:14:39 - Will Vincent Parrone \nOh, by the way, do we have the scope already for the Read.AI tool? A what? A scope.\n\n1:14:46 - Jorge Lewis \nScope?\n\n1:14:47 - Will Vincent Parrone \nYeah, like inclusion of the to-do, like the backlogs.\n\n1:14:53 - Jorge Lewis \nNo, no, no. I mean, it's just in my head.\n\n1:14:56 - Jorge Lewis \nOkay.\n\n1:14:57 - Jorge Lewis \nI use this on a daily basis for reaching out to people for sales.\n\n1:15:03 - Jorge Lewis \nYeah, there's quite a few things that I would like, but they're all kind of nice to have. It's not really too important. Okay, okay.\n\n1:15:13 - Will Vincent Parrone \nI'll try to fix this, if ever, during my date. But it looks like Q1 wants to...\n\n1:15:21 - Jorge Lewis \nYeah, I think it's more important we go back to work on that. And hopefully, next time we attack this issue on rest, it's gone.\n\n1:15:29 - Will Vincent Parrone \nYeah. Wait, wait. Before you go, Q1 said that they're going to be signing up for the newsletter before the Y experience, so most likely, the users have an account. They're probably going to transfer the account from the newsletter to us. I'm not sure about this.\n\n1:15:49 - Will Vincent Parrone \nSorry, say that again?\n\n1:15:52 - Will Vincent Parrone \nI'll say this. This is what Q1 had said. Remember, in terms of sequence, they could have signed up for the newsletter before the Y experience. And they can call to the mobile app. Try the Y experience and want to sign up. So basically, people from the newsletter would be signing in. Should we do some kind of creating an account if a person came from the newsletter, like the workflow of it?\n\n1:16:25 -"}
02:07:09,643 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,644 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: you follow me, Hmm. So here we give it its prompts here, but then we\'re also giving it more. This should be, we should try to, this is kind of as a backlog. I know this is probably temporary, but there should be a backlog for somebody to migrate it to the front end because we want everything, all the prompts to be exposed to the front end. So yeah, we need to.\n\n1:31:55 - Hasnain sayyed \nOn the backend, right?\n\n1:31:58 - Jorge Lewis \nNo, no, it\'s the front end. We don\'t want text here. We don\'t want this text here. What we want to do is be using the data tape, the super base and accessing the prompts from there, which admins can modify from the front end.\n\n1:32:08 - Jorge Lewis \nOkay.\n\n1:32:19 - Jorge Lewis \nSo we don\'t want to hard code the prompts here.\n\n1:32:25 - Jorge Lewis \nBut instead, we want to use a promise for the profile. So yeah, that\'s something to note out. So what is this here?\n\n1:32:55 - Jorge Lewis \nUh, you can click on me somewhere.\n\n1:32:59 - Hasnain sayyed \nUh, could you also share your screen? Uh, I can.\n\n1:33:02 - Unidentified Speaker \nYeah.\n\n1:33:03 - Hasnain sayyed \nYeah. Okay. So, so we have this, this loop.\n\n1:33:27 - Jorge Lewis \nI just copied this thing So we don\'t need this here Okay, so...\n\n1:34:06 - Jorge Lewis \nWhy is that still saying? Oh, expected zero. Oh, okay. Oh, I see. Sorry. Okay, this is the...\n\n1:34:18 - Hasnain sayyed \nNo, we can edit this.\n\n1:34:21 - Jorge Lewis \nThis is the new guy. I thought this was the super generate message function.\n\n1:34:29 - Hasnain sayyed \nSo this, uh, this file is different. This is a generate message function. We can just, uh, let the LLM to generate, uh, the question on the behalf of synthetic agent. So, uh, the prompt, the prompt will be different.\n\n1:34:52 - Hasnain sayyed \nIs that make sense? Yeah, we just remove this all.\n\n1:35:04 - Jorge Lewis \nCorrect.\n\n1:35:21 - Jorge Lewis \nSo this is not a structure of profile. I believe this is a synthetic user.\n\n1:35:36 - Hasnain sayyed \nYeah.\n\n1:35:39 - Jorge Lewis \nWhat was the definition of this profile though?\n\n1:35:45 - Jorge Lewis \nOver here. So we can do type, uh, then back here.\n\n1:36:07 - Hasnain sayyed \nOkay. It\'s not profiled. It\'s it\'s in. Yeah, there is no S. Correct. And this we have to export over here.\n\n1:36:22 - Jorge Lewis \nYeah.\n\n1:36:24 - Jorge Lewis \nSo, is this correct over here? System and then, or is this a tuple?\n\n1:36:31 - Jorge Lewis \nAnd then I have to do prompts.\n\n1:36:34 - Jorge Lewis \nOr how was it before? Let me just copy this.\n\n1:36:39 - Jorge Lewis \nSo, it\'s a list. Oh, it\'s just the two, okay.\n\n1:36:44 - Jorge Lewis \nSo prompts teams, okay, so this is going to change from Like it\'s just prompt this is not gonna be using So how How should we go about structuring the profile structure? So if you see on my screen We have the prompt is Is it these three?\n\n1:37:17 - Jorge Lewis \nHmm.\n\n1:37:17 - Jorge Lewis \nOr well, we\'re actually. Okay. So let me think.\n\n1:37:28 - Jorge Lewis \nSo this objective is, it can be just prompt. Personality can be part of the prompt and LM. Okay. Okay. So these two are just part of the prompt. So inside of the structure of here of synthetic profile, Should I re-upload the file?\n\n1:37:50 - Hasnain sayyed \nBecause I have deleted.\n\n1:37:53 - Hasnain sayyed \nRe-upload the file? Which file?\n\n1:37:55 - Hasnain sayyed \nThe CSV from the profile. So we will be having the users in the synthetic one. Like, do you want- I think, I think.\n\n1:38:05 - Unidentified Speaker \nYeah.\n\n1:38:06 - Jorge Lewis \nGo ahead. Yes.\n\n1:38:09 - Jorge Lewis \nOh, actually, you know what we could do to make it more dynamic and probably better, just a lot better code is within anywhere in the original code that\'s accessing the profile. So let me, let me go to man to kind of illustrate what I mean. So this function here is returning a profile, right?\n\n1:38:31 - Hasnain sayyed \nRight. Just a second. Yes.\n\n1:38:37 - Jorge Lewis \nSo this profile here is referring to the, like an actual user. What we can do is do something like, so we take in another Boolean synthetic.\n\n1:38:49 - Unidentified Speaker \nYeah.\n\n1:38:52 - Hasnain sayyed \nIt will be false for the default value\n######################\nOutput:'}
02:07:09,644 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,647 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "you follow me, Hmm. So here we give it its prompts here, but then we're also giving it more. This should be, we should try to, this is kind of as a backlog. I know this is probably temporary, but there should be a backlog for somebody to migrate it to the front end because we want everything, all the prompts to be exposed to the front end. So yeah, we need to.\n\n1:31:55 - Hasnain sayyed \nOn the backend, right?\n\n1:31:58 - Jorge Lewis \nNo, no, it's the front end. We don't want text here. We don't want this text here. What we want to do is be using the data tape, the super base and accessing the prompts from there, which admins can modify from the front end.\n\n1:32:08 - Jorge Lewis \nOkay.\n\n1:32:19 - Jorge Lewis \nSo we don't want to hard code the prompts here.\n\n1:32:25 - Jorge Lewis \nBut instead, we want to use a promise for the profile. So yeah, that's something to note out. So what is this here?\n\n1:32:55 - Jorge Lewis \nUh, you can click on me somewhere.\n\n1:32:59 - Hasnain sayyed \nUh, could you also share your screen? Uh, I can.\n\n1:33:02 - Unidentified Speaker \nYeah.\n\n1:33:03 - Hasnain sayyed \nYeah. Okay. So, so we have this, this loop.\n\n1:33:27 - Jorge Lewis \nI just copied this thing So we don't need this here Okay, so...\n\n1:34:06 - Jorge Lewis \nWhy is that still saying? Oh, expected zero. Oh, okay. Oh, I see. Sorry. Okay, this is the...\n\n1:34:18 - Hasnain sayyed \nNo, we can edit this.\n\n1:34:21 - Jorge Lewis \nThis is the new guy. I thought this was the super generate message function.\n\n1:34:29 - Hasnain sayyed \nSo this, uh, this file is different. This is a generate message function. We can just, uh, let the LLM to generate, uh, the question on the behalf of synthetic agent. So, uh, the prompt, the prompt will be different.\n\n1:34:52 - Hasnain sayyed \nIs that make sense? Yeah, we just remove this all.\n\n1:35:04 - Jorge Lewis \nCorrect.\n\n1:35:21 - Jorge Lewis \nSo this is not a structure of profile. I believe this is a synthetic user.\n\n1:35:36 - Hasnain sayyed \nYeah.\n\n1:35:39 - Jorge Lewis \nWhat was the definition of this profile though?\n\n1:35:45 - Jorge Lewis \nOver here. So we can do type, uh, then back here.\n\n1:36:07 - Hasnain sayyed \nOkay. It's not profiled. It's it's in. Yeah, there is no S. Correct. And this we have to export over here.\n\n1:36:22 - Jorge Lewis \nYeah.\n\n1:36:24 - Jorge Lewis \nSo, is this correct over here? System and then, or is this a tuple?\n\n1:36:31 - Jorge Lewis \nAnd then I have to do prompts.\n\n1:36:34 - Jorge Lewis \nOr how was it before? Let me just copy this.\n\n1:36:39 - Jorge Lewis \nSo, it's a list. Oh, it's just the two, okay.\n\n1:36:44 - Jorge Lewis \nSo prompts teams, okay, so this is going to change from Like it's just prompt this is not gonna be using So how How should we go about structuring the profile structure? So if you see on my screen We have the prompt is Is it these three?\n\n1:37:17 - Jorge Lewis \nHmm.\n\n1:37:17 - Jorge Lewis \nOr well, we're actually. Okay. So let me think.\n\n1:37:28 - Jorge Lewis \nSo this objective is, it can be just prompt. Personality can be part of the prompt and LM. Okay. Okay. So these two are just part of the prompt. So inside of the structure of here of synthetic profile, Should I re-upload the file?\n\n1:37:50 - Hasnain sayyed \nBecause I have deleted.\n\n1:37:53 - Hasnain sayyed \nRe-upload the file? Which file?\n\n1:37:55 - Hasnain sayyed \nThe CSV from the profile. So we will be having the users in the synthetic one. Like, do you want- I think, I think.\n\n1:38:05 - Unidentified Speaker \nYeah.\n\n1:38:06 - Jorge Lewis \nGo ahead. Yes.\n\n1:38:09 - Jorge Lewis \nOh, actually, you know what we could do to make it more dynamic and probably better, just a lot better code is within anywhere in the original code that's accessing the profile. So let me, let me go to man to kind of illustrate what I mean. So this function here is returning a profile, right?\n\n1:38:31 - Hasnain sayyed \nRight. Just a second. Yes.\n\n1:38:37 - Jorge Lewis \nSo this profile here is referring to the, like an actual user. What we can do is do something like, so we take in another Boolean synthetic.\n\n1:38:49 - Unidentified Speaker \nYeah.\n\n1:38:52 - Hasnain sayyed \nIt will be false for the default value"}
02:07:09,696 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,698 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: returning a profile, right?\n\n1:38:31 - Hasnain sayyed \nRight. Just a second. Yes.\n\n1:38:37 - Jorge Lewis \nSo this profile here is referring to the, like an actual user. What we can do is do something like, so we take in another Boolean synthetic.\n\n1:38:49 - Unidentified Speaker \nYeah.\n\n1:38:52 - Hasnain sayyed \nIt will be false for the default value. You can put the default value as well.\n\n1:38:58 - Jorge Lewis \nOh, yeah. Good point. And then we do table. Synthetic.\n\n1:39:08 - Jorge Lewis \nOr just do profile table.\n\n1:39:15 - Hasnain sayyed \nIs it profile?\n\n1:39:19 - Jorge Lewis \nWe want to make sure it\'s, they\'re all the same. That\'s a big, that\'s important.\n\n1:39:27 - Jorge Lewis \nSo profiles with an S. So we wanted this one to be profiles with an S.\n\n1:39:33 - Jorge Lewis \nThere\'s of course best practices in terms of should we use S or not, but at least make them all the same. So if they all use S, use S.\n\n1:39:41 - Jorge Lewis \nYeah. Okay.\n\n1:39:44 - Jorge Lewis \nWhich means I believe in, yeah, I already added S, okay, nice. Or did you? Okay, so it comes, what else? And I think that\'s, it\'s just that table that we\'re changing, right?\n\n1:39:56 - Unidentified Speaker \nYeah.\n\n1:39:59 - Jorge Lewis \nOr just do synthetic, we don\'t need it, we can just clean this up a bit.\n\n1:40:15 - Hasnain sayyed \nI\'ve added the data over you.\n\n1:40:19 - Jorge Lewis \nSo pretty much like that. And then we use, Oh, is that you?\n\n1:40:30 - Jorge Lewis \nNo.\n\n1:40:33 - Jorge Lewis \nHuh?\n\n1:40:35 - Jorge Lewis \nUh, So, what type, what does this take in?\n\n1:40:59 - Hasnain sayyed \nI think the row, maybe?\n\n1:41:02 - Jorge Lewis \nActually, I think I know.\n\n1:41:11 - Jorge Lewis \nIf you go into database.types, it takes in...\n\n1:41:18 - Jorge Lewis \nTake some of these things.\n\n1:41:22 - Unidentified Speaker \nTables.\n\n1:41:29 - Jorge Lewis \nHow do I? Where\'s the\n\n1:42:07 - Hasnain sayyed \nHow should we add?\n\n1:42:09 - Hasnain sayyed \nLet me try.\n\n1:42:36 - Jorge Lewis \nBye.\n\n1:43:03 - Jorge Lewis \nYes, I mean, if we use...\n\n1:43:07 - Hasnain sayyed \nYeah, have you found the solution?\n\n1:43:12 - Jorge Lewis \nSo, not yet, but just kind of to think it through, this does take in a string, or it ends up being a string, but it\'s just typed differently. So maybe, or maybe actually. We can use this code.\n\n1:43:38 - Unidentified Speaker \nYeah.\n\n1:43:41 - Jorge Lewis \nSo if I put the string, if I do this, it works.\n\n1:43:48 - Jorge Lewis \nBut I want to reuse this variable profile table since we I think use it down? Oh no, it\'s just once.\n\n1:44:06 - Jorge Lewis \nWe\'re only asking, we\'re only making the simple base request once, so I guess we can use this, but I wonder maybe we should figure it out instead of\n\n1:44:34 - Hasnain sayyed \nLet me try one thing.\n\n1:45:02 - Hasnain sayyed \nYeah. Yeah.\n\n1:45:33 - Hasnain sayyed \nThat\'s it.\n\n1:46:00 - Hasnain sayyed \nAt 10 o\'clock, she would get up and leave. What? Again? She would leave at 2.30 in the morning. You would come at 8.30?\n\n1:46:12 - Hasnain sayyed \nNo, no. She would come at 6.30 in the morning. She would come at 8.30 the morning. Sometimes, she would come late at night. She would come late at night and leave early in the morning. She would leave early in the morning. I would come at the 8.30 morning. She would come at 8.30 in the morning. I would eat and leave.\n\n1:46:33 - Hasnain sayyed \nYou think he made any progress?\n\n1:47:04 - Hasnain sayyed \nI don\'t know.\n\n1:47:31 - Hasnain sayyed \nI think that\'s better actually.\n\n1:47:57 - Jorge Lewis \nBut I can\'t tell because my screen doesn\'t show me the correct things.\n\n1:48:15 - Jorge Lewis \nShowing you any errors? Yeah.\n\n1:48:24 - Hasnain sayyed \nI think we both are in different areas.\n\n1:48:30 - Hasnain sayyed \nTables, it\'s not as stable, I think.\n\n1:48:33 - Jorge Lewis \nYeah, I think month of dates.\n\n1:48:\n######################\nOutput:'}
02:07:09,698 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,701 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "returning a profile, right?\n\n1:38:31 - Hasnain sayyed \nRight. Just a second. Yes.\n\n1:38:37 - Jorge Lewis \nSo this profile here is referring to the, like an actual user. What we can do is do something like, so we take in another Boolean synthetic.\n\n1:38:49 - Unidentified Speaker \nYeah.\n\n1:38:52 - Hasnain sayyed \nIt will be false for the default value. You can put the default value as well.\n\n1:38:58 - Jorge Lewis \nOh, yeah. Good point. And then we do table. Synthetic.\n\n1:39:08 - Jorge Lewis \nOr just do profile table.\n\n1:39:15 - Hasnain sayyed \nIs it profile?\n\n1:39:19 - Jorge Lewis \nWe want to make sure it's, they're all the same. That's a big, that's important.\n\n1:39:27 - Jorge Lewis \nSo profiles with an S. So we wanted this one to be profiles with an S.\n\n1:39:33 - Jorge Lewis \nThere's of course best practices in terms of should we use S or not, but at least make them all the same. So if they all use S, use S.\n\n1:39:41 - Jorge Lewis \nYeah. Okay.\n\n1:39:44 - Jorge Lewis \nWhich means I believe in, yeah, I already added S, okay, nice. Or did you? Okay, so it comes, what else? And I think that's, it's just that table that we're changing, right?\n\n1:39:56 - Unidentified Speaker \nYeah.\n\n1:39:59 - Jorge Lewis \nOr just do synthetic, we don't need it, we can just clean this up a bit.\n\n1:40:15 - Hasnain sayyed \nI've added the data over you.\n\n1:40:19 - Jorge Lewis \nSo pretty much like that. And then we use, Oh, is that you?\n\n1:40:30 - Jorge Lewis \nNo.\n\n1:40:33 - Jorge Lewis \nHuh?\n\n1:40:35 - Jorge Lewis \nUh, So, what type, what does this take in?\n\n1:40:59 - Hasnain sayyed \nI think the row, maybe?\n\n1:41:02 - Jorge Lewis \nActually, I think I know.\n\n1:41:11 - Jorge Lewis \nIf you go into database.types, it takes in...\n\n1:41:18 - Jorge Lewis \nTake some of these things.\n\n1:41:22 - Unidentified Speaker \nTables.\n\n1:41:29 - Jorge Lewis \nHow do I? Where's the\n\n1:42:07 - Hasnain sayyed \nHow should we add?\n\n1:42:09 - Hasnain sayyed \nLet me try.\n\n1:42:36 - Jorge Lewis \nBye.\n\n1:43:03 - Jorge Lewis \nYes, I mean, if we use...\n\n1:43:07 - Hasnain sayyed \nYeah, have you found the solution?\n\n1:43:12 - Jorge Lewis \nSo, not yet, but just kind of to think it through, this does take in a string, or it ends up being a string, but it's just typed differently. So maybe, or maybe actually. We can use this code.\n\n1:43:38 - Unidentified Speaker \nYeah.\n\n1:43:41 - Jorge Lewis \nSo if I put the string, if I do this, it works.\n\n1:43:48 - Jorge Lewis \nBut I want to reuse this variable profile table since we I think use it down? Oh no, it's just once.\n\n1:44:06 - Jorge Lewis \nWe're only asking, we're only making the simple base request once, so I guess we can use this, but I wonder maybe we should figure it out instead of\n\n1:44:34 - Hasnain sayyed \nLet me try one thing.\n\n1:45:02 - Hasnain sayyed \nYeah. Yeah.\n\n1:45:33 - Hasnain sayyed \nThat's it.\n\n1:46:00 - Hasnain sayyed \nAt 10 o'clock, she would get up and leave. What? Again? She would leave at 2.30 in the morning. You would come at 8.30?\n\n1:46:12 - Hasnain sayyed \nNo, no. She would come at 6.30 in the morning. She would come at 8.30 the morning. Sometimes, she would come late at night. She would come late at night and leave early in the morning. She would leave early in the morning. I would come at the 8.30 morning. She would come at 8.30 in the morning. I would eat and leave.\n\n1:46:33 - Hasnain sayyed \nYou think he made any progress?\n\n1:47:04 - Hasnain sayyed \nI don't know.\n\n1:47:31 - Hasnain sayyed \nI think that's better actually.\n\n1:47:57 - Jorge Lewis \nBut I can't tell because my screen doesn't show me the correct things.\n\n1:48:15 - Jorge Lewis \nShowing you any errors? Yeah.\n\n1:48:24 - Hasnain sayyed \nI think we both are in different areas.\n\n1:48:30 - Hasnain sayyed \nTables, it's not as stable, I think.\n\n1:48:33 - Jorge Lewis \nYeah, I think month of dates.\n\n1:48:"}
02:07:09,705 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,706 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Hasnain / Jorge - Pair Programming \nThu, Aug 8, 2024\n\n0:03 - Jorge Lewis \nHey there, hi, how are you?\n\n0:07 - Hasnain sayyed \nGood, good, good. What about you?\n\n0:09 - Hasnain sayyed \nYeah, all good.\n\n0:12 - Hasnain sayyed \nHave you looked at the Figma file that I have created for brain project?\n\n0:18 - Jorge Lewis \nI did, I did, I did. I made some, so I went down a rabbit hole yesterday of just learning some stuff. Can you give me an idea of what\'s the flow for this ADAPT simulation, what kind of thing we have to work with?\n\n0:50 - Jorge Lewis \nYeah, exactly. So, so that\'s what we\'ll get into. So we\'ll kind of today in this, in this hour, I think probably we\'ll do an hour and a half. We\'ll kind of figure out what do we, what are the requirements? What do we require the system to accomplish? Um, and then we\'ll go into kind of making it.\n\n1:03 - Hasnain sayyed \nOkay. So are we creating in Figma or in like the code stuff?\n\n1:08 - Jorge Lewis \nSo we\'ll start with Figma and then we\'ll go into the code. Okay. It\'s only a span, maybe 10 minutes in the, in the Figma.\n\n1:15 - Hasnain sayyed \nOkay.\n\n1:17 - Jorge Lewis \nWe can take a quick look at your graph from yesterday. These are all of my thoughts from yesterday. I was just doing a lot of learning.\n\n1:38 - Jorge Lewis \nSo there\'s gonna be a big issue, which I put a message yesterday, but people didn\'t understand is that we\'re doing so much data. So every day, if you look at, I did some math here, every day it\'s 85,600 words. So that\'s not too much in terms of like, that\'s around 430 kilobytes, that\'s fine. But when you, put that into a vector database, it\'s about one gigabyte, that many words. And when you put in a knowledge graph, then it scales much, it\'s much harder to scale. So there\'s gonna be a big, there\'s gonna be that issue, it\'s gonna be too big. Like of course we can use really powerful servers and stuff, but it just can\'t scale. This is one gigabyte a day over, like for a knowledge graph, since it\'s more, it\'s harder, or it\'s a bigger, data structure, it\'s going to be much bigger. So like over 10 days, when you connect multiple nodes, like it\'s just, uh, I think it\'ll get out of hand. So we need to figure out that.\n\n2:44 - Hasnain sayyed \nYeah. Data is the main concern, like how we keep updated and you know, uh, how can we manage that as well? Because the data is changing each and every day. So we have to, yeah.\n\n2:57 - Jorge Lewis \nYeah. So, so I put a, I put a note here, an idea to have a longterm and a short term system where We have our long-term system that gets updated maybe once a day or once every so often. And then we have a short-term system which is very basic, like just simple rag maybe. The long-term can be a knowledge graph and the new one can be a vector database.\n\n3:20 - Jorge Lewis \nAnyways, yeah, so I did take a look at yours. Although some of the, I really like this pros and cons list, by the way. I didn\'t see this until after this morning. I was looking at the graph and then I saw that.\n\n3:34 - Jorge Lewis \nBut for the graph, I didn\'t totally understand all of the items.\n\n3:38 - Hasnain sayyed \nYeah, yeah. So let me get you. Will I explain like what\'s my idea behind?\n\n3:46 - Jorge Lewis \nWe can we can try to do that another time since I would like to do the the adapt evaluation system So after the adapt thing if I still have time then we can do that.\n\n3:54 - Unidentified Speaker \nOkay?\n\n3:54 - Jorge Lewis \nAll right, cool. Yeah, so let\'s let\'s get into so I\'ll go to Adapt project and I\'ll make a new design file a new fig gem board Or actually I\'ll go to the go to the adapt spec page the main one and then make a new page and All right, so I\'ll make a new page. All right, can you see the new page?\n\n4:40 - Jorge Lewis \nYes, I can.\n\n4:43 - Hasnain sayyed \nYeah, simulation, I can see.\n\n4:48 - Jorge Lewis \nSo what does this need to accomplish? Let\'s see. So we need it to generate synthetic conversations so that admins can How up to date are you on your DAD projects?\n\n5:32 - Hasnain sayyed \nLike I know the graph working like the check-in the chatting and Onboarding, yeah, the last onboarding I know a little bit.\n\n5:46 - Jorge Lewis \nOkay.\n\n5:49 - Jorge Lewis \nYeah, pretty much same. Okay, so pretty much, do you understand the vision of ADAPT, the goal?\n\n5:58 - Hasnain sayyed \nYeah, so it\'s kind of 10 weeks framework. It will ask the goal of the user, like whether he wants\n######################\nOutput:'}
02:07:09,706 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,709 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Hasnain / Jorge - Pair Programming \nThu, Aug 8, 2024\n\n0:03 - Jorge Lewis \nHey there, hi, how are you?\n\n0:07 - Hasnain sayyed \nGood, good, good. What about you?\n\n0:09 - Hasnain sayyed \nYeah, all good.\n\n0:12 - Hasnain sayyed \nHave you looked at the Figma file that I have created for brain project?\n\n0:18 - Jorge Lewis \nI did, I did, I did. I made some, so I went down a rabbit hole yesterday of just learning some stuff. Can you give me an idea of what's the flow for this ADAPT simulation, what kind of thing we have to work with?\n\n0:50 - Jorge Lewis \nYeah, exactly. So, so that's what we'll get into. So we'll kind of today in this, in this hour, I think probably we'll do an hour and a half. We'll kind of figure out what do we, what are the requirements? What do we require the system to accomplish? Um, and then we'll go into kind of making it.\n\n1:03 - Hasnain sayyed \nOkay. So are we creating in Figma or in like the code stuff?\n\n1:08 - Jorge Lewis \nSo we'll start with Figma and then we'll go into the code. Okay. It's only a span, maybe 10 minutes in the, in the Figma.\n\n1:15 - Hasnain sayyed \nOkay.\n\n1:17 - Jorge Lewis \nWe can take a quick look at your graph from yesterday. These are all of my thoughts from yesterday. I was just doing a lot of learning.\n\n1:38 - Jorge Lewis \nSo there's gonna be a big issue, which I put a message yesterday, but people didn't understand is that we're doing so much data. So every day, if you look at, I did some math here, every day it's 85,600 words. So that's not too much in terms of like, that's around 430 kilobytes, that's fine. But when you, put that into a vector database, it's about one gigabyte, that many words. And when you put in a knowledge graph, then it scales much, it's much harder to scale. So there's gonna be a big, there's gonna be that issue, it's gonna be too big. Like of course we can use really powerful servers and stuff, but it just can't scale. This is one gigabyte a day over, like for a knowledge graph, since it's more, it's harder, or it's a bigger, data structure, it's going to be much bigger. So like over 10 days, when you connect multiple nodes, like it's just, uh, I think it'll get out of hand. So we need to figure out that.\n\n2:44 - Hasnain sayyed \nYeah. Data is the main concern, like how we keep updated and you know, uh, how can we manage that as well? Because the data is changing each and every day. So we have to, yeah.\n\n2:57 - Jorge Lewis \nYeah. So, so I put a, I put a note here, an idea to have a longterm and a short term system where We have our long-term system that gets updated maybe once a day or once every so often. And then we have a short-term system which is very basic, like just simple rag maybe. The long-term can be a knowledge graph and the new one can be a vector database.\n\n3:20 - Jorge Lewis \nAnyways, yeah, so I did take a look at yours. Although some of the, I really like this pros and cons list, by the way. I didn't see this until after this morning. I was looking at the graph and then I saw that.\n\n3:34 - Jorge Lewis \nBut for the graph, I didn't totally understand all of the items.\n\n3:38 - Hasnain sayyed \nYeah, yeah. So let me get you. Will I explain like what's my idea behind?\n\n3:46 - Jorge Lewis \nWe can we can try to do that another time since I would like to do the the adapt evaluation system So after the adapt thing if I still have time then we can do that.\n\n3:54 - Unidentified Speaker \nOkay?\n\n3:54 - Jorge Lewis \nAll right, cool. Yeah, so let's let's get into so I'll go to Adapt project and I'll make a new design file a new fig gem board Or actually I'll go to the go to the adapt spec page the main one and then make a new page and All right, so I'll make a new page. All right, can you see the new page?\n\n4:40 - Jorge Lewis \nYes, I can.\n\n4:43 - Hasnain sayyed \nYeah, simulation, I can see.\n\n4:48 - Jorge Lewis \nSo what does this need to accomplish? Let's see. So we need it to generate synthetic conversations so that admins can How up to date are you on your DAD projects?\n\n5:32 - Hasnain sayyed \nLike I know the graph working like the check-in the chatting and Onboarding, yeah, the last onboarding I know a little bit.\n\n5:46 - Jorge Lewis \nOkay.\n\n5:49 - Jorge Lewis \nYeah, pretty much same. Okay, so pretty much, do you understand the vision of ADAPT, the goal?\n\n5:58 - Hasnain sayyed \nYeah, so it's kind of 10 weeks framework. It will ask the goal of the user, like whether he wants"}
02:07:09,737 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,739 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: But I can\'t tell because my screen doesn\'t show me the correct things.\n\n1:48:15 - Jorge Lewis \nShowing you any errors? Yeah.\n\n1:48:24 - Hasnain sayyed \nI think we both are in different areas.\n\n1:48:30 - Hasnain sayyed \nTables, it\'s not as stable, I think.\n\n1:48:33 - Jorge Lewis \nYeah, I think month of dates.\n\n1:48:36 - Unidentified Speaker \nMaybe.\n\n1:48:50 - Jorge Lewis \nBecause I mean, I\'m fairly certain that the one here should work.\n\n1:49:32 - Jorge Lewis \nCan you, it just, our screens are different. Yeah. Okay, let me, looks like we\'re going to disconnect it, I guess.\n\n1:49:52 - Hasnain sayyed \nI mean, why is tables erroring there?\n\n1:50:21 - Jorge Lewis \nHey, have you seen my daughter-in-law? Yes, she has gone to work.\n\n1:50:25 - Hasnain sayyed \nOh, really? Yes, she has gone to work. Why are you so late today? Are you busy? Yes, I am busy. Yes, I am busy.\n\n1:50:50 - Hasnain sayyed \nYes I have to go at 6.30.\n\n1:50:51 - Jorge Lewis \nI have to go I have to go at 6.30 I don\'t know why it\'s taking so long to load. I\'m gonna stop sharing my screen, my camera so that, to see if it can go faster.\n\n1:51:33 - Hasnain sayyed \nYeah. Yeah.\n\n1:51:37 - Jorge Lewis \nUm, but yeah, it\'s just super slow. Like I clicked it\'s joining collaboration session for quite a while. Okay. But, um, okay. So I\'ll, I\'ll just ask you to do it. So instead of, so take copy and paste everything after the question mark.\n\n1:51:57 - Hasnain sayyed \nThis one.\n\n1:51:58 - Jorge Lewis \nSo the second one should be a cool one.\n\n1:52:04 - Hasnain sayyed \nYeah. Yeah.\n\n1:52:12 - Jorge Lewis \nBut anyway, so copy copy those two so the table synthetic profile and tables profile the whole the whole thing Now it doesn\'t like it Oh no, there we go, cool. Is it airing for you?\n\n1:52:51 - Hasnain sayyed \nUnknown word, it\'s failing.\n\n1:52:56 - Jorge Lewis \nI think it\'s just slow to update.\n\n1:53:11 - Jorge Lewis \nCan you try... It looks like it\'s just confused. It\'s the same type of string, but it thinks it\'s something else. Like we just labeled it as something else. So all we need to do is just use the types that it needs. So we\'re synthetic here on the right-hand side of the equals is just is saying making it a string. But then we\'re just typing it as a tables synthetic profile. But for me, it\'s not giving any errors. But for you, it is. It\'s just saying it doesn\'t know what it is.\n\n1:53:59 - Hasnain sayyed \nIt\'s also getting error in the profile as well.\n\n1:54:09 - Hasnain sayyed \nI said maybe.\n\n1:54:41 - Jorge Lewis \nCan you push and then save all and push and I\'ll try to open it locally? Because it just feels like the IDE is not being very happy.\n\n1:54:54 - Hasnain sayyed \nSo should I push while creating a new branch?\n\n1:54:59 - Jorge Lewis \nYeah, yeah.\n\n1:55:03 - Jorge Lewis \nYeah, create a new branch.\n\n1:55:23 - Hasnain sayyed \nWhat should be the branch name?\n\n1:55:29 - Jorge Lewis \nWhat did you suggest?\n\n1:55:31 - Hasnain sayyed \nFeatures and synthetic profile.\n\n1:55:36 - Hasnain sayyed \nMaybe.\n\n1:55:36 - Jorge Lewis \nYeah, or yes.\n\n1:55:38 - Jorge Lewis \nYeah, whatever. That works.\n\n1:56:07 - Jorge Lewis \nYeah, I\'m now in.\n\n1:56:32 - Jorge Lewis \nYeah.\n\n1:56:33 - Unidentified Speaker \nYeah.\n\n1:56:58 - Jorge Lewis \nHave you generated the superbase types again?\n\n1:57:04 - Hasnain sayyed \nWhich one?\n\n1:57:06 - Hasnain sayyed \nThe superbase types.\n\n1:57:11 - Hasnain sayyed \nThe interface?\n\n1:57:18 - Jorge Lewis \nSo we made a new table. Have you generated the new types for it?\n\n1:57:23 - Hasnain sayyed \nYeah, I\'ve created the types over here.\n\n1:57:33 - Hasnain sayyed \nWhy it\'s not coming? Yeah. Yes, profiles. OK.\n\n1:58:10 - Hasnain sayyed \nYeah, I pushed on GitHub.\n\n1:58:13 - Unidentified Speaker \nOK.\n\n1:59:10 - Hasnain sayyed \nor else we can make this dynamic afterwards like just.\n\n1:59:46 - Jorge Lewis \nWhy is there so many branches open?\n\n2:00:05 - Jorge Lewis \nUh, your,\n######################\nOutput:'}
02:07:09,739 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,742 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "But I can't tell because my screen doesn't show me the correct things.\n\n1:48:15 - Jorge Lewis \nShowing you any errors? Yeah.\n\n1:48:24 - Hasnain sayyed \nI think we both are in different areas.\n\n1:48:30 - Hasnain sayyed \nTables, it's not as stable, I think.\n\n1:48:33 - Jorge Lewis \nYeah, I think month of dates.\n\n1:48:36 - Unidentified Speaker \nMaybe.\n\n1:48:50 - Jorge Lewis \nBecause I mean, I'm fairly certain that the one here should work.\n\n1:49:32 - Jorge Lewis \nCan you, it just, our screens are different. Yeah. Okay, let me, looks like we're going to disconnect it, I guess.\n\n1:49:52 - Hasnain sayyed \nI mean, why is tables erroring there?\n\n1:50:21 - Jorge Lewis \nHey, have you seen my daughter-in-law? Yes, she has gone to work.\n\n1:50:25 - Hasnain sayyed \nOh, really? Yes, she has gone to work. Why are you so late today? Are you busy? Yes, I am busy. Yes, I am busy.\n\n1:50:50 - Hasnain sayyed \nYes I have to go at 6.30.\n\n1:50:51 - Jorge Lewis \nI have to go I have to go at 6.30 I don't know why it's taking so long to load. I'm gonna stop sharing my screen, my camera so that, to see if it can go faster.\n\n1:51:33 - Hasnain sayyed \nYeah. Yeah.\n\n1:51:37 - Jorge Lewis \nUm, but yeah, it's just super slow. Like I clicked it's joining collaboration session for quite a while. Okay. But, um, okay. So I'll, I'll just ask you to do it. So instead of, so take copy and paste everything after the question mark.\n\n1:51:57 - Hasnain sayyed \nThis one.\n\n1:51:58 - Jorge Lewis \nSo the second one should be a cool one.\n\n1:52:04 - Hasnain sayyed \nYeah. Yeah.\n\n1:52:12 - Jorge Lewis \nBut anyway, so copy copy those two so the table synthetic profile and tables profile the whole the whole thing Now it doesn't like it Oh no, there we go, cool. Is it airing for you?\n\n1:52:51 - Hasnain sayyed \nUnknown word, it's failing.\n\n1:52:56 - Jorge Lewis \nI think it's just slow to update.\n\n1:53:11 - Jorge Lewis \nCan you try... It looks like it's just confused. It's the same type of string, but it thinks it's something else. Like we just labeled it as something else. So all we need to do is just use the types that it needs. So we're synthetic here on the right-hand side of the equals is just is saying making it a string. But then we're just typing it as a tables synthetic profile. But for me, it's not giving any errors. But for you, it is. It's just saying it doesn't know what it is.\n\n1:53:59 - Hasnain sayyed \nIt's also getting error in the profile as well.\n\n1:54:09 - Hasnain sayyed \nI said maybe.\n\n1:54:41 - Jorge Lewis \nCan you push and then save all and push and I'll try to open it locally? Because it just feels like the IDE is not being very happy.\n\n1:54:54 - Hasnain sayyed \nSo should I push while creating a new branch?\n\n1:54:59 - Jorge Lewis \nYeah, yeah.\n\n1:55:03 - Jorge Lewis \nYeah, create a new branch.\n\n1:55:23 - Hasnain sayyed \nWhat should be the branch name?\n\n1:55:29 - Jorge Lewis \nWhat did you suggest?\n\n1:55:31 - Hasnain sayyed \nFeatures and synthetic profile.\n\n1:55:36 - Hasnain sayyed \nMaybe.\n\n1:55:36 - Jorge Lewis \nYeah, or yes.\n\n1:55:38 - Jorge Lewis \nYeah, whatever. That works.\n\n1:56:07 - Jorge Lewis \nYeah, I'm now in.\n\n1:56:32 - Jorge Lewis \nYeah.\n\n1:56:33 - Unidentified Speaker \nYeah.\n\n1:56:58 - Jorge Lewis \nHave you generated the superbase types again?\n\n1:57:04 - Hasnain sayyed \nWhich one?\n\n1:57:06 - Hasnain sayyed \nThe superbase types.\n\n1:57:11 - Hasnain sayyed \nThe interface?\n\n1:57:18 - Jorge Lewis \nSo we made a new table. Have you generated the new types for it?\n\n1:57:23 - Hasnain sayyed \nYeah, I've created the types over here.\n\n1:57:33 - Hasnain sayyed \nWhy it's not coming? Yeah. Yes, profiles. OK.\n\n1:58:10 - Hasnain sayyed \nYeah, I pushed on GitHub.\n\n1:58:13 - Unidentified Speaker \nOK.\n\n1:59:10 - Hasnain sayyed \nor else we can make this dynamic afterwards like just.\n\n1:59:46 - Jorge Lewis \nWhy is there so many branches open?\n\n2:00:05 - Jorge Lewis \nUh, your,"}
02:07:09,966 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:09,968 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Why it\'s not coming? Yeah. Yes, profiles. OK.\n\n1:58:10 - Hasnain sayyed \nYeah, I pushed on GitHub.\n\n1:58:13 - Unidentified Speaker \nOK.\n\n1:59:10 - Hasnain sayyed \nor else we can make this dynamic afterwards like just.\n\n1:59:46 - Jorge Lewis \nWhy is there so many branches open?\n\n2:00:05 - Jorge Lewis \nUh, your, your branch, the branch name should not be with an S feature and then slash. That\'s why I couldn\'t, I was trying to check it out, check out, get checkout, but it wasn\'t finding it.\n\n2:00:20 - Hasnain sayyed \nOh.\n\n2:00:26 - Jorge Lewis \nUm, Yeah, so my thing doesn\'t error. Does your thing still error with the type? Yes. Try restarting your IDE.\n\n2:01:31 - Jorge Lewis \nNo, it\'s a very old name, so I shouldn\'t...\n\n2:01:36 - Hasnain sayyed \nof extension which gets an error if my spelling mistake is there, so.\n\n2:01:47 - Hasnain sayyed \nOh, so is that what\'s erring?\n\n2:01:49 - Hasnain sayyed \nNo, no, it\'s not the extension one.\n\n2:01:53 - Jorge Lewis \nOh, there\'s two. TypeString is not assignable to type.\n\n2:02:02 - Jorge Lewis \nOh, wait, maybe...\n\n2:02:07 - Jorge Lewis \nUh, do. So I\'m trying to figure out why I\'m not getting those errors.\n\n2:02:17 - Jorge Lewis \nUm, but try, try the string. So go to the strings and do as tables and then.\n\n2:02:26 - Jorge Lewis \nWhere in the data type.\n\n2:02:27 - Jorge Lewis \nSo, so when you\'re setting the screen, no, no. So right where you are, right where you are back, you want to cast the string to the type. So. Synthetic underscore profiles as, and then tables synthetic profiles. No, no, no, up, up, on the string, on the string.\n\n2:02:46 - Jorge Lewis \nSo the variable, the string, synthetic profiles, the string.\n\n2:02:50 - Unidentified Speaker \nOkay.\n\n2:02:52 - Jorge Lewis \nDown, yeah.\n\n2:02:54 - Jorge Lewis \nYeah, so we want to cast it as the table.\n\n2:03:03 - Jorge Lewis \nCannot, there\'s no type string to type.\n\n2:03:18 - Jorge Lewis \nWait a minute. Why is...\n\n2:03:30 - Hasnain sayyed \nIt\'s also getting type string is not assignable to the row.\n\n2:03:32 - Unidentified Speaker \nAll right.\n\n2:03:36 - Jorge Lewis \nUm, are we spent enough time on this? So I had to do, um, and make, and just use the hard coded one.\n\n2:03:46 - Jorge Lewis \nI\'m going to use the rest of your beer book.\n\n2:04:36 - Unidentified Speaker \nOh, my God.\n\n2:05:27 - Unidentified Speaker \nHello.\n\n2:05:30 - Hasnain sayyed \nYeah, I\'m just coming in two minutes for washroom.\n\n2:06:25 - Unidentified Speaker \nBye.\n\n2:07:37 - Hasnain sayyed \nWelcome back.\n\n2:07:44 - Jorge Lewis \nSo is it all done now?\n\n2:07:47 - Unidentified Speaker \nYeah.\n\n2:07:47 - Hasnain sayyed \nIs that problem solved?\n\n2:07:48 - Hasnain sayyed \nWell, which problem? All right, cool.\n\n2:07:53 - Jorge Lewis \nOh, yeah. The type.\n\n2:07:54 - Unidentified Speaker \nYeah.\n\n2:07:56 - Jorge Lewis \nOh, wait, no, no, it\'s not solved. So the problem was that the problem is that we need to access either the synthetic profile or the user profile right there. We\'re only accessing the profile. We need, so the solution is to just move. So take a look. Let me share my screen.\n\n2:08:22 - Jorge Lewis \nLike the whole world, what we\'re solving, I feel like you kind of tunnel vision too much on what we\'re on the typing issue. The, what we\'re trying to do here is, is set this profile to either be from the synthetic profile or the profile list. That\'s what we were doing up here. So we were trying to set up. We\'re trying to do this and make it a variable, but instead we\'re just going to copy this and then paste it here. This profile here will either be from the synthetic profiles or the profiles.\n\n2:09:01 - Hasnain sayyed \nOkay. Well, I thought it can be.\n\n2:09:18 - Jorge Lewis \nOne thing we need to be careful of that maybe is that if there\'s any properties of these two that if profiles has something that synthetic profiles doesn\'t, then there might be an error at some point. I don\'t think so.\n\n2:09:34 - Hasnain sayyed \nBecause it has copy paste.\n\n2:09:39 - Hasnain sayyed \nIt\'s the same. I copy pasted the same.\n\n2:09:42 - Hasnain sayyed \nIt has all of the\n######################\nOutput:'}
02:07:09,969 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:09,972 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Why it's not coming? Yeah. Yes, profiles. OK.\n\n1:58:10 - Hasnain sayyed \nYeah, I pushed on GitHub.\n\n1:58:13 - Unidentified Speaker \nOK.\n\n1:59:10 - Hasnain sayyed \nor else we can make this dynamic afterwards like just.\n\n1:59:46 - Jorge Lewis \nWhy is there so many branches open?\n\n2:00:05 - Jorge Lewis \nUh, your, your branch, the branch name should not be with an S feature and then slash. That's why I couldn't, I was trying to check it out, check out, get checkout, but it wasn't finding it.\n\n2:00:20 - Hasnain sayyed \nOh.\n\n2:00:26 - Jorge Lewis \nUm, Yeah, so my thing doesn't error. Does your thing still error with the type? Yes. Try restarting your IDE.\n\n2:01:31 - Jorge Lewis \nNo, it's a very old name, so I shouldn't...\n\n2:01:36 - Hasnain sayyed \nof extension which gets an error if my spelling mistake is there, so.\n\n2:01:47 - Hasnain sayyed \nOh, so is that what's erring?\n\n2:01:49 - Hasnain sayyed \nNo, no, it's not the extension one.\n\n2:01:53 - Jorge Lewis \nOh, there's two. TypeString is not assignable to type.\n\n2:02:02 - Jorge Lewis \nOh, wait, maybe...\n\n2:02:07 - Jorge Lewis \nUh, do. So I'm trying to figure out why I'm not getting those errors.\n\n2:02:17 - Jorge Lewis \nUm, but try, try the string. So go to the strings and do as tables and then.\n\n2:02:26 - Jorge Lewis \nWhere in the data type.\n\n2:02:27 - Jorge Lewis \nSo, so when you're setting the screen, no, no. So right where you are, right where you are back, you want to cast the string to the type. So. Synthetic underscore profiles as, and then tables synthetic profiles. No, no, no, up, up, on the string, on the string.\n\n2:02:46 - Jorge Lewis \nSo the variable, the string, synthetic profiles, the string.\n\n2:02:50 - Unidentified Speaker \nOkay.\n\n2:02:52 - Jorge Lewis \nDown, yeah.\n\n2:02:54 - Jorge Lewis \nYeah, so we want to cast it as the table.\n\n2:03:03 - Jorge Lewis \nCannot, there's no type string to type.\n\n2:03:18 - Jorge Lewis \nWait a minute. Why is...\n\n2:03:30 - Hasnain sayyed \nIt's also getting type string is not assignable to the row.\n\n2:03:32 - Unidentified Speaker \nAll right.\n\n2:03:36 - Jorge Lewis \nUm, are we spent enough time on this? So I had to do, um, and make, and just use the hard coded one.\n\n2:03:46 - Jorge Lewis \nI'm going to use the rest of your beer book.\n\n2:04:36 - Unidentified Speaker \nOh, my God.\n\n2:05:27 - Unidentified Speaker \nHello.\n\n2:05:30 - Hasnain sayyed \nYeah, I'm just coming in two minutes for washroom.\n\n2:06:25 - Unidentified Speaker \nBye.\n\n2:07:37 - Hasnain sayyed \nWelcome back.\n\n2:07:44 - Jorge Lewis \nSo is it all done now?\n\n2:07:47 - Unidentified Speaker \nYeah.\n\n2:07:47 - Hasnain sayyed \nIs that problem solved?\n\n2:07:48 - Hasnain sayyed \nWell, which problem? All right, cool.\n\n2:07:53 - Jorge Lewis \nOh, yeah. The type.\n\n2:07:54 - Unidentified Speaker \nYeah.\n\n2:07:56 - Jorge Lewis \nOh, wait, no, no, it's not solved. So the problem was that the problem is that we need to access either the synthetic profile or the user profile right there. We're only accessing the profile. We need, so the solution is to just move. So take a look. Let me share my screen.\n\n2:08:22 - Jorge Lewis \nLike the whole world, what we're solving, I feel like you kind of tunnel vision too much on what we're on the typing issue. The, what we're trying to do here is, is set this profile to either be from the synthetic profile or the profile list. That's what we were doing up here. So we were trying to set up. We're trying to do this and make it a variable, but instead we're just going to copy this and then paste it here. This profile here will either be from the synthetic profiles or the profiles.\n\n2:09:01 - Hasnain sayyed \nOkay. Well, I thought it can be.\n\n2:09:18 - Jorge Lewis \nOne thing we need to be careful of that maybe is that if there's any properties of these two that if profiles has something that synthetic profiles doesn't, then there might be an error at some point. I don't think so.\n\n2:09:34 - Hasnain sayyed \nBecause it has copy paste.\n\n2:09:39 - Hasnain sayyed \nIt's the same. I copy pasted the same.\n\n2:09:42 - Hasnain sayyed \nIt has all of the"}
02:07:10,27 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,29 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: maybe is that if there\'s any properties of these two that if profiles has something that synthetic profiles doesn\'t, then there might be an error at some point. I don\'t think so.\n\n2:09:34 - Hasnain sayyed \nBecause it has copy paste.\n\n2:09:39 - Hasnain sayyed \nIt\'s the same. I copy pasted the same.\n\n2:09:42 - Hasnain sayyed \nIt has all of the properties.\n\n2:09:44 - Hasnain sayyed \nYeah.\n\n2:09:46 - Jorge Lewis \nYeah. Cool. All right. So I\'ll just push this in.\n\n2:10:02 - Jorge Lewis \nAll right, go ahead and pull. And yeah, I\'m a hop off. It\'s been a great session. I think very productive.\n\n2:10:08 - Hasnain sayyed \nI think we learned a lot.\n\n2:10:11 - Jorge Lewis \nSo for now, I guess just keep working on this and then, um, and then, yeah, keep me updated. So it\'s clear what the objectives are, right. And how we should move forward with this.\n\n2:10:24 - Hasnain sayyed \nYeah. So for now, uh, we will be using the loop, right. Uh, for, uh, iterating for the 10 times.\n\n2:10:32 - Hasnain sayyed \nOr should I create a function? OK.\n\n2:10:38 - Jorge Lewis \nJust do that for now. And then once we can see something on the screen, then we\'ll move forward. We need to do it step by step, because it\'s a very big issue that most new developers have, is that they try to make the whole application And then it takes them three months and within that three months they never finish something that they can test. Not test as in make unit tests, not test as in no errors. Test as in see the experience so it\'s very important that we that when we\'re making these projects and you\'re developing is you focus on very small things that you can test as an end and you so in this case what we can test as an end user the smallest thing is we can see a AI the synthetic user having a conversation with a chatbot that\'s all we need like we all we need to see is they can send messages to each other basic that\'s it hmm And then after we can see that, then we work on expanding it little by little. But it\'s very important that we see the progress through the testing that like with the end user.\n\n2:11:50 - Hasnain sayyed \nOkay. Okay. I will work on this and make it as functional as a basic level and then we can move step by step.\n\n2:11:58 - Jorge Lewis \nAll right, cool.\n\n2:12:01 - Jorge Lewis \nUm, I think you\'ll have to work with, um, I think you\'ll have to work with one of the front-end developers to get the front-end for this done. So whether Will or Nazif, kind of bring them both in a call and ask and demonstrate or tell them, hey, we have this new task. How can we go about working on this? Check who\'s busy or who\'s not.\n\n2:12:27 - Hasnain sayyed \nYeah. Okay. I will ask them right now.\n\n2:12:33 - Jorge Lewis \ndoing this programming session. Looking forward to the ones to come. I think it\'s a great way to keep growing.\n\n2:12:45 - Hasnain sayyed \nYeah.\n\n2:12:48 - Hasnain sayyed \nCorrect then. I will update you once I will get our achieving done. Okay.\n\n2:12:55 - Jorge Lewis \nAll right. Cool. All right. Thanks.\n\n2:12:58 - Unidentified Speaker \nThanks. Bye.\n######################\nOutput:'}
02:07:10,31 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,34 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "maybe is that if there's any properties of these two that if profiles has something that synthetic profiles doesn't, then there might be an error at some point. I don't think so.\n\n2:09:34 - Hasnain sayyed \nBecause it has copy paste.\n\n2:09:39 - Hasnain sayyed \nIt's the same. I copy pasted the same.\n\n2:09:42 - Hasnain sayyed \nIt has all of the properties.\n\n2:09:44 - Hasnain sayyed \nYeah.\n\n2:09:46 - Jorge Lewis \nYeah. Cool. All right. So I'll just push this in.\n\n2:10:02 - Jorge Lewis \nAll right, go ahead and pull. And yeah, I'm a hop off. It's been a great session. I think very productive.\n\n2:10:08 - Hasnain sayyed \nI think we learned a lot.\n\n2:10:11 - Jorge Lewis \nSo for now, I guess just keep working on this and then, um, and then, yeah, keep me updated. So it's clear what the objectives are, right. And how we should move forward with this.\n\n2:10:24 - Hasnain sayyed \nYeah. So for now, uh, we will be using the loop, right. Uh, for, uh, iterating for the 10 times.\n\n2:10:32 - Hasnain sayyed \nOr should I create a function? OK.\n\n2:10:38 - Jorge Lewis \nJust do that for now. And then once we can see something on the screen, then we'll move forward. We need to do it step by step, because it's a very big issue that most new developers have, is that they try to make the whole application And then it takes them three months and within that three months they never finish something that they can test. Not test as in make unit tests, not test as in no errors. Test as in see the experience so it's very important that we that when we're making these projects and you're developing is you focus on very small things that you can test as an end and you so in this case what we can test as an end user the smallest thing is we can see a AI the synthetic user having a conversation with a chatbot that's all we need like we all we need to see is they can send messages to each other basic that's it hmm And then after we can see that, then we work on expanding it little by little. But it's very important that we see the progress through the testing that like with the end user.\n\n2:11:50 - Hasnain sayyed \nOkay. Okay. I will work on this and make it as functional as a basic level and then we can move step by step.\n\n2:11:58 - Jorge Lewis \nAll right, cool.\n\n2:12:01 - Jorge Lewis \nUm, I think you'll have to work with, um, I think you'll have to work with one of the front-end developers to get the front-end for this done. So whether Will or Nazif, kind of bring them both in a call and ask and demonstrate or tell them, hey, we have this new task. How can we go about working on this? Check who's busy or who's not.\n\n2:12:27 - Hasnain sayyed \nYeah. Okay. I will ask them right now.\n\n2:12:33 - Jorge Lewis \ndoing this programming session. Looking forward to the ones to come. I think it's a great way to keep growing.\n\n2:12:45 - Hasnain sayyed \nYeah.\n\n2:12:48 - Hasnain sayyed \nCorrect then. I will update you once I will get our achieving done. Okay.\n\n2:12:55 - Jorge Lewis \nAll right. Cool. All right. Thanks.\n\n2:12:58 - Unidentified Speaker \nThanks. Bye."}
02:07:10,58 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,64 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Congent Vision & Mission Workshop \nWed, Aug 28, 2024\n\n0:01 - Jorge Lewis \nOkay, so let me share my screen so that when someone is watching this, they understand what I\'m talking about. All right.\n\n0:23 - Jorge Lewis \nOkay, so let\'s start from the top. So this is the division mission workshop for content.\n\n0:33 - Jorge Lewis \nLet\'s make sure we\'re on the same page. So today we\'re just going to align on those two things. Here\'s a quick example of what the vision and mission are. The mission is explaining why are we trying to build this? What problem is it solving? And then what is the solution? So building an online platform to solve this problem. So yeah, so let\'s get into the mission. So with a mission, what we\'ll do first is have me say off the top of my head, the problem we\'re trying to solve.\n\n1:06 - Jorge Lewis \nSo, PO, project owner, will explain how the idea behind the project was conceived, what problem arised that gave him the idea of IntelliO.\n\n1:20 - Jorge Lewis \nOkay, so the project was conceived because the past two weeks or three weeks I have spent a lot of effort and time into writing, trying to write content, but haven\'t gotten anywhere.\n\n1:38 - Jorge Lewis \nNumber one, I like writing, I like that aspect, but it just takes too much time to write things on paper or on Notion or whatever, to put things down.\n\n1:51 - Jorge Lewis \nIt takes a lot of mental effort and time to get those onto paper and then into a script or whatever.\n\n1:59 - Jorge Lewis \nSo like I\'ve tried writing content and just hasn\'t worked out I have time for it, but I just I\'m I guess I\'m It\'s too much effort I guess you could say I have better things to do than writing content\n\n2:11 - Biwas bhandari \nor at least yeah But if content yeah sometimes you feel like, okay, I want to write about this, but you cannot start writing in the copy about all the scripts.\n\n2:26 - Jorge Lewis \nIt\'s a form of writer\'s block, but also, yeah. Kind of procrastination, but it\'s like I have better things to do. I\'m not I\'m gonna save this for later. So procrastination Okay, so with that said let\'s take just two minutes to notes our interpretation of what I just said and then What the mission is I think you\'ve already done it, but if you want to try again Yeah, I think my one links with your Alright, I\'ve got mine.\n\n3:23 - Biwas bhandari \nOkay, yeah. I finished mine too.\n\n3:26 - Jorge Lewis \nAlright, so Marina, why is yours the same color?\n\n3:30 - Biwas bhandari \nLet me change it.\n\n3:34 - Biwas bhandari \nOkay, thanks.\n\n3:35 - Jorge Lewis \nOkay, so let\'s read yours. So the project owner will usually read his out first, I believe. Reduce time and efforts required to write content. So that\'s what I put. And for yours, the mission of the product is to help make content and brainstorm about it. The problem is, is it takes a lot of time to brainstorm about the content I\'m making and the current AI tools congeneration is not it. Okay, that\'s perfect. Your one\'s great.\n\n4:03 - Biwas bhandari \nNo, yours one is like my summarized form.\n\n4:07 - Jorge Lewis \nYeah, so one thing we noticed in the last one when we did this with Jonas was his was too many things. So...\n\n4:27 - Jorge Lewis \nOkay, so we\'ll take your one. Let me copy it. And then what we do is we bring it here, and we get a new note, and we put the mission.\n\n4:41 - Jorge Lewis \nAnd under, the mission. Okay, so we can shorten here. So the mission of the product is to help make content um creation and ideation so ideation is the brainstorm part um faster and or is to make it easier so faster and less mental effort okay because that\'s that\'s the problem okay So this part\'s a good point. The current AI tools for content generation is not good, but I don\'t think it doesn\'t belong in the mission. So I\'ll just bring that over and paste it somewhere here.\n\n5:40 - Jorge Lewis \nOkay, so the mission of the product is, so we don\'t have to say this, so help. So, or not help, just make content creation, content creation and ideation, Why is it saying ideation is not a word? I think it is. Yeah, it is. It\'s the formation of ideas or concepts, but all right then, buddy. Make content creation and ideation easier, faster by requiring... Okay, just by making it faster and require less mental effort. Okay, cool.\n\n6:23 - Jorge Lewis \nNow on to the vision. So P.O.\n\n6:36 - Jorge Lewis \nAfterwards, P.O. And then P.O.\n\n6:43 - Jorge Lewis \nSo P.O. Will give a high level explanation of his idea and vision of the project. Afterwards, I\'ll invite everyone to write down their motivation behind working on the project.\n\n6:56 - Biwas bhandari \nCan I invite everyone? What do you mean?\n\n7:04 - Jorge Lewis \nI\'m just going to tell everyone. All right, everyone, let\'s do this now.\n\n7:08 - Jorge Lewis \nAfter everyone is done, we\'ll collaborate, collaboratively compare all\n######################\nOutput:'}
02:07:10,64 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,69 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Congent Vision & Mission Workshop \nWed, Aug 28, 2024\n\n0:01 - Jorge Lewis \nOkay, so let me share my screen so that when someone is watching this, they understand what I'm talking about. All right.\n\n0:23 - Jorge Lewis \nOkay, so let's start from the top. So this is the division mission workshop for content.\n\n0:33 - Jorge Lewis \nLet's make sure we're on the same page. So today we're just going to align on those two things. Here's a quick example of what the vision and mission are. The mission is explaining why are we trying to build this? What problem is it solving? And then what is the solution? So building an online platform to solve this problem. So yeah, so let's get into the mission. So with a mission, what we'll do first is have me say off the top of my head, the problem we're trying to solve.\n\n1:06 - Jorge Lewis \nSo, PO, project owner, will explain how the idea behind the project was conceived, what problem arised that gave him the idea of IntelliO.\n\n1:20 - Jorge Lewis \nOkay, so the project was conceived because the past two weeks or three weeks I have spent a lot of effort and time into writing, trying to write content, but haven't gotten anywhere.\n\n1:38 - Jorge Lewis \nNumber one, I like writing, I like that aspect, but it just takes too much time to write things on paper or on Notion or whatever, to put things down.\n\n1:51 - Jorge Lewis \nIt takes a lot of mental effort and time to get those onto paper and then into a script or whatever.\n\n1:59 - Jorge Lewis \nSo like I've tried writing content and just hasn't worked out I have time for it, but I just I'm I guess I'm It's too much effort I guess you could say I have better things to do than writing content\n\n2:11 - Biwas bhandari \nor at least yeah But if content yeah sometimes you feel like, okay, I want to write about this, but you cannot start writing in the copy about all the scripts.\n\n2:26 - Jorge Lewis \nIt's a form of writer's block, but also, yeah. Kind of procrastination, but it's like I have better things to do. I'm not I'm gonna save this for later. So procrastination Okay, so with that said let's take just two minutes to notes our interpretation of what I just said and then What the mission is I think you've already done it, but if you want to try again Yeah, I think my one links with your Alright, I've got mine.\n\n3:23 - Biwas bhandari \nOkay, yeah. I finished mine too.\n\n3:26 - Jorge Lewis \nAlright, so Marina, why is yours the same color?\n\n3:30 - Biwas bhandari \nLet me change it.\n\n3:34 - Biwas bhandari \nOkay, thanks.\n\n3:35 - Jorge Lewis \nOkay, so let's read yours. So the project owner will usually read his out first, I believe. Reduce time and efforts required to write content. So that's what I put. And for yours, the mission of the product is to help make content and brainstorm about it. The problem is, is it takes a lot of time to brainstorm about the content I'm making and the current AI tools congeneration is not it. Okay, that's perfect. Your one's great.\n\n4:03 - Biwas bhandari \nNo, yours one is like my summarized form.\n\n4:07 - Jorge Lewis \nYeah, so one thing we noticed in the last one when we did this with Jonas was his was too many things. So...\n\n4:27 - Jorge Lewis \nOkay, so we'll take your one. Let me copy it. And then what we do is we bring it here, and we get a new note, and we put the mission.\n\n4:41 - Jorge Lewis \nAnd under, the mission. Okay, so we can shorten here. So the mission of the product is to help make content um creation and ideation so ideation is the brainstorm part um faster and or is to make it easier so faster and less mental effort okay because that's that's the problem okay So this part's a good point. The current AI tools for content generation is not good, but I don't think it doesn't belong in the mission. So I'll just bring that over and paste it somewhere here.\n\n5:40 - Jorge Lewis \nOkay, so the mission of the product is, so we don't have to say this, so help. So, or not help, just make content creation, content creation and ideation, Why is it saying ideation is not a word? I think it is. Yeah, it is. It's the formation of ideas or concepts, but all right then, buddy. Make content creation and ideation easier, faster by requiring... Okay, just by making it faster and require less mental effort. Okay, cool.\n\n6:23 - Jorge Lewis \nNow on to the vision. So P.O.\n\n6:36 - Jorge Lewis \nAfterwards, P.O. And then P.O.\n\n6:43 - Jorge Lewis \nSo P.O. Will give a high level explanation of his idea and vision of the project. Afterwards, I'll invite everyone to write down their motivation behind working on the project.\n\n6:56 - Biwas bhandari \nCan I invite everyone? What do you mean?\n\n7:04 - Jorge Lewis \nI'm just going to tell everyone. All right, everyone, let's do this now.\n\n7:08 - Jorge Lewis \nAfter everyone is done, we'll collaborate, collaboratively compare all"}
02:07:10,138 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,140 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: .O. Will give a high level explanation of his idea and vision of the project. Afterwards, I\'ll invite everyone to write down their motivation behind working on the project.\n\n6:56 - Biwas bhandari \nCan I invite everyone? What do you mean?\n\n7:04 - Jorge Lewis \nI\'m just going to tell everyone. All right, everyone, let\'s do this now.\n\n7:08 - Jorge Lewis \nAfter everyone is done, we\'ll collaborate, collaboratively compare all the ideas. Yeah. Okay. So. The vision, so this is really, this is great when you have a lot of like more than a few people. When it\'s two people, it\'s, it\'s very fast and there\'s only two things. So it\'s not too much to worry about, which is why I asked Jonas if he could join, because he could give more input. So.\n\n7:33 - Jorge Lewis \nOkay. So the idea, so what I imagine this is, and the vision is kind of the end goal of this entire project. It\'s not a It can be like the very end goal. So for example, for, for adapt, it could be the vision is a chatbot can help coach the user to build habits.\n\n8:04 - Biwas bhandari \nYeah.\n\n8:06 - Jorge Lewis \nTo build good habits. I think that\'s it. That\'s the vision. A chatbot building good habits for users.\n\n8:13 - Jorge Lewis \nYeah. How we do that, there\'s a lot of different ways, but that\'s the end goal. The chapel will help users build habits. So for this one, what I think, what I like this project to become, well, is I can sit, so I\'m going to kind of just draw a story. So I want to wake up, have my coffee. And this is when I usually like to write or do my creative things. Cause I\'m just, I\'ve got my coffee. It\'s morning. I want to be in the chair and just.\n\n8:41 - Jorge Lewis \nlike have content there that I just refine. So content is generated and I can refine it. And that content is something I agree with. It\'s in the style that I like, It doesn\'t sound like AI at all. And to convert it into an actual post or script, it\'s not a lot of work. Meaning I only have to change some small things. It doesn\'t have to be perfect, of course. Well, I mean, of course Google is perfect. I ask it to make something about a topic and it\'ll tell me, it\'ll run me through a process to create the content. For example, I want to make a video about the best way to build a SaaS as a non-technical person.\n\n9:33 - Jorge Lewis \nI want it to know what my opinions are on that whole topic. And if it doesn\'t, I want it to ask me, okay, what do you think about this? What about this? What about this? To build a knowledge base around this whole topic so that it can understand how I would write this. Because a lot of content is so opinion-based. Building fact-based content is very easy. You can research things and find facts.\n\n9:59 - Jorge Lewis \nWhat people are after for content is experienced people that have done it before that can use their experience to provide advice. And I would say I have some experience that I want to be sharing. Instead of just kind of regurgitating everything like, oh, you should raise funding and then you should do this. Like kind of the very basic things. I don\'t want it to be that. I don\'t want this project to be a regurgitation of a Google search. I don\'t want it to kind of search Google and then print whatever it finds.\n\n10:36 - Unidentified Speaker \nYeah.\n\n10:37 - Jorge Lewis \nYeah.\n\n10:38 - Biwas bhandari \nI can keep going, but there\'s, um, But that can be done in normal AI chatbots like chatGPT. You can just ask, okay, I want to do this and it will reply instantly. So what\'s the selling point of this product?\n\n11:00 - Biwas bhandari \nUm, it\'s like, it\'s like, why would I come to these, uh, the content app instead of going to chatGPT?\n\n11:09 - Jorge Lewis \nSo, so this, this right.\n\n11:14 - Jorge Lewis \nI want this project to write your content, not chat, UBT\'s content or not the internet\'s content. I want it to be based off of the, the, the user. So the project\'s going to need to know a lot about the user, whether it can ask questions or it can take some input, wink, wink transcript. Yeah.\n\n11:38 - Jorge Lewis \nYeah, so I have a lot of ideas and like features, ways we can do this, but I think the vision aspect of this is supposed to be very high level. So I think hopefully I\'ve done an okay job at keeping it high level. Let\'s go into our corners and rights.\n\n11:57 - Biwas bhandari \nSo the vision?\n\n11:58 - Jorge Lewis \nYeah, the vision.\n\n11:59 - Unidentified Speaker \nOkay.\n\n12:10 - Biwas bhandari \nvision PR plus PC don\'t understand All right, I\'m done. I want to understand and create, okay. All right.\n\n13:24 - Jorge Lewis \nAll right, so I\'ll go ahead and read mine first. A platform that writes content as if it were me, not only the style but also the opinions and experiences, leading to no necessary\n######################\nOutput:'}
02:07:10,141 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,144 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ".O. Will give a high level explanation of his idea and vision of the project. Afterwards, I'll invite everyone to write down their motivation behind working on the project.\n\n6:56 - Biwas bhandari \nCan I invite everyone? What do you mean?\n\n7:04 - Jorge Lewis \nI'm just going to tell everyone. All right, everyone, let's do this now.\n\n7:08 - Jorge Lewis \nAfter everyone is done, we'll collaborate, collaboratively compare all the ideas. Yeah. Okay. So. The vision, so this is really, this is great when you have a lot of like more than a few people. When it's two people, it's, it's very fast and there's only two things. So it's not too much to worry about, which is why I asked Jonas if he could join, because he could give more input. So.\n\n7:33 - Jorge Lewis \nOkay. So the idea, so what I imagine this is, and the vision is kind of the end goal of this entire project. It's not a It can be like the very end goal. So for example, for, for adapt, it could be the vision is a chatbot can help coach the user to build habits.\n\n8:04 - Biwas bhandari \nYeah.\n\n8:06 - Jorge Lewis \nTo build good habits. I think that's it. That's the vision. A chatbot building good habits for users.\n\n8:13 - Jorge Lewis \nYeah. How we do that, there's a lot of different ways, but that's the end goal. The chapel will help users build habits. So for this one, what I think, what I like this project to become, well, is I can sit, so I'm going to kind of just draw a story. So I want to wake up, have my coffee. And this is when I usually like to write or do my creative things. Cause I'm just, I've got my coffee. It's morning. I want to be in the chair and just.\n\n8:41 - Jorge Lewis \nlike have content there that I just refine. So content is generated and I can refine it. And that content is something I agree with. It's in the style that I like, It doesn't sound like AI at all. And to convert it into an actual post or script, it's not a lot of work. Meaning I only have to change some small things. It doesn't have to be perfect, of course. Well, I mean, of course Google is perfect. I ask it to make something about a topic and it'll tell me, it'll run me through a process to create the content. For example, I want to make a video about the best way to build a SaaS as a non-technical person.\n\n9:33 - Jorge Lewis \nI want it to know what my opinions are on that whole topic. And if it doesn't, I want it to ask me, okay, what do you think about this? What about this? What about this? To build a knowledge base around this whole topic so that it can understand how I would write this. Because a lot of content is so opinion-based. Building fact-based content is very easy. You can research things and find facts.\n\n9:59 - Jorge Lewis \nWhat people are after for content is experienced people that have done it before that can use their experience to provide advice. And I would say I have some experience that I want to be sharing. Instead of just kind of regurgitating everything like, oh, you should raise funding and then you should do this. Like kind of the very basic things. I don't want it to be that. I don't want this project to be a regurgitation of a Google search. I don't want it to kind of search Google and then print whatever it finds.\n\n10:36 - Unidentified Speaker \nYeah.\n\n10:37 - Jorge Lewis \nYeah.\n\n10:38 - Biwas bhandari \nI can keep going, but there's, um, But that can be done in normal AI chatbots like chatGPT. You can just ask, okay, I want to do this and it will reply instantly. So what's the selling point of this product?\n\n11:00 - Biwas bhandari \nUm, it's like, it's like, why would I come to these, uh, the content app instead of going to chatGPT?\n\n11:09 - Jorge Lewis \nSo, so this, this right.\n\n11:14 - Jorge Lewis \nI want this project to write your content, not chat, UBT's content or not the internet's content. I want it to be based off of the, the, the user. So the project's going to need to know a lot about the user, whether it can ask questions or it can take some input, wink, wink transcript. Yeah.\n\n11:38 - Jorge Lewis \nYeah, so I have a lot of ideas and like features, ways we can do this, but I think the vision aspect of this is supposed to be very high level. So I think hopefully I've done an okay job at keeping it high level. Let's go into our corners and rights.\n\n11:57 - Biwas bhandari \nSo the vision?\n\n11:58 - Jorge Lewis \nYeah, the vision.\n\n11:59 - Unidentified Speaker \nOkay.\n\n12:10 - Biwas bhandari \nvision PR plus PC don't understand All right, I'm done. I want to understand and create, okay. All right.\n\n13:24 - Jorge Lewis \nAll right, so I'll go ahead and read mine first. A platform that writes content as if it were me, not only the style but also the opinions and experiences, leading to no necessary"}
02:07:10,163 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,167 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Jorge Lewis \nYeah, the vision.\n\n11:59 - Unidentified Speaker \nOkay.\n\n12:10 - Biwas bhandari \nvision PR plus PC don\'t understand All right, I\'m done. I want to understand and create, okay. All right.\n\n13:24 - Jorge Lewis \nAll right, so I\'ll go ahead and read mine first. A platform that writes content as if it were me, not only the style but also the opinions and experiences, leading to no necessary modifications post-generation.\n\n13:41 - Jorge Lewis \nTo understand and create content through a user\'s perspective and generate content based on his or her vision.\n\n13:49 - Biwas bhandari \nAnd both of the lines are same. Mine was. After that end, it\'s the same. I just realized it. Oh yeah.\n\n14:03 - Jorge Lewis \nUser\'s perspective and vision.\n\n14:07 - Biwas bhandari \nYeah.\n\n14:09 - Jorge Lewis \nSo this part we\'ve got aligned. We want it to be based on the user\'s perspective and vision.\n\n14:15 - Unidentified Speaker \nYeah.\n\n14:17 - Jorge Lewis \nAnd I phrase that as style, opinions, and experiences.\n\n14:29 - Biwas bhandari \nSo let\'s say instead of, uh, instead of, uh, instead of no necessary modifications, I think some, we need to modify it to some content.\n\n14:40 - Jorge Lewis \nBut at the end, the vision of this is that I can just ask it to make something regarding a topic and it can go ahead and make something.\n\n14:49 - Unidentified Speaker \nOh.\n\n14:52 - Jorge Lewis \nor even not even I don\'t want to like the vision isn\'t I want to ask it to make content about something I wanted to just make content like on like as if it were me like completely autonomous okay yeah so maybe I can I can so a platform that writes content so we\'re leaving out to the part where Because the vision shouldn\'t be the implementation of, oh, I ask it for content and then it makes content. It\'s just, this is what it, I want it to write content and then we can figure out the rest.\n\n15:27 - Biwas bhandari \nIt\'s like instead of hiring a content writer, you come to our platform and tell us about your perspective and what content you want to make.\n\n15:38 - Jorge Lewis \nAnd that\'s the hard part, getting your, the user\'s perspective to this chatbot, like very well, like done.\n\n15:45 - Unidentified Speaker \nYeah.\n\n15:51 - Jorge Lewis \nOkay.\n\n15:56 - Jorge Lewis \nOkay. Wait, there\'s also, so a platform that writes content as if it were me, not only the styles style, but also the opinions and experiences leading to Okay. How do you think that is that good? Or what do you think?\n\n16:18 - Biwas bhandari \nYeah, it\'s good. No. But we need to be able to tell it to modify it later. For example, like we if we if you are a content, if you are a content writer, you will say, Okay, I don\'t like this part, please modify it or something.\n\n16:37 - Jorge Lewis \nSo the end goal is I can just, it just posts content, it writes and posts content for me, I guess, is the end goal, the vision. So a platform that writes or...\n\n16:52 - Jorge Lewis \nThat I\'m going to say creates content and creates what can mean what writes publish and all of the above. The creates.\n\n17:03 - Biwas bhandari \nYeah. Does it align with the mission in the mission? We says make content creation and ideas and fast. Oh yeah. There\'s creation to creation.\n\n17:16 - Jorge Lewis \nSo creation, I guess, is both writing the content.\n\n17:21 - Jorge Lewis \nand everything between publishing it. And we\'re using the word content here, but we know that since we\'ve kind of already briefed ourselves on what this is, at first it\'ll start with just text content since it\'s easiest. And that\'s where we get into it in the roadmap afterwards. So let\'s just stay on track. So it writes the content as if it were me without necessary modifications, without, okay. And these things will change, by the way, over time, if I\'m not mistaken. Like as we go, we can read this every week and say, oh, we\'ve actually changed the mission, I think. Like, I\'m just guessing. It usually stays the same, but I think the vision might change here and there. It changes more often, but they both change. So now we get into, let\'s delete this, this, and then copy this. That\'s the vision. And here\'s the mission.\n\n18:17 - Jorge Lewis \nSo the product vision board is, okay. So what is, so this is, we can both just fill in at the same time. This is kind of like a group task where we can just each take a part.\n\n18:28 - Biwas bhandari \nOkay.\n\n18:29 - Jorge Lewis \nLet me check. So what is, okay, so let\'s just vision. What is your purpose in creating the product?\n\n18:38 - Unidentified Speaker \nOkay.\n\n18:47 - Biwas bhandari \nTargeted group, it\'s...\n\n19:01 - Biwas bhandari \nCan I fill all the tabs? The targeted groups and all that?\n\n19:06 - Jorge Lewis \nSorry?\n\n19:07 - Biwas bhandari \nCan I fill the other empty tabs?\n\n19:09 - Jorge Lewis\n######################\nOutput:'}
02:07:10,168 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,172 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Jorge Lewis \nYeah, the vision.\n\n11:59 - Unidentified Speaker \nOkay.\n\n12:10 - Biwas bhandari \nvision PR plus PC don't understand All right, I'm done. I want to understand and create, okay. All right.\n\n13:24 - Jorge Lewis \nAll right, so I'll go ahead and read mine first. A platform that writes content as if it were me, not only the style but also the opinions and experiences, leading to no necessary modifications post-generation.\n\n13:41 - Jorge Lewis \nTo understand and create content through a user's perspective and generate content based on his or her vision.\n\n13:49 - Biwas bhandari \nAnd both of the lines are same. Mine was. After that end, it's the same. I just realized it. Oh yeah.\n\n14:03 - Jorge Lewis \nUser's perspective and vision.\n\n14:07 - Biwas bhandari \nYeah.\n\n14:09 - Jorge Lewis \nSo this part we've got aligned. We want it to be based on the user's perspective and vision.\n\n14:15 - Unidentified Speaker \nYeah.\n\n14:17 - Jorge Lewis \nAnd I phrase that as style, opinions, and experiences.\n\n14:29 - Biwas bhandari \nSo let's say instead of, uh, instead of, uh, instead of no necessary modifications, I think some, we need to modify it to some content.\n\n14:40 - Jorge Lewis \nBut at the end, the vision of this is that I can just ask it to make something regarding a topic and it can go ahead and make something.\n\n14:49 - Unidentified Speaker \nOh.\n\n14:52 - Jorge Lewis \nor even not even I don't want to like the vision isn't I want to ask it to make content about something I wanted to just make content like on like as if it were me like completely autonomous okay yeah so maybe I can I can so a platform that writes content so we're leaving out to the part where Because the vision shouldn't be the implementation of, oh, I ask it for content and then it makes content. It's just, this is what it, I want it to write content and then we can figure out the rest.\n\n15:27 - Biwas bhandari \nIt's like instead of hiring a content writer, you come to our platform and tell us about your perspective and what content you want to make.\n\n15:38 - Jorge Lewis \nAnd that's the hard part, getting your, the user's perspective to this chatbot, like very well, like done.\n\n15:45 - Unidentified Speaker \nYeah.\n\n15:51 - Jorge Lewis \nOkay.\n\n15:56 - Jorge Lewis \nOkay. Wait, there's also, so a platform that writes content as if it were me, not only the styles style, but also the opinions and experiences leading to Okay. How do you think that is that good? Or what do you think?\n\n16:18 - Biwas bhandari \nYeah, it's good. No. But we need to be able to tell it to modify it later. For example, like we if we if you are a content, if you are a content writer, you will say, Okay, I don't like this part, please modify it or something.\n\n16:37 - Jorge Lewis \nSo the end goal is I can just, it just posts content, it writes and posts content for me, I guess, is the end goal, the vision. So a platform that writes or...\n\n16:52 - Jorge Lewis \nThat I'm going to say creates content and creates what can mean what writes publish and all of the above. The creates.\n\n17:03 - Biwas bhandari \nYeah. Does it align with the mission in the mission? We says make content creation and ideas and fast. Oh yeah. There's creation to creation.\n\n17:16 - Jorge Lewis \nSo creation, I guess, is both writing the content.\n\n17:21 - Jorge Lewis \nand everything between publishing it. And we're using the word content here, but we know that since we've kind of already briefed ourselves on what this is, at first it'll start with just text content since it's easiest. And that's where we get into it in the roadmap afterwards. So let's just stay on track. So it writes the content as if it were me without necessary modifications, without, okay. And these things will change, by the way, over time, if I'm not mistaken. Like as we go, we can read this every week and say, oh, we've actually changed the mission, I think. Like, I'm just guessing. It usually stays the same, but I think the vision might change here and there. It changes more often, but they both change. So now we get into, let's delete this, this, and then copy this. That's the vision. And here's the mission.\n\n18:17 - Jorge Lewis \nSo the product vision board is, okay. So what is, so this is, we can both just fill in at the same time. This is kind of like a group task where we can just each take a part.\n\n18:28 - Biwas bhandari \nOkay.\n\n18:29 - Jorge Lewis \nLet me check. So what is, okay, so let's just vision. What is your purpose in creating the product?\n\n18:38 - Unidentified Speaker \nOkay.\n\n18:47 - Biwas bhandari \nTargeted group, it's...\n\n19:01 - Biwas bhandari \nCan I fill all the tabs? The targeted groups and all that?\n\n19:06 - Jorge Lewis \nSorry?\n\n19:07 - Biwas bhandari \nCan I fill the other empty tabs?\n\n19:09 - Jorge Lewis"}
02:07:10,273 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,274 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: , so let\'s just vision. What is your purpose in creating the product?\n\n18:38 - Unidentified Speaker \nOkay.\n\n18:47 - Biwas bhandari \nTargeted group, it\'s...\n\n19:01 - Biwas bhandari \nCan I fill all the tabs? The targeted groups and all that?\n\n19:06 - Jorge Lewis \nSorry?\n\n19:07 - Biwas bhandari \nCan I fill the other empty tabs?\n\n19:09 - Jorge Lewis \nYeah, yeah, yeah, go ahead, go ahead. At the end we can just refute to make sure we\'re all aligned.\n\n19:14 - Unidentified Speaker \nOkay.\n\n19:15 - Biwas bhandari \nTargeted groups.\n\n19:48 - Biwas bhandari \nNow what problem does the paradox solve?\n\n20:49 - Biwas bhandari \nI mean, are content writers expensive to hire or something?\n\n20:56 - Biwas bhandari \nDepends.\n\n21:00 - Biwas bhandari \nIt depends, I think.\n\n21:02 - Jorge Lewis \nYeah. Well, they\'re more expensive than this, so.\n\n21:08 - Biwas bhandari \nOh, yeah.\n\n21:13 - Biwas bhandari \nI think that will go into the business school or something like that.\n\n21:24 - Biwas bhandari \nNot so much.\n\n21:33 - Biwas bhandari \nContent creation is time consuming.\n\n21:54 - Biwas bhandari \nHey, darling.\n\n22:07 - Biwas bhandari \nWhat?\n\n22:17 - Biwas bhandari \nOkay.\n\n22:20 - Biwas bhandari \nOkay. I think this is it. Do you need to go to business schools?\n\n22:27 - Jorge Lewis \nUm, yeah, once I, for the target group, one idea I have is that since, so in general with SAS and I hope whoever\'s watching this doesn\'t get bored by this, but, um, SAS there\'s two aspects of, of SAS. That\'s really hard making it and making a good product and then selling it. Selling it requires distribution, which is probably the hardest part, getting it to people that need it. For us, our means of distribution for this would be Okay, so the reason why we\'re advantaged at making a good product on that side is because this is going to serve me. I know I\'m the customer of this, so I\'ll understand my own problems. And then to distribute it, I\'ll be able to use my network of people that are also, like one example is I could use my network for people that are also trying to start content writing for whatever they\'re doing. Because I know quite a lot of people instead of people, a lot of entrepreneurs and business owners that are getting into content writing, but they\'re struggling with kind of doing it and their own business. But because everyone right now understands the value of content writing and how important it is to build the brand and all that.\n\n23:45 - Biwas bhandari \nYeah.\n\n23:47 - Jorge Lewis \nUm, and then, yeah, for this also to help the selling part is since I understand the problems, I can present this better to potential users since I, I can use my own pains.\n\n23:58 - Biwas bhandari \nYeah.\n\n24:02 - Jorge Lewis \nSo maybe, I think I can rephrase it to business or entrepreneurs, I think, because that\'s the term they use on all their social media and stuff. So entrepreneurs trying to, or that do content creation.\n\n24:26 - Jorge Lewis \nThey either do it or they\'re trying to, no, because if they, One thing to think about is if we, well, I was going to write entrepreneurs that are trying to get into content creation, but that\'s not really a market because those people that have it, that are trying to get into it, I don\'t think they\'re going to understand the value this brings. Like, I don\'t know if that\'s, maybe, maybe I\'m wrong, but I think starting with people that are already making content and saying, Hey, we can save you this many hours is a much better sell than, Hey, we could save you this many hours instead of we will save you if you buy this.\n\n25:01 - Biwas bhandari \nYes, someone who is getting into the content creation will come back later after he knows that, oh, it\'s so much of hassle to brainstorm about it.\n\n25:11 - Jorge Lewis \nYeah. So, and then, okay, who are the target customers and users? Business owners with no prior knowledge in content creation, but wants to write content for his or her business. That\'s interesting, yeah?\n\n25:25 - Biwas bhandari \nSo, yeah.\n\n25:27 - Jorge Lewis \nThat\'s very interesting because... There\'s so many people that this could target. It\'s a matter of picking. The reason I\'m picking entrepreneurs is because it\'s my network. But my network also includes my dad. And he has a lot of friends that are also running a business.\n\n25:47 - Jorge Lewis \nThey could have a lot of improvements if they start content creation. If we\'re targeting businesses that don\'t do content creation already, we have two jobs. We have to convince them to start, um, to convince them to buy our, our, to use our software. So I think starting with people that are already doing it as an easier sell, what do you think?\n\n26:10 - Biwas bhandari \nI mean, we can tell, uh, so the business owners, the benefits of content creation and all that, and they can just\n######################\nOutput:'}
02:07:10,275 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,278 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ", so let's just vision. What is your purpose in creating the product?\n\n18:38 - Unidentified Speaker \nOkay.\n\n18:47 - Biwas bhandari \nTargeted group, it's...\n\n19:01 - Biwas bhandari \nCan I fill all the tabs? The targeted groups and all that?\n\n19:06 - Jorge Lewis \nSorry?\n\n19:07 - Biwas bhandari \nCan I fill the other empty tabs?\n\n19:09 - Jorge Lewis \nYeah, yeah, yeah, go ahead, go ahead. At the end we can just refute to make sure we're all aligned.\n\n19:14 - Unidentified Speaker \nOkay.\n\n19:15 - Biwas bhandari \nTargeted groups.\n\n19:48 - Biwas bhandari \nNow what problem does the paradox solve?\n\n20:49 - Biwas bhandari \nI mean, are content writers expensive to hire or something?\n\n20:56 - Biwas bhandari \nDepends.\n\n21:00 - Biwas bhandari \nIt depends, I think.\n\n21:02 - Jorge Lewis \nYeah. Well, they're more expensive than this, so.\n\n21:08 - Biwas bhandari \nOh, yeah.\n\n21:13 - Biwas bhandari \nI think that will go into the business school or something like that.\n\n21:24 - Biwas bhandari \nNot so much.\n\n21:33 - Biwas bhandari \nContent creation is time consuming.\n\n21:54 - Biwas bhandari \nHey, darling.\n\n22:07 - Biwas bhandari \nWhat?\n\n22:17 - Biwas bhandari \nOkay.\n\n22:20 - Biwas bhandari \nOkay. I think this is it. Do you need to go to business schools?\n\n22:27 - Jorge Lewis \nUm, yeah, once I, for the target group, one idea I have is that since, so in general with SAS and I hope whoever's watching this doesn't get bored by this, but, um, SAS there's two aspects of, of SAS. That's really hard making it and making a good product and then selling it. Selling it requires distribution, which is probably the hardest part, getting it to people that need it. For us, our means of distribution for this would be Okay, so the reason why we're advantaged at making a good product on that side is because this is going to serve me. I know I'm the customer of this, so I'll understand my own problems. And then to distribute it, I'll be able to use my network of people that are also, like one example is I could use my network for people that are also trying to start content writing for whatever they're doing. Because I know quite a lot of people instead of people, a lot of entrepreneurs and business owners that are getting into content writing, but they're struggling with kind of doing it and their own business. But because everyone right now understands the value of content writing and how important it is to build the brand and all that.\n\n23:45 - Biwas bhandari \nYeah.\n\n23:47 - Jorge Lewis \nUm, and then, yeah, for this also to help the selling part is since I understand the problems, I can present this better to potential users since I, I can use my own pains.\n\n23:58 - Biwas bhandari \nYeah.\n\n24:02 - Jorge Lewis \nSo maybe, I think I can rephrase it to business or entrepreneurs, I think, because that's the term they use on all their social media and stuff. So entrepreneurs trying to, or that do content creation.\n\n24:26 - Jorge Lewis \nThey either do it or they're trying to, no, because if they, One thing to think about is if we, well, I was going to write entrepreneurs that are trying to get into content creation, but that's not really a market because those people that have it, that are trying to get into it, I don't think they're going to understand the value this brings. Like, I don't know if that's, maybe, maybe I'm wrong, but I think starting with people that are already making content and saying, Hey, we can save you this many hours is a much better sell than, Hey, we could save you this many hours instead of we will save you if you buy this.\n\n25:01 - Biwas bhandari \nYes, someone who is getting into the content creation will come back later after he knows that, oh, it's so much of hassle to brainstorm about it.\n\n25:11 - Jorge Lewis \nYeah. So, and then, okay, who are the target customers and users? Business owners with no prior knowledge in content creation, but wants to write content for his or her business. That's interesting, yeah?\n\n25:25 - Biwas bhandari \nSo, yeah.\n\n25:27 - Jorge Lewis \nThat's very interesting because... There's so many people that this could target. It's a matter of picking. The reason I'm picking entrepreneurs is because it's my network. But my network also includes my dad. And he has a lot of friends that are also running a business.\n\n25:47 - Jorge Lewis \nThey could have a lot of improvements if they start content creation. If we're targeting businesses that don't do content creation already, we have two jobs. We have to convince them to start, um, to convince them to buy our, our, to use our software. So I think starting with people that are already doing it as an easier sell, what do you think?\n\n26:10 - Biwas bhandari \nI mean, we can tell, uh, so the business owners, the benefits of content creation and all that, and they can just"}
02:07:10,368 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,372 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: If we\'re targeting businesses that don\'t do content creation already, we have two jobs. We have to convince them to start, um, to convince them to buy our, our, to use our software. So I think starting with people that are already doing it as an easier sell, what do you think?\n\n26:10 - Biwas bhandari \nI mean, we can tell, uh, so the business owners, the benefits of content creation and all that, and they can just come to our platform to create content maybe.\n\n26:23 - Jorge Lewis \nThat\'s how we would sell them on it.\n\n26:28 - Jorge Lewis \nFor example, if I sold this software to me, I\'m already making videos and I\'m already doing it. If you tell me, hey, you probably spend 30 hours a week writing content, why not just have conversations with your friends? And use that to create content, save 30 hours and just have normal conversations instead. And I\'ll be like, damn, that\'s actually, yeah, okay. Instead, if I sell it to Jonas, where Jonas wants to start a content creation, wants to start writing content, for him, when I come to him, I\'m saying, hey, when you start your business, You can, um, or you should start your content creation now because it\'s so important. I had to convince him of that. Why do I have to convince, why should I convince him when I\'m already doing it? Like, I don\'t want to convince him to start and also buy this instead. I could just, they can already start by themselves and just buy it. So I would, I think I would be a better target customer than Jonas because I\'ve already started. Yeah.\n\n27:28 - Biwas bhandari \nYeah.\n\n27:29 - Jorge Lewis \nBut later, like this, this has a lot of potential to target like business owners as well. Like we could have a whole sales process of also including that aspect of convincing them to start content creation saying, Hey, content creation has never been easier with this. You should start content creation with our software. That could be a later, that could be our offer later, but right now I think it\'s better. Make your content creation easier with this.\n\n27:54 - Biwas bhandari \nYeah. Yeah.\n\n27:57 - Jorge Lewis \nUm, Okay, so we\'re the target customers and users. I\'m going to just keep that as one question.\n\n28:11 - Jorge Lewis \nThis thing is going to change so much that it\'s mostly important so that everyone\'s always aligned through conversation, I think, rather than having it on paper.\n\n28:22 - Jorge Lewis \nBusinesses use business plans. We, specifically at Startino, use a lean business plan.\n\n28:30 - Jorge Lewis \nThe problem, what you\'re supposed to do is not use that as a, like that\'s not supposed to point you to success. That\'s supposed to point you to the next chapter. The next chapter is determined by whenever things change, like all the time they\'ll change. You have to update your business plan accordingly or your business model. Um, Because in the same way with this, it has to be updated constantly. But it\'s just a hassle. I haven\'t gone into that Google document and updated our business model. But we understand, Jonas and I, the same vision, because we always talk about it. So I think that\'s more important than actually a document that says it.\n\n29:08 - Jorge Lewis \nHaving it on a document is very important when you\'re trying to share it with other people, though.\n\n29:16 - Jorge Lewis \nIt\'s also useful for distilling whatever information you have into very concise forms.\n\n29:46 - Jorge Lewis \nWhat benefit does it provide? What benefit does this product provide? Bro, it\'s the same... Bro, it\'s... I\'m not gonna... The problem is this. Of course, it\'s solving the problem. What do you mean... I don\'t know. Yeah, I\'m just lazy. It\'s only me and you making this and at some point, this is all gonna change, so... How is the product going to benefit the company? What are the business goals? Okay.\n\n30:15 - Jorge Lewis \nBusiness goal is make money, bro. Quote my Brazilian friends. I think the first goal is to, the business goal is to allow me, allow Jorge to produce content.\n\n30:37 - Biwas bhandari \nIt will be launched as a SaaS and also it will help you yourself write content and all that.\n\n30:45 - Jorge Lewis \nYeah. So first it needs to allow me to write content. Like, cause if I can\'t use this, why would I, I can\'t sell it, you know? So that\'s the goal, the first goal. Um, and at some point it\'s going to be launched as a SaaS.\n\n31:00 - Jorge Lewis \nas a market leader in content, AI content creation software industry.\n\n31:16 - Jorge Lewis \nSo, we need some, I\'d like some fixed, some smart goals. So, something measurable.\n\n31:23 - Jorge Lewis \nSo, to allow Jorge to produce content, You know what\'s interesting? It\'s, I don\'t think it\'s so weird because my problem with me is not that it\'s, so the problem is that I\'m not writing content because I\'m procrastinating. It\'s not that it\'s taking me too long. It\'s that I\'m procrastinating it.\n\n31:54 - Jorge Lewis \nSo. Maybe this should be making it enjoyable enough or making it frictionless to a point where it\'s easy enough for me to make content. I don\'t\n######################\nOutput:'}
02:07:10,372 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,376 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "If we're targeting businesses that don't do content creation already, we have two jobs. We have to convince them to start, um, to convince them to buy our, our, to use our software. So I think starting with people that are already doing it as an easier sell, what do you think?\n\n26:10 - Biwas bhandari \nI mean, we can tell, uh, so the business owners, the benefits of content creation and all that, and they can just come to our platform to create content maybe.\n\n26:23 - Jorge Lewis \nThat's how we would sell them on it.\n\n26:28 - Jorge Lewis \nFor example, if I sold this software to me, I'm already making videos and I'm already doing it. If you tell me, hey, you probably spend 30 hours a week writing content, why not just have conversations with your friends? And use that to create content, save 30 hours and just have normal conversations instead. And I'll be like, damn, that's actually, yeah, okay. Instead, if I sell it to Jonas, where Jonas wants to start a content creation, wants to start writing content, for him, when I come to him, I'm saying, hey, when you start your business, You can, um, or you should start your content creation now because it's so important. I had to convince him of that. Why do I have to convince, why should I convince him when I'm already doing it? Like, I don't want to convince him to start and also buy this instead. I could just, they can already start by themselves and just buy it. So I would, I think I would be a better target customer than Jonas because I've already started. Yeah.\n\n27:28 - Biwas bhandari \nYeah.\n\n27:29 - Jorge Lewis \nBut later, like this, this has a lot of potential to target like business owners as well. Like we could have a whole sales process of also including that aspect of convincing them to start content creation saying, Hey, content creation has never been easier with this. You should start content creation with our software. That could be a later, that could be our offer later, but right now I think it's better. Make your content creation easier with this.\n\n27:54 - Biwas bhandari \nYeah. Yeah.\n\n27:57 - Jorge Lewis \nUm, Okay, so we're the target customers and users. I'm going to just keep that as one question.\n\n28:11 - Jorge Lewis \nThis thing is going to change so much that it's mostly important so that everyone's always aligned through conversation, I think, rather than having it on paper.\n\n28:22 - Jorge Lewis \nBusinesses use business plans. We, specifically at Startino, use a lean business plan.\n\n28:30 - Jorge Lewis \nThe problem, what you're supposed to do is not use that as a, like that's not supposed to point you to success. That's supposed to point you to the next chapter. The next chapter is determined by whenever things change, like all the time they'll change. You have to update your business plan accordingly or your business model. Um, Because in the same way with this, it has to be updated constantly. But it's just a hassle. I haven't gone into that Google document and updated our business model. But we understand, Jonas and I, the same vision, because we always talk about it. So I think that's more important than actually a document that says it.\n\n29:08 - Jorge Lewis \nHaving it on a document is very important when you're trying to share it with other people, though.\n\n29:16 - Jorge Lewis \nIt's also useful for distilling whatever information you have into very concise forms.\n\n29:46 - Jorge Lewis \nWhat benefit does it provide? What benefit does this product provide? Bro, it's the same... Bro, it's... I'm not gonna... The problem is this. Of course, it's solving the problem. What do you mean... I don't know. Yeah, I'm just lazy. It's only me and you making this and at some point, this is all gonna change, so... How is the product going to benefit the company? What are the business goals? Okay.\n\n30:15 - Jorge Lewis \nBusiness goal is make money, bro. Quote my Brazilian friends. I think the first goal is to, the business goal is to allow me, allow Jorge to produce content.\n\n30:37 - Biwas bhandari \nIt will be launched as a SaaS and also it will help you yourself write content and all that.\n\n30:45 - Jorge Lewis \nYeah. So first it needs to allow me to write content. Like, cause if I can't use this, why would I, I can't sell it, you know? So that's the goal, the first goal. Um, and at some point it's going to be launched as a SaaS.\n\n31:00 - Jorge Lewis \nas a market leader in content, AI content creation software industry.\n\n31:16 - Jorge Lewis \nSo, we need some, I'd like some fixed, some smart goals. So, something measurable.\n\n31:23 - Jorge Lewis \nSo, to allow Jorge to produce content, You know what's interesting? It's, I don't think it's so weird because my problem with me is not that it's, so the problem is that I'm not writing content because I'm procrastinating. It's not that it's taking me too long. It's that I'm procrastinating it.\n\n31:54 - Jorge Lewis \nSo. Maybe this should be making it enjoyable enough or making it frictionless to a point where it's easy enough for me to make content. I don't"}
02:07:10,415 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,418 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'s interesting? It\'s, I don\'t think it\'s so weird because my problem with me is not that it\'s, so the problem is that I\'m not writing content because I\'m procrastinating. It\'s not that it\'s taking me too long. It\'s that I\'m procrastinating it.\n\n31:54 - Jorge Lewis \nSo. Maybe this should be making it enjoyable enough or making it frictionless to a point where it\'s easy enough for me to make content. I don\'t know. Do you get where I\'m going? Because I don\'t write the Startino content right now. And this won\'t be making it This won\'t be making that faster because how do you make something faster that you don\'t do? So I think this is going instead of what this, what benefit does this provide is it. Convinces me to write content that content is that writing the content is worth it because the effort to make it as less.\n\n32:35 - Biwas bhandari \nSo, yeah, I think instead of saying make, uh, to help content creation easier and faster should be content creation, uh, enjoyable, maybe.\n\n32:47 - Jorge Lewis \nContent creation what?\n\n32:49 - Biwas bhandari \nEnjoyable, more enjoyable.\n\n32:53 - Jorge Lewis \nI think that can be the angle because, okay, this is a perfect example. Right now, the call you and I are in, I can upload this transcript to this software and I can say, make a post about the vision and mission statement. And highlight the key points that we mentioned in this. And you can highlight things like, oh, not spending too much time on specific things or whatever. And that\'ll make content writing more enjoyable for me because I can, instead of writing content, do things like this, where it\'s just I\'m having a conversation with you and it\'s more enjoyable. So maybe the goal could be to make it more enjoyable, maybe. I don\'t know.\n\n33:44 - Biwas bhandari \nBecause I\'ve tried I tried writing blocks one two times in the blog post and medium I think I\'ve written one two and I\'ve slipped it but if if that would be more enjoyable like playing games and all that but\n\n33:59 - Jorge Lewis \nThat will be what if effective maybe yeah, yeah Yeah, that\'s interesting maybe Yeah, because like, imagine this, imagine instead of writing a script, what you do to make the content is you have a conversation about whatever that topic is with the friend. You tell the friend, Hey, can we have a conversation? I want to record it. I\'m going to use it to make a script later. How does that sound? And they\'re like, cool.\n\n34:32 - Biwas bhandari \nWhy not?\n\n34:36 - Unidentified Speaker \nYeah.\n\n34:39 - Jorge Lewis \nIt\'s interesting. So, um, in, in, um, Give me one second, I\'m gonna find a...\n\n34:51 - Jorge Lewis \nA message I sent. Here. Wait.\n\n34:57 - Jorge Lewis \nSo, I don\'t know where... Actually, it\'s probably on the Obsidian. Let me find it.\n\n35:29 - Jorge Lewis \nDon\'t worry, I didn\'t hear anything.\n\n35:48 - Jorge Lewis \nOkay, I found it.\n\n35:52 - Jorge Lewis \nSo, I\'m just going to post it as a note here. So, I think a great method to give these videos both as high quality and validated as possible is to have a recording group session.\n\n36:13 - Jorge Lewis \nThe recording should include face cams and screen cams. We\'ll pretend it\'s both a live podcast and research session. Merging the two into one in order to save time. The first half can be more of research than discussion, and the second half we can discuss about putting things on paper. So the goal of that is at the end, this makes the production of work, of creating the script, gathering footage, and researching, validating opinions, a lot more fun, and more importantly, faster. We take the recordings of the participants and use it to structure and create the actual video. Probably won\'t use any of the footage in the final video, but we definitely could. So, this text, by the way, was in my plan for how to do the Startino videos. When I first conceived of, okay, we should probably be doing content. So, I think we\'re coming back to full circle where this is a big point where it should be fun.\n\n37:05 - Jorge Lewis \nAnd I think that\'s the issue because content writing is boring.\n\n37:10 - Biwas bhandari \nLike I don\'t want to write like it\'s even, even if you know, yeah, it\'s important for me to write content.\n\n37:18 - Jorge Lewis \nAnd also, yeah, it\'s so, okay. So maybe we can read. If we look at the mission again.\n\n37:36 - Unidentified Speaker \nYeah.\n\n37:38 - Jorge Lewis \nSo the problem isn\'t actually that it takes too much time. I think it\'s that it\'s not enjoyable enough.\n\n37:46 - Unidentified Speaker \nYeah.\n\n37:49 - Jorge Lewis \nIt\'s a little bit of both because I wonder if I would eventually, if I would, okay, an okay example is, okay, no, no, no. So what I\'ve been with Jonas, whenever we, We have amazing conversations. Earlier we were just discussing about SvelteKit and when we should be using form actions versus API routes and et cetera. It was a good technical conversation. If we could just take that conversation and convert it into some form of content, whether it\'s\n######################\nOutput:'}
02:07:10,418 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,421 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'s interesting? It's, I don't think it's so weird because my problem with me is not that it's, so the problem is that I'm not writing content because I'm procrastinating. It's not that it's taking me too long. It's that I'm procrastinating it.\n\n31:54 - Jorge Lewis \nSo. Maybe this should be making it enjoyable enough or making it frictionless to a point where it's easy enough for me to make content. I don't know. Do you get where I'm going? Because I don't write the Startino content right now. And this won't be making it This won't be making that faster because how do you make something faster that you don't do? So I think this is going instead of what this, what benefit does this provide is it. Convinces me to write content that content is that writing the content is worth it because the effort to make it as less.\n\n32:35 - Biwas bhandari \nSo, yeah, I think instead of saying make, uh, to help content creation easier and faster should be content creation, uh, enjoyable, maybe.\n\n32:47 - Jorge Lewis \nContent creation what?\n\n32:49 - Biwas bhandari \nEnjoyable, more enjoyable.\n\n32:53 - Jorge Lewis \nI think that can be the angle because, okay, this is a perfect example. Right now, the call you and I are in, I can upload this transcript to this software and I can say, make a post about the vision and mission statement. And highlight the key points that we mentioned in this. And you can highlight things like, oh, not spending too much time on specific things or whatever. And that'll make content writing more enjoyable for me because I can, instead of writing content, do things like this, where it's just I'm having a conversation with you and it's more enjoyable. So maybe the goal could be to make it more enjoyable, maybe. I don't know.\n\n33:44 - Biwas bhandari \nBecause I've tried I tried writing blocks one two times in the blog post and medium I think I've written one two and I've slipped it but if if that would be more enjoyable like playing games and all that but\n\n33:59 - Jorge Lewis \nThat will be what if effective maybe yeah, yeah Yeah, that's interesting maybe Yeah, because like, imagine this, imagine instead of writing a script, what you do to make the content is you have a conversation about whatever that topic is with the friend. You tell the friend, Hey, can we have a conversation? I want to record it. I'm going to use it to make a script later. How does that sound? And they're like, cool.\n\n34:32 - Biwas bhandari \nWhy not?\n\n34:36 - Unidentified Speaker \nYeah.\n\n34:39 - Jorge Lewis \nIt's interesting. So, um, in, in, um, Give me one second, I'm gonna find a...\n\n34:51 - Jorge Lewis \nA message I sent. Here. Wait.\n\n34:57 - Jorge Lewis \nSo, I don't know where... Actually, it's probably on the Obsidian. Let me find it.\n\n35:29 - Jorge Lewis \nDon't worry, I didn't hear anything.\n\n35:48 - Jorge Lewis \nOkay, I found it.\n\n35:52 - Jorge Lewis \nSo, I'm just going to post it as a note here. So, I think a great method to give these videos both as high quality and validated as possible is to have a recording group session.\n\n36:13 - Jorge Lewis \nThe recording should include face cams and screen cams. We'll pretend it's both a live podcast and research session. Merging the two into one in order to save time. The first half can be more of research than discussion, and the second half we can discuss about putting things on paper. So the goal of that is at the end, this makes the production of work, of creating the script, gathering footage, and researching, validating opinions, a lot more fun, and more importantly, faster. We take the recordings of the participants and use it to structure and create the actual video. Probably won't use any of the footage in the final video, but we definitely could. So, this text, by the way, was in my plan for how to do the Startino videos. When I first conceived of, okay, we should probably be doing content. So, I think we're coming back to full circle where this is a big point where it should be fun.\n\n37:05 - Jorge Lewis \nAnd I think that's the issue because content writing is boring.\n\n37:10 - Biwas bhandari \nLike I don't want to write like it's even, even if you know, yeah, it's important for me to write content.\n\n37:18 - Jorge Lewis \nAnd also, yeah, it's so, okay. So maybe we can read. If we look at the mission again.\n\n37:36 - Unidentified Speaker \nYeah.\n\n37:38 - Jorge Lewis \nSo the problem isn't actually that it takes too much time. I think it's that it's not enjoyable enough.\n\n37:46 - Unidentified Speaker \nYeah.\n\n37:49 - Jorge Lewis \nIt's a little bit of both because I wonder if I would eventually, if I would, okay, an okay example is, okay, no, no, no. So what I've been with Jonas, whenever we, We have amazing conversations. Earlier we were just discussing about SvelteKit and when we should be using form actions versus API routes and et cetera. It was a good technical conversation. If we could just take that conversation and convert it into some form of content, whether it's"}
02:07:10,475 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,476 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: of every point. So that first one is more efficient. This one\'s more enjoyable. This one\'s ease is easier. And this last one is more enjoyable.\n\n45:56 - Jorge Lewis \nSo those are kind of the use cases I can imagine. This top one is the most business oriented where, or is the most indirect. I\'m not thinking about making content when I have conversations. It\'s just, I\'m already having conversations. Let\'s reuse that into, so extracting more value from conversations. That are already being done so this one\'s extracting more value from the conversations that are already being done make using unstructured voice notes is more enjoyable this one so what do you mean by unstructured voice notes so for example like What I want to do is open my phone and start a voice note and say, hey, I\'m just going to ramble on about my opinions, my experience relating to SaaS and something. So for example, the three biggest mistakes I\'ve seen in my past is that you non-technical founders will have a big vision, but then not be able to isolate one feature. Another one might be they\'re not niched enough. Etc. And I just rent on for a bit without having to worry about the structure of it being very organized.\n\n47:28 - Biwas bhandari \nI can see this second point is more, I mean, like a practical, for example, in the midnight, I will be having so much ideas in my mind that I can just babble about it on the voice.\n\n47:43 - Jorge Lewis \nIt\'s easier to extract. To put down on paper ideas and thoughts.\n\n47:53 - Jorge Lewis \nSo this, so in the end, all of these are going to be content.\n\n48:01 - Jorge Lewis \nSo at the end, when you, your notes and ideas are, I mean, they\'re very nice to have, of course, but the end goal in this case is for content. So like, and then using others posts as inspiration is, What is that doing? That\'s kind of...\n\n48:24 - Biwas bhandari \nI think we don\'t need that thought point. Using all those posts as interest. Um, no, no, no.\n\n48:30 - Jorge Lewis \nSo what I actually like about this one, so I think it was in, it was in the other. Oh, what did I click?\n\n48:38 - Jorge Lewis \nUm, it was in the other fake jam. If you check out my screen share on the Google meet or if you just, um, So okay, other contents in the same niche. So what I mean by this is, if we were to take a look at an example of an implementation, I thought of, so I have a, you know, Tinder.\n\n49:05 - Biwas bhandari \nYeah.\n\n49:06 - Jorge Lewis \nSo what I want.\n\n49:10 - Jorge Lewis \nWhat I want to be able to do is it gives me content that from the internet and it says, Hey, it gives me the content and I can say, I like this. I don\'t like this. Or to give it to give more context, I can say, I agree with this part, but I don\'t agree with this part. So it\'s still me. I\'m adding my opinion to it, but it\'s giving, it\'s giving me a foundation, something to go off of Like I can just build on top of that because if I agree with it, then there\'s no reason to create it from scratch. And I feel like if you do this a thousand times, that\'s one way you can capture your opinion on things in a very efficient manner.\n\n49:51 - Biwas bhandari \nYeah, I got that.\n\n49:54 - Jorge Lewis \nSo maybe...\n\n50:01 - Jorge Lewis \nSo using others\' posts is...\n\n50:06 - Jorge Lewis \nSo what I just described is not, is, is a great way to is, I guess it\'s easier than thinking from scratch or yeah. Cause content itself is, is so it should be unique to you, but if people share opinions, it\'s not like we\'re copying someone\'s post. It\'s like, all we\'re doing is going to copy two sentences from his whole post and copy another two sentences from another post. Not because we\'re just trying to copy it, but because we actually agree with it.\n\n50:36 - Unidentified Speaker \nYeah.\n\n50:39 - Jorge Lewis \nIt\'s like, um, it\'s like we\'re using GitHub code. You might reuse someone\'s little micro, like someone\'s project. That\'s a tiny part of your whole content because you like it and you think it\'s a good, a good package or something. You could have made your own unique one, but why not? Why just use that one?\n\n51:01 - Biwas bhandari \nFor example, if I\'m making content on programming, I can see others first, take inspiration, and based on that, I can write my own.\n\n51:11 - Jorge Lewis \nYeah. And the important part is that you\'re actually not being a, you\'re not, what\'s the word when you\'re...\n\n51:28 - Jorge Lewis \nThere\'s a word for being too agreeable and programmers are often...\n\n51:38 - Biwas bhandari \nI can\'t find it.\n\n51:42 - Jorge Lewis \nSo oftentimes when, for example, the primogen, you know the primogen?\n\n51:49 - Biwas bhandari \nYeah.\n\n51:51 - Jorge Lewis \nSo he says a lot of things on his stuff, on his podcast. He reviews a lot of articles, by the way, which is like, if I\n######################\nOutput:'}
02:07:10,477 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,480 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "of every point. So that first one is more efficient. This one's more enjoyable. This one's ease is easier. And this last one is more enjoyable.\n\n45:56 - Jorge Lewis \nSo those are kind of the use cases I can imagine. This top one is the most business oriented where, or is the most indirect. I'm not thinking about making content when I have conversations. It's just, I'm already having conversations. Let's reuse that into, so extracting more value from conversations. That are already being done so this one's extracting more value from the conversations that are already being done make using unstructured voice notes is more enjoyable this one so what do you mean by unstructured voice notes so for example like What I want to do is open my phone and start a voice note and say, hey, I'm just going to ramble on about my opinions, my experience relating to SaaS and something. So for example, the three biggest mistakes I've seen in my past is that you non-technical founders will have a big vision, but then not be able to isolate one feature. Another one might be they're not niched enough. Etc. And I just rent on for a bit without having to worry about the structure of it being very organized.\n\n47:28 - Biwas bhandari \nI can see this second point is more, I mean, like a practical, for example, in the midnight, I will be having so much ideas in my mind that I can just babble about it on the voice.\n\n47:43 - Jorge Lewis \nIt's easier to extract. To put down on paper ideas and thoughts.\n\n47:53 - Jorge Lewis \nSo this, so in the end, all of these are going to be content.\n\n48:01 - Jorge Lewis \nSo at the end, when you, your notes and ideas are, I mean, they're very nice to have, of course, but the end goal in this case is for content. So like, and then using others posts as inspiration is, What is that doing? That's kind of...\n\n48:24 - Biwas bhandari \nI think we don't need that thought point. Using all those posts as interest. Um, no, no, no.\n\n48:30 - Jorge Lewis \nSo what I actually like about this one, so I think it was in, it was in the other. Oh, what did I click?\n\n48:38 - Jorge Lewis \nUm, it was in the other fake jam. If you check out my screen share on the Google meet or if you just, um, So okay, other contents in the same niche. So what I mean by this is, if we were to take a look at an example of an implementation, I thought of, so I have a, you know, Tinder.\n\n49:05 - Biwas bhandari \nYeah.\n\n49:06 - Jorge Lewis \nSo what I want.\n\n49:10 - Jorge Lewis \nWhat I want to be able to do is it gives me content that from the internet and it says, Hey, it gives me the content and I can say, I like this. I don't like this. Or to give it to give more context, I can say, I agree with this part, but I don't agree with this part. So it's still me. I'm adding my opinion to it, but it's giving, it's giving me a foundation, something to go off of Like I can just build on top of that because if I agree with it, then there's no reason to create it from scratch. And I feel like if you do this a thousand times, that's one way you can capture your opinion on things in a very efficient manner.\n\n49:51 - Biwas bhandari \nYeah, I got that.\n\n49:54 - Jorge Lewis \nSo maybe...\n\n50:01 - Jorge Lewis \nSo using others' posts is...\n\n50:06 - Jorge Lewis \nSo what I just described is not, is, is a great way to is, I guess it's easier than thinking from scratch or yeah. Cause content itself is, is so it should be unique to you, but if people share opinions, it's not like we're copying someone's post. It's like, all we're doing is going to copy two sentences from his whole post and copy another two sentences from another post. Not because we're just trying to copy it, but because we actually agree with it.\n\n50:36 - Unidentified Speaker \nYeah.\n\n50:39 - Jorge Lewis \nIt's like, um, it's like we're using GitHub code. You might reuse someone's little micro, like someone's project. That's a tiny part of your whole content because you like it and you think it's a good, a good package or something. You could have made your own unique one, but why not? Why just use that one?\n\n51:01 - Biwas bhandari \nFor example, if I'm making content on programming, I can see others first, take inspiration, and based on that, I can write my own.\n\n51:11 - Jorge Lewis \nYeah. And the important part is that you're actually not being a, you're not, what's the word when you're...\n\n51:28 - Jorge Lewis \nThere's a word for being too agreeable and programmers are often...\n\n51:38 - Biwas bhandari \nI can't find it.\n\n51:42 - Jorge Lewis \nSo oftentimes when, for example, the primogen, you know the primogen?\n\n51:49 - Biwas bhandari \nYeah.\n\n51:51 - Jorge Lewis \nSo he says a lot of things on his stuff, on his podcast. He reviews a lot of articles, by the way, which is like, if I"}
02:07:10,545 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,546 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: a little bit of both because I wonder if I would eventually, if I would, okay, an okay example is, okay, no, no, no. So what I\'ve been with Jonas, whenever we, We have amazing conversations. Earlier we were just discussing about SvelteKit and when we should be using form actions versus API routes and et cetera. It was a good technical conversation. If we could just take that conversation and convert it into some form of content, whether it\'s a snippet of that video and we can publish that or it writes a script for us or a post, anything like that would be great. So, maybe the mission isn\'t that it takes too much time to write content. I think it\'s... Can you see where I\'m going with this? It\'s more of trying to use what I already have, which is conversations with my team, which is conversations I already have.\n\n39:06 - Biwas bhandari \nTrying to summarize it and write a blog or content, something like that.\n\n39:15 - Jorge Lewis \nBut what\'s the problem then? The problem is there\'s no way to repurpose our conversations, I guess. I don\'t know.\n\n39:25 - Jorge Lewis \nSo you see, this is where these workshops are very helpful because you, you\'re really trying to understand what you\'re trying to do here.\n\n39:31 - Biwas bhandari \nI think it\'s not the, uh, what\'s the problem, but what we are trying to improve maybe because right now we are having a good conversation and that\'s good. But, uh, what, you know, what, what could make it more effective is if you just summarize it and make a blog post so everybody can read and all that. Maybe so.\n\n39:58 - Jorge Lewis \nOkay, so the problem is that when people have conversations, that knowledge and that there\'s value in that conversation that gets lost as soon as that, that only gets shared to those two people after that conversation finishes. But instead we want to extract as much value as possible by recording it and then converting it into something, into content. Whether you publish it to the public or just your team.\n\n40:33 - Jorge Lewis \nSo the problem is that we don\'t extract enough values from conversations.\n\n40:40 - Jorge Lewis \nBut when I\'m thinking, it doesn\'t sound very like, okay, the mission, instead of saying the problem, the mission is to make my conversations more valuable by being able to write content from them.\n\n40:58 - Jorge Lewis \nThat\'s the mission because that\'s pretty realistic. The only other time is that it\'s like maybe sometimes it\'s not my conversations, it\'s maybe a voice message I recorded on myself. Like I\'m on a walk and I just want to discuss the topic and convert it into content afterwards.\n\n41:39 - Biwas bhandari \nSo, I think that one is different than what we were talking before.\n\n41:57 - Biwas bhandari \nYeah, just before we were talking about that, okay, I want to write a content, but I need to instead of spending my time on company, I\'m spending time on brainstorming the brainstorming for the content. It takes too long time for that. And so in order to make it easier, I just need a tool that will help me. I\'m thinking of making content on SAS, for example. And based on that, our product will generate a content or something like that, maybe.\n\n42:36 - Jorge Lewis \nYeah, I can see. Yeah.\n\n42:43 - Jorge Lewis \nI want to take you through a story of how I can imagine using this. So I have, I\'ve recorded about a hundred read AI meetings between my team and clients and other people I\'ve met within my network. So what I can imagine myself doing is uploading those transcripts or videos or whatever format to this software. And then I say, Hey, Can you write, can you help me write something about SAS on, on how to build a SAS as a non-technical founder. It\'ll go through all those, try to pull as much as it can from it.\n\n43:22 - Biwas bhandari \nOh yeah. So instead of pulling it from the internet and creating separate content, it will take all the transcripts you provided. And based on that, it will create a whole new content. Yeah.\n\n43:34 - Jorge Lewis \nBut there\'s also another aspect of this project of this, of what I want is like, I want, um, okay, okay, I\'m getting, so, okay, okay, let me, I\'m gonna go on top of the mission, the blue card, so, why is that so small? So, writing, or, having conversations is more fun than writing.\n\n44:05 - Unidentified Speaker \nDumb? Yeah.\n\n44:15 - Jorge Lewis \nUsing other\'s posts as inspiration is easier than thinking from scratch.\n\n44:42 - Jorge Lewis \nusing voice using unstructured voice notes is more fun to make than writing scripts I\'m gonna say more enjoyable but then also um Using all my previous conversations and data is more efficient to produce new content than restate what I\'ve already discussed.\n\n45:33 - Jorge Lewis \nSo I\'ve got these two sides of every point. So that first one is more efficient. This one\'s more enjoyable. This one\'s ease is easier. And this last one is more enjoyable.\n\n45:56 - Jorge Lewis \nSo those are kind of the use cases I can imagine. This top one is the most business oriented where, or is the most indirect. I\'m not thinking about making content when I have conversations. It\'s just, I\'m already having conversations. Let\'s reuse that into, so extracting more value\n######################\nOutput:'}
02:07:10,547 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,550 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "a little bit of both because I wonder if I would eventually, if I would, okay, an okay example is, okay, no, no, no. So what I've been with Jonas, whenever we, We have amazing conversations. Earlier we were just discussing about SvelteKit and when we should be using form actions versus API routes and et cetera. It was a good technical conversation. If we could just take that conversation and convert it into some form of content, whether it's a snippet of that video and we can publish that or it writes a script for us or a post, anything like that would be great. So, maybe the mission isn't that it takes too much time to write content. I think it's... Can you see where I'm going with this? It's more of trying to use what I already have, which is conversations with my team, which is conversations I already have.\n\n39:06 - Biwas bhandari \nTrying to summarize it and write a blog or content, something like that.\n\n39:15 - Jorge Lewis \nBut what's the problem then? The problem is there's no way to repurpose our conversations, I guess. I don't know.\n\n39:25 - Jorge Lewis \nSo you see, this is where these workshops are very helpful because you, you're really trying to understand what you're trying to do here.\n\n39:31 - Biwas bhandari \nI think it's not the, uh, what's the problem, but what we are trying to improve maybe because right now we are having a good conversation and that's good. But, uh, what, you know, what, what could make it more effective is if you just summarize it and make a blog post so everybody can read and all that. Maybe so.\n\n39:58 - Jorge Lewis \nOkay, so the problem is that when people have conversations, that knowledge and that there's value in that conversation that gets lost as soon as that, that only gets shared to those two people after that conversation finishes. But instead we want to extract as much value as possible by recording it and then converting it into something, into content. Whether you publish it to the public or just your team.\n\n40:33 - Jorge Lewis \nSo the problem is that we don't extract enough values from conversations.\n\n40:40 - Jorge Lewis \nBut when I'm thinking, it doesn't sound very like, okay, the mission, instead of saying the problem, the mission is to make my conversations more valuable by being able to write content from them.\n\n40:58 - Jorge Lewis \nThat's the mission because that's pretty realistic. The only other time is that it's like maybe sometimes it's not my conversations, it's maybe a voice message I recorded on myself. Like I'm on a walk and I just want to discuss the topic and convert it into content afterwards.\n\n41:39 - Biwas bhandari \nSo, I think that one is different than what we were talking before.\n\n41:57 - Biwas bhandari \nYeah, just before we were talking about that, okay, I want to write a content, but I need to instead of spending my time on company, I'm spending time on brainstorming the brainstorming for the content. It takes too long time for that. And so in order to make it easier, I just need a tool that will help me. I'm thinking of making content on SAS, for example. And based on that, our product will generate a content or something like that, maybe.\n\n42:36 - Jorge Lewis \nYeah, I can see. Yeah.\n\n42:43 - Jorge Lewis \nI want to take you through a story of how I can imagine using this. So I have, I've recorded about a hundred read AI meetings between my team and clients and other people I've met within my network. So what I can imagine myself doing is uploading those transcripts or videos or whatever format to this software. And then I say, Hey, Can you write, can you help me write something about SAS on, on how to build a SAS as a non-technical founder. It'll go through all those, try to pull as much as it can from it.\n\n43:22 - Biwas bhandari \nOh yeah. So instead of pulling it from the internet and creating separate content, it will take all the transcripts you provided. And based on that, it will create a whole new content. Yeah.\n\n43:34 - Jorge Lewis \nBut there's also another aspect of this project of this, of what I want is like, I want, um, okay, okay, I'm getting, so, okay, okay, let me, I'm gonna go on top of the mission, the blue card, so, why is that so small? So, writing, or, having conversations is more fun than writing.\n\n44:05 - Unidentified Speaker \nDumb? Yeah.\n\n44:15 - Jorge Lewis \nUsing other's posts as inspiration is easier than thinking from scratch.\n\n44:42 - Jorge Lewis \nusing voice using unstructured voice notes is more fun to make than writing scripts I'm gonna say more enjoyable but then also um Using all my previous conversations and data is more efficient to produce new content than restate what I've already discussed.\n\n45:33 - Jorge Lewis \nSo I've got these two sides of every point. So that first one is more efficient. This one's more enjoyable. This one's ease is easier. And this last one is more enjoyable.\n\n45:56 - Jorge Lewis \nSo those are kind of the use cases I can imagine. This top one is the most business oriented where, or is the most indirect. I'm not thinking about making content when I have conversations. It's just, I'm already having conversations. Let's reuse that into, so extracting more value"}
02:07:10,594 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,596 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: too agreeable and programmers are often...\n\n51:38 - Biwas bhandari \nI can\'t find it.\n\n51:42 - Jorge Lewis \nSo oftentimes when, for example, the primogen, you know the primogen?\n\n51:49 - Biwas bhandari \nYeah.\n\n51:51 - Jorge Lewis \nSo he says a lot of things on his stuff, on his podcast. He reviews a lot of articles, by the way, which is like, if I watch that article, if I was a content writer, I could write a new article watching that for the Prime Agent, for example. So maybe this app, what it does is it facilitates, it records your screen And those reviews of articles and you just review it like that. Maybe that\'s how it gathers. I don\'t know. Or we can do the Tinder style where you\'re like, uh, yes, which part, uh, this part, I don\'t know.\n\n52:28 - Biwas bhandari \nOr we can just paste the link of the article and say, okay, this is the article and here are my opinions and you can send it via voice input.\n\n52:39 - Jorge Lewis \nYeah, like there\'s a lot of UXs, user experience ways to do this that would make it more accessible. But the main idea is to use that as a foundation to create or to articulate your own opinions. To give you like a... It\'s easier to say what I believe when someone says their opinion on it. Like you can say you believe in... Are you... Okay, that was a bad example.\n\n53:12 - Jorge Lewis \nIf I hear you say that using types is better than not using types, it\'s a lot easier to respond to that than just thinking, okay, what\'s an idea? Oh, types. Yeah. Right. I think we got the point. So using other people\'s posts is easier to gather our own opinion.\n\n53:40 - Jorge Lewis \nAnd then what else? Having conversations are more enjoyable. I will have more conversations.\n\n54:02 - Jorge Lewis \nWriting content, i.e.\n\n54:11 - Jorge Lewis \nHaving a conversation is more fun, so I will write more content.\n\n54:24 - Jorge Lewis \nAll right, cool. Anyways, there\'s not much, um, there\'s no format to this. Like all of these are pretty random, like what\'s on the left and right side, but I think it\'s more important to just kind of get those thoughts on paper first. And then we can use that to write something more well formatted afterwards. Okay. This misalignment is bothering me. Why is that?\n\n54:46 - Jorge Lewis \nThere we go.\n\n54:48 - Biwas bhandari \nOkay, cool.\n\n54:51 - Jorge Lewis \nAnd then, this Google Meet was supposed to be just a vision and workshop mission. A vision and mission workshop, but we ended up just going through a rabbit hole of what this project actually is. Which is the entire point of this workshop, so I guess it illustrates that. Maybe Jonas is free now at this point. Okay, so using all that.\n\n55:18 - Biwas bhandari \nSo what\'s the mission now?\n\n55:21 - Jorge Lewis \nYeah, what is the new mission?\n\n55:26 - Jorge Lewis \nLet\'s take some time and go and go iterate. So let\'s, I\'m going to go into my own corner and just think about it for a second and write it down.\n\n55:44 - Biwas bhandari \nHmm.\n\n56:33 - Jorge Lewis \nAll right, I got something out, I think. I\'ll be in the restroom real quick.\n\n57:21 - Jorge Lewis \nOops.\n\n57:35 - Jorge Lewis \nYeah.\n\n58:52 - Jorge Lewis \nHave you finished your thing?\n\n58:53 - Biwas bhandari \nYeah, I finished mine.\n\n59:09 - Jorge Lewis \nChanging your thoughts, conversations into experiences, into content by extracting relevant into them.\n\n59:36 - Jorge Lewis \nAh.\n\n59:41 - Biwas bhandari \nBut if we look at mine, the target audience will not only be content creators and entrepreneurs, but everybody, because everybody had thoughts and experiences which they want to share to others.\n\n1:00:12 - Biwas bhandari \nIt is the friction involved in content creation by making it more human.\n\n1:00:33 - Biwas bhandari \nMine one is more misaligned with the original.\n\n1:00:40 - Jorge Lewis \nIt\'s more what? More misaligned with the from the original mission so make content creation out of ideation faster and require less mental effort technically what we\'ve described does that that\'s the But I think we can narrow it down more precisely into what we\'re doing. All of these above that we list is experiences. I think we can group them into just the term experiences.\n\n1:01:30 - Jorge Lewis \nTo allow experiences to be used for content writing.\n\n1:01:38 - Jorge Lewis \nTo allow experiences to be used for content writing.\n\n1:01:46 - Jorge Lewis \nTo create content. Allow previous experiences to be used. So our mission is to allow previous experiences to be used to create content.\n\n1:02:24 - Jorge Lewis \nSo we went from making the content creation easier to enjoyable and it\'s Allowing previous experiences to be used to make content is making it faster and require less mental effort. It\'s like, I don\'t know, it\'s the same. I think we can just keep these both. We\'ll have all of this here. We don\'t have to come to a conclusion right now. I think we\'re pretty aligned on kind of the direction\n######################\nOutput:'}
02:07:10,596 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,601 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "too agreeable and programmers are often...\n\n51:38 - Biwas bhandari \nI can't find it.\n\n51:42 - Jorge Lewis \nSo oftentimes when, for example, the primogen, you know the primogen?\n\n51:49 - Biwas bhandari \nYeah.\n\n51:51 - Jorge Lewis \nSo he says a lot of things on his stuff, on his podcast. He reviews a lot of articles, by the way, which is like, if I watch that article, if I was a content writer, I could write a new article watching that for the Prime Agent, for example. So maybe this app, what it does is it facilitates, it records your screen And those reviews of articles and you just review it like that. Maybe that's how it gathers. I don't know. Or we can do the Tinder style where you're like, uh, yes, which part, uh, this part, I don't know.\n\n52:28 - Biwas bhandari \nOr we can just paste the link of the article and say, okay, this is the article and here are my opinions and you can send it via voice input.\n\n52:39 - Jorge Lewis \nYeah, like there's a lot of UXs, user experience ways to do this that would make it more accessible. But the main idea is to use that as a foundation to create or to articulate your own opinions. To give you like a... It's easier to say what I believe when someone says their opinion on it. Like you can say you believe in... Are you... Okay, that was a bad example.\n\n53:12 - Jorge Lewis \nIf I hear you say that using types is better than not using types, it's a lot easier to respond to that than just thinking, okay, what's an idea? Oh, types. Yeah. Right. I think we got the point. So using other people's posts is easier to gather our own opinion.\n\n53:40 - Jorge Lewis \nAnd then what else? Having conversations are more enjoyable. I will have more conversations.\n\n54:02 - Jorge Lewis \nWriting content, i.e.\n\n54:11 - Jorge Lewis \nHaving a conversation is more fun, so I will write more content.\n\n54:24 - Jorge Lewis \nAll right, cool. Anyways, there's not much, um, there's no format to this. Like all of these are pretty random, like what's on the left and right side, but I think it's more important to just kind of get those thoughts on paper first. And then we can use that to write something more well formatted afterwards. Okay. This misalignment is bothering me. Why is that?\n\n54:46 - Jorge Lewis \nThere we go.\n\n54:48 - Biwas bhandari \nOkay, cool.\n\n54:51 - Jorge Lewis \nAnd then, this Google Meet was supposed to be just a vision and workshop mission. A vision and mission workshop, but we ended up just going through a rabbit hole of what this project actually is. Which is the entire point of this workshop, so I guess it illustrates that. Maybe Jonas is free now at this point. Okay, so using all that.\n\n55:18 - Biwas bhandari \nSo what's the mission now?\n\n55:21 - Jorge Lewis \nYeah, what is the new mission?\n\n55:26 - Jorge Lewis \nLet's take some time and go and go iterate. So let's, I'm going to go into my own corner and just think about it for a second and write it down.\n\n55:44 - Biwas bhandari \nHmm.\n\n56:33 - Jorge Lewis \nAll right, I got something out, I think. I'll be in the restroom real quick.\n\n57:21 - Jorge Lewis \nOops.\n\n57:35 - Jorge Lewis \nYeah.\n\n58:52 - Jorge Lewis \nHave you finished your thing?\n\n58:53 - Biwas bhandari \nYeah, I finished mine.\n\n59:09 - Jorge Lewis \nChanging your thoughts, conversations into experiences, into content by extracting relevant into them.\n\n59:36 - Jorge Lewis \nAh.\n\n59:41 - Biwas bhandari \nBut if we look at mine, the target audience will not only be content creators and entrepreneurs, but everybody, because everybody had thoughts and experiences which they want to share to others.\n\n1:00:12 - Biwas bhandari \nIt is the friction involved in content creation by making it more human.\n\n1:00:33 - Biwas bhandari \nMine one is more misaligned with the original.\n\n1:00:40 - Jorge Lewis \nIt's more what? More misaligned with the from the original mission so make content creation out of ideation faster and require less mental effort technically what we've described does that that's the But I think we can narrow it down more precisely into what we're doing. All of these above that we list is experiences. I think we can group them into just the term experiences.\n\n1:01:30 - Jorge Lewis \nTo allow experiences to be used for content writing.\n\n1:01:38 - Jorge Lewis \nTo allow experiences to be used for content writing.\n\n1:01:46 - Jorge Lewis \nTo create content. Allow previous experiences to be used. So our mission is to allow previous experiences to be used to create content.\n\n1:02:24 - Jorge Lewis \nSo we went from making the content creation easier to enjoyable and it's Allowing previous experiences to be used to make content is making it faster and require less mental effort. It's like, I don't know, it's the same. I think we can just keep these both. We'll have all of this here. We don't have to come to a conclusion right now. I think we're pretty aligned on kind of the direction"}
02:07:10,645 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,647 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: create content.\n\n1:02:24 - Jorge Lewis \nSo we went from making the content creation easier to enjoyable and it\'s Allowing previous experiences to be used to make content is making it faster and require less mental effort. It\'s like, I don\'t know, it\'s the same. I think we can just keep these both. We\'ll have all of this here. We don\'t have to come to a conclusion right now. I think we\'re pretty aligned on kind of the direction, but the line that we go in, it can be defined later, maybe with Jonas\' help.\n\n1:03:05 - Biwas bhandari \nYeah. Content can be made not only through previous experiences to only maybe we can create content about anything, not only previous experiences.\n\n1:03:21 - Jorge Lewis \nYeah. Like also like if we use, Hmm, I think, I think the mission, I think this mission makes sense, but I think what we change is the vision. Maybe.\n\n1:03:30 - Unidentified Speaker \nYeah.\n\n1:03:32 - Jorge Lewis \nLet\'s, um, Let me see. This is accurate. This is what the platform should be doing. It should create content if it were me. Not only the style, this is the vision, the means, how we get there. These are what I want to do to get there. I want to use conversations. I want to use my unstructured voice notes. I want to use other people\'s posts as inspirations. I want to use my, yeah.\n\n1:04:02 - Biwas bhandari \nBut initially we can, uh, make the app that can just, uh, create a content based on your, um, the one that was initially, uh, what do you call it? Proposed or something like that.\n\n1:04:22 - Biwas bhandari \nSo you want to write a content, but you are just, uh, and you have the idea too, but you are just not able to start writing it in a copy and all that. So for that, uh, our AI chat bot can help you. Uh, visualize, uh, not visualize. How do you call it? Give a certain context or ideas or just write the content.\n\n1:04:54 - Jorge Lewis \nI think so for me, at least I don\'t think the ideas are too hard right now. Ideas become hard or no, no, no. In every, so in every day, every day I have a lot of conversations and I\'m quite sure that I don\'t need to create new ideas to write about. I can use those conversations to make ideas. Like I say, Hey, are there any types of like, are there any cool posts I can make from today\'s news?\n\n1:05:23 - Unidentified Speaker \nYeah.\n\n1:05:24 - Biwas bhandari \nYeah. That can be great.\n\n1:05:30 - Jorge Lewis \nSo that instead of when you\'re writing a voice memo, instead of thinking, oh, this is going to be making a video. You\'re just talking like in general, like you can go from talking about the problems SAS founders make to, um, to ugly code. And then you can go to architectural problems. And in the end, it won\'t matter because all you\'re going to do is insert this into, um, the AI chatbot and he\'ll use it when relevant. So like, um, so. Yeah, okay, cool. We can touch on this. Hopefully Jonas can watch all this and see us going in circles and maybe help us figure out where we want to go. Because usually how this works is there\'s one facilitator, the project owner, and then the stakeholders, so like, and the developers, I guess. So it\'d be helpful if, because I\'m also, I\'m facilitating, developing, and the owner. So I don\'t know if that\'s helpful or not. I don\'t think that\'s helpful.\n\n1:06:30 - Jorge Lewis \nAnd Jonas has watched quite a lot of, he\'s educated quite a lot on this. I\'ve just done this workshop once with Jonas and here I am trying to do one. All right. Well, I guess let\'s just leave it at there. We can go into the road. I don\'t know. Let\'s go into the roadmap maybe.\n\n1:07:05 - Jorge Lewis \nLet me, uh oh. Are we in the wrong file again?\n\n1:07:13 - Jorge Lewis \nNot the right one. Let me rename it. I think I\'m just gonna copy all of this and paste it into the other file and just use a different page because going through, going between different files is really inefficient.\n\n1:07:32 - Biwas bhandari \nOkay. All right.\n\n1:07:40 - Jorge Lewis \nSo I pasted it there.\n\n1:07:41 - Biwas bhandari \nWord bet.\n\n1:08:11 - Jorge Lewis \nSo we have the conception, and then the vision and mission, and then the planning.\n\n1:08:18 - Jorge Lewis \nSo the planning will define the backlog pretty much, the features we\'re going to build.\n\n1:08:31 - Jorge Lewis \nAnd which features we want to build first, and when, and all that. So, very tiring, huh?\n\n1:08:47 - Jorge Lewis \nSo, let\'s see. Also, wait.\n\n1:08:55 - Jorge Lewis \nWill requested access to something.\n\n1:09:28 - Jorge Lewis \nSo we want to get into the roadmap and kind of the features. So I\'m going to borrow this from here. And if you go to the\n######################\nOutput:'}
02:07:10,647 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,650 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "create content.\n\n1:02:24 - Jorge Lewis \nSo we went from making the content creation easier to enjoyable and it's Allowing previous experiences to be used to make content is making it faster and require less mental effort. It's like, I don't know, it's the same. I think we can just keep these both. We'll have all of this here. We don't have to come to a conclusion right now. I think we're pretty aligned on kind of the direction, but the line that we go in, it can be defined later, maybe with Jonas' help.\n\n1:03:05 - Biwas bhandari \nYeah. Content can be made not only through previous experiences to only maybe we can create content about anything, not only previous experiences.\n\n1:03:21 - Jorge Lewis \nYeah. Like also like if we use, Hmm, I think, I think the mission, I think this mission makes sense, but I think what we change is the vision. Maybe.\n\n1:03:30 - Unidentified Speaker \nYeah.\n\n1:03:32 - Jorge Lewis \nLet's, um, Let me see. This is accurate. This is what the platform should be doing. It should create content if it were me. Not only the style, this is the vision, the means, how we get there. These are what I want to do to get there. I want to use conversations. I want to use my unstructured voice notes. I want to use other people's posts as inspirations. I want to use my, yeah.\n\n1:04:02 - Biwas bhandari \nBut initially we can, uh, make the app that can just, uh, create a content based on your, um, the one that was initially, uh, what do you call it? Proposed or something like that.\n\n1:04:22 - Biwas bhandari \nSo you want to write a content, but you are just, uh, and you have the idea too, but you are just not able to start writing it in a copy and all that. So for that, uh, our AI chat bot can help you. Uh, visualize, uh, not visualize. How do you call it? Give a certain context or ideas or just write the content.\n\n1:04:54 - Jorge Lewis \nI think so for me, at least I don't think the ideas are too hard right now. Ideas become hard or no, no, no. In every, so in every day, every day I have a lot of conversations and I'm quite sure that I don't need to create new ideas to write about. I can use those conversations to make ideas. Like I say, Hey, are there any types of like, are there any cool posts I can make from today's news?\n\n1:05:23 - Unidentified Speaker \nYeah.\n\n1:05:24 - Biwas bhandari \nYeah. That can be great.\n\n1:05:30 - Jorge Lewis \nSo that instead of when you're writing a voice memo, instead of thinking, oh, this is going to be making a video. You're just talking like in general, like you can go from talking about the problems SAS founders make to, um, to ugly code. And then you can go to architectural problems. And in the end, it won't matter because all you're going to do is insert this into, um, the AI chatbot and he'll use it when relevant. So like, um, so. Yeah, okay, cool. We can touch on this. Hopefully Jonas can watch all this and see us going in circles and maybe help us figure out where we want to go. Because usually how this works is there's one facilitator, the project owner, and then the stakeholders, so like, and the developers, I guess. So it'd be helpful if, because I'm also, I'm facilitating, developing, and the owner. So I don't know if that's helpful or not. I don't think that's helpful.\n\n1:06:30 - Jorge Lewis \nAnd Jonas has watched quite a lot of, he's educated quite a lot on this. I've just done this workshop once with Jonas and here I am trying to do one. All right. Well, I guess let's just leave it at there. We can go into the road. I don't know. Let's go into the roadmap maybe.\n\n1:07:05 - Jorge Lewis \nLet me, uh oh. Are we in the wrong file again?\n\n1:07:13 - Jorge Lewis \nNot the right one. Let me rename it. I think I'm just gonna copy all of this and paste it into the other file and just use a different page because going through, going between different files is really inefficient.\n\n1:07:32 - Biwas bhandari \nOkay. All right.\n\n1:07:40 - Jorge Lewis \nSo I pasted it there.\n\n1:07:41 - Biwas bhandari \nWord bet.\n\n1:08:11 - Jorge Lewis \nSo we have the conception, and then the vision and mission, and then the planning.\n\n1:08:18 - Jorge Lewis \nSo the planning will define the backlog pretty much, the features we're going to build.\n\n1:08:31 - Jorge Lewis \nAnd which features we want to build first, and when, and all that. So, very tiring, huh?\n\n1:08:47 - Jorge Lewis \nSo, let's see. Also, wait.\n\n1:08:55 - Jorge Lewis \nWill requested access to something.\n\n1:09:28 - Jorge Lewis \nSo we want to get into the roadmap and kind of the features. So I'm going to borrow this from here. And if you go to the"}
02:07:10,752 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,754 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Will / Jorge - Pair Programming \nWed, Aug 7, 2024\n\n0:04 - Jorge Lewis \nSo yeah, so let\'s do the, what do I wanna work on today? The signup stuff?\n\n0:09 - Will Vincent Parrone \nYeah, so wait, let me just finish this up. I\'m just gonna be removing this.\n\n0:25 - Will Vincent Parrone \nYeah, so just a rundown on my code. So basically, this is a really simple prototype right now that I\'m working on. In the sign-in, what was discussed is that we\'re going to be using passwordless kind of authentication.\n\n0:48 - Will Vincent Parrone \nassume that we\'re going to be using OTP. So the way I did it is I created basically the status.\n\n0:58 - Jorge Lewis \nBut have you discussed? So for each feature, we\'ve kind of concluded that we should be discussing with the client for each small feature to make sure all these small things are clarified. Right.\n\n1:11 - Will Vincent Parrone \nAll right. We discussed this with Q1, I think.\n\n1:18 - Will Vincent Parrone \ndays ago before we even finished the scope. Basically, what Q1 wants here is that it\'s going to be passwordless and not done along with the chatbot, like a separate UI for the sign-in.\n\n1:38 - Jorge Lewis \nI don\'t want to interrupt the pair programming session, but just so that we make sure we don\'t work on something that we won\'t use. There\'s two sections to the user authentication with Adapt. The first one is the anonymous authentication where there\'s no required credentials or input from the user. And the second is a sign up page where after they\'ve completed the workshop, they can sign up. Right? So far so good?\n\n2:14 - Will Vincent Parrone \nYep.\n\n2:18 - Jorge Lewis \nAnd then you\'re telling me that you guys said you\'re going to use single SSO for the signup page. Yeah.\n\n2:27 - Will Vincent Parrone \nYeah?\n\n2:31 - Unidentified Speaker \nYeah.\n\n2:37 - Jorge Lewis \nOkay.\n\n2:37 - Jorge Lewis \nBut what about, so has he said we, so are we not going to use Google authentication or Facebook authentication or?\n\n2:47 - Will Vincent Parrone \nActually, we haven\'t discussed this.\n\n2:49 - Jorge Lewis \nBecause Superbase gives those to us, and it\'s surprisingly easy to integrate. I think we should be- Okay, okay. Yeah, wait, I\'ll- No, no, I gotcha, I gotcha.\n\n3:01 - Jorge Lewis \nOkay, okay.\n\n3:02 - Jorge Lewis \nSo let\'s, let\'s, um...\n\n3:09 - Jorge Lewis \nLet\'s...\n\n3:11 - Jorge Lewis \nSee...\n\n3:13 - Jorge Lewis \nLet\'s ask him, then.\n\n3:18 - Jorge Lewis \nSo, ask him in AdaptDev at Kuen and say, hey, I\'m working on the sign-up thing or the user authentication now. What do you want to include? So, the options are this, this, and this. Make sure to include kind of how the user experience is for each. So, for a Google sign-on, or Google sign up, what that means is that they can sign in, they click, maybe you can send some examples, kind of, you click the Google sign up, sign up with Google, it takes, it opens the pop up of Google and they click their Google account and it\'s in. Explain that to him, because I don\'t know, he probably knows, but I think it\'s good to illustrate with examples. Because like for example, JP probably won\'t know, so we want to kind of pretend Kuin doesn\'t know any technical things, but he does.\n\n4:18 - Will Vincent Parrone \nI\'m messaging him right now.\n\n4:28 - Jorge Lewis \nHave you done any OAuth authentication with Superbase?\n\n4:34 - Will Vincent Parrone \nTo be honest, no.\n\n4:41 - Will Vincent Parrone \nI think the authentication that I did was on Firebase.\n\n4:48 - Jorge Lewis \nNo, it\'s fine, bro. Don\'t worry. I don\'t need know-it-alls. I need fast learn.\n\n4:56 - Jorge Lewis \nOK. And on Firebase, was that single sign-on or was that using Google or?\n\n5:07 - Will Vincent Parrone \nI did an option wherein I tried Google Authentication, and then what I\'m slightly more familiar with is using the email and password to sign in.\n\n5:27 - Will Vincent Parrone \nHello? Sorry?\n\n5:27 - Jorge Lewis \nYeah, me too.\n\n5:31 - Jorge Lewis \nOk.\n\n5:32 - Jorge Lewis \nYeah, I\'ve only done email and password and then I think anonymous as well. There\'s actually a project we, I\'ve only done email and anonymous as well. We have a project, we have a project, IT, you know, actually, are you aware, like, do you know ITNO?\n\n6:00 - Will Vincent Parrone \nArtino, I saw it. Yeah, yeah, yeah, yeah. When I searched Artino, Artino came up.\n\n6:09 - Will Vincent Parrone \nRight there?\n\n6:10 - Will Vincent Parrone \nHello, hello. My mic is not picking up, but I saw Artino one time, I think, in the messages while searching for something.\n\n6:23 - Jorge Lewis \nYeah, so I, yeah, yeah.\n\n6:30 - Jorge Lewis \nAetino is our AI project we worked on before. It was kind of\n######################\nOutput:'}
02:07:10,754 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,757 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Will / Jorge - Pair Programming \nWed, Aug 7, 2024\n\n0:04 - Jorge Lewis \nSo yeah, so let's do the, what do I wanna work on today? The signup stuff?\n\n0:09 - Will Vincent Parrone \nYeah, so wait, let me just finish this up. I'm just gonna be removing this.\n\n0:25 - Will Vincent Parrone \nYeah, so just a rundown on my code. So basically, this is a really simple prototype right now that I'm working on. In the sign-in, what was discussed is that we're going to be using passwordless kind of authentication.\n\n0:48 - Will Vincent Parrone \nassume that we're going to be using OTP. So the way I did it is I created basically the status.\n\n0:58 - Jorge Lewis \nBut have you discussed? So for each feature, we've kind of concluded that we should be discussing with the client for each small feature to make sure all these small things are clarified. Right.\n\n1:11 - Will Vincent Parrone \nAll right. We discussed this with Q1, I think.\n\n1:18 - Will Vincent Parrone \ndays ago before we even finished the scope. Basically, what Q1 wants here is that it's going to be passwordless and not done along with the chatbot, like a separate UI for the sign-in.\n\n1:38 - Jorge Lewis \nI don't want to interrupt the pair programming session, but just so that we make sure we don't work on something that we won't use. There's two sections to the user authentication with Adapt. The first one is the anonymous authentication where there's no required credentials or input from the user. And the second is a sign up page where after they've completed the workshop, they can sign up. Right? So far so good?\n\n2:14 - Will Vincent Parrone \nYep.\n\n2:18 - Jorge Lewis \nAnd then you're telling me that you guys said you're going to use single SSO for the signup page. Yeah.\n\n2:27 - Will Vincent Parrone \nYeah?\n\n2:31 - Unidentified Speaker \nYeah.\n\n2:37 - Jorge Lewis \nOkay.\n\n2:37 - Jorge Lewis \nBut what about, so has he said we, so are we not going to use Google authentication or Facebook authentication or?\n\n2:47 - Will Vincent Parrone \nActually, we haven't discussed this.\n\n2:49 - Jorge Lewis \nBecause Superbase gives those to us, and it's surprisingly easy to integrate. I think we should be- Okay, okay. Yeah, wait, I'll- No, no, I gotcha, I gotcha.\n\n3:01 - Jorge Lewis \nOkay, okay.\n\n3:02 - Jorge Lewis \nSo let's, let's, um...\n\n3:09 - Jorge Lewis \nLet's...\n\n3:11 - Jorge Lewis \nSee...\n\n3:13 - Jorge Lewis \nLet's ask him, then.\n\n3:18 - Jorge Lewis \nSo, ask him in AdaptDev at Kuen and say, hey, I'm working on the sign-up thing or the user authentication now. What do you want to include? So, the options are this, this, and this. Make sure to include kind of how the user experience is for each. So, for a Google sign-on, or Google sign up, what that means is that they can sign in, they click, maybe you can send some examples, kind of, you click the Google sign up, sign up with Google, it takes, it opens the pop up of Google and they click their Google account and it's in. Explain that to him, because I don't know, he probably knows, but I think it's good to illustrate with examples. Because like for example, JP probably won't know, so we want to kind of pretend Kuin doesn't know any technical things, but he does.\n\n4:18 - Will Vincent Parrone \nI'm messaging him right now.\n\n4:28 - Jorge Lewis \nHave you done any OAuth authentication with Superbase?\n\n4:34 - Will Vincent Parrone \nTo be honest, no.\n\n4:41 - Will Vincent Parrone \nI think the authentication that I did was on Firebase.\n\n4:48 - Jorge Lewis \nNo, it's fine, bro. Don't worry. I don't need know-it-alls. I need fast learn.\n\n4:56 - Jorge Lewis \nOK. And on Firebase, was that single sign-on or was that using Google or?\n\n5:07 - Will Vincent Parrone \nI did an option wherein I tried Google Authentication, and then what I'm slightly more familiar with is using the email and password to sign in.\n\n5:27 - Will Vincent Parrone \nHello? Sorry?\n\n5:27 - Jorge Lewis \nYeah, me too.\n\n5:31 - Jorge Lewis \nOk.\n\n5:32 - Jorge Lewis \nYeah, I've only done email and password and then I think anonymous as well. There's actually a project we, I've only done email and anonymous as well. We have a project, we have a project, IT, you know, actually, are you aware, like, do you know ITNO?\n\n6:00 - Will Vincent Parrone \nArtino, I saw it. Yeah, yeah, yeah, yeah. When I searched Artino, Artino came up.\n\n6:09 - Will Vincent Parrone \nRight there?\n\n6:10 - Will Vincent Parrone \nHello, hello. My mic is not picking up, but I saw Artino one time, I think, in the messages while searching for something.\n\n6:23 - Jorge Lewis \nYeah, so I, yeah, yeah.\n\n6:30 - Jorge Lewis \nAetino is our AI project we worked on before. It was kind of"}
02:07:10,766 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,770 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Jorge Lewis \nAnd which features we want to build first, and when, and all that. So, very tiring, huh?\n\n1:08:47 - Jorge Lewis \nSo, let\'s see. Also, wait.\n\n1:08:55 - Jorge Lewis \nWill requested access to something.\n\n1:09:28 - Jorge Lewis \nSo we want to get into the roadmap and kind of the features. So I\'m going to borrow this from here. And if you go to the planning page, are you following along, by the way?\n\n1:09:37 - Biwas bhandari \nI\'m just watching it in this screen.\n\n1:09:49 - Jorge Lewis \nI think the only feature we\'re building is the chatbot.\n\n1:10:09 - Jorge Lewis \nOn the front end, we just need a chatbot. And that chatbot\'s going to need to have all the capabilities.\n\n1:10:19 - Jorge Lewis \nI\'m just kind of going off of nothing here. So we have the chatbot.\n\n1:10:27 - Jorge Lewis \nAnd this guy needs...\n\n1:10:39 - Jorge Lewis \nLet\'s start with just trick like or actually just two And then Needs a good strategy to write good content So the strategy to write good content is gonna be the hardest part because hmm And it\'s going to require a lot of figuring out the best way to make.\n\n1:11:14 - Jorge Lewis \nBecause I think the hard part about this. Yeah. I mean, the only the the unique value proposition of this is that we can convert anything into content.\n\n1:11:26 - Jorge Lewis \nLike any text in any conversation or transcript or meeting, anything like that, we can convert into content.\n\n1:11:34 - Biwas bhandari \nMm hmm.\n\n1:11:35 - Jorge Lewis \nAnd to do that, we need a system that\'s really good at that. And how can we tell this bot to make good content if we don\'t know how to make good content ourselves? So we have a lot of homework to do, and we have to figure out how to make good content.\n\n1:11:53 - Jorge Lewis \nThere\'s actually one guy I know. Oh, this is pretty funny. What\'s his name?\n\n1:12:01 - Jorge Lewis \nYes, luckily me. This guy.\n\n1:12:05 - Biwas bhandari \nNo.\n\n1:12:07 - Jorge Lewis \nI think he does, um, like he teaches people how to do content creation. Okay.\n\n1:12:15 - Jorge Lewis \nIt doesn\'t seem like it.\n\n1:12:23 - Jorge Lewis \nI don\'t know, but what we have to do is a lot of research and figuring out how to make, we need to figure out the graph we want to use, the structure, the cognitive architecture we want to use, and then That\'s one thing that\'s for the technical implementation and then also how to make good content. So how can we teach this chatbot to make good content?\n\n1:12:52 - Biwas bhandari \nSo one part is we need to, okay, we ourselves need to know how to make a good content at first, or we need to just research a bit on that. And for the technical part of the chatbot.\n\n1:13:09 - Jorge Lewis \nSo the chatbot has access to the files, but it\'s not using the files. It\'s using a knowledge, like I think the knowledge graph is the way to go for this.\n\n1:13:31 - Jorge Lewis \nYou know knowledge graphs, right?\n\n1:13:32 - Biwas bhandari \nYeah.\n\n1:13:34 - Jorge Lewis \nYeah.\n\n1:13:37 - Jorge Lewis \nSo just figuring out how do we make this chatbot do this well. And we can plan this all we want. The best way to go about it is probably to make an MVP in like three hours and see how how like a just normal chatbot tries to make content from a transcript. So I think the first step, like for me, my intuition just tells me, okay, let\'s create a knowledge graph from a bunch of transcripts. So I\'m going to take all my, and I want to use existing data so that it just saves time. So I\'m going to take all these reports, print out the transcripts, upload it to Superbit, or no, that\'s already over-complicating it. Just use those text files locally. Yeah.\n\n1:14:27 - Biwas bhandari \nAnd then we can just pass it. These are the con. Yeah. Pass it as a input instead of saving it in.\n\n1:14:37 - Jorge Lewis \nYeah. Take out, um, check out graph reg. This start the, this is what we\'ll be using to, to make this happen. At first it uses, um, it uses an LLM to make a graph, a graph like this. Then these are the steps of indexing it. And then at the end, it queries it using an LLM as well. So for vector databases, we have a model that creates the vector database. It decides, it knows what words are to place where in the vector space. For this one, it knows where to place things relative to other things. That\'s all these steps. So what we can do is play around and this is why I\'m doing it in Python for one one reason is because Everything is in Python like this is in Python. So, okay One warning one warning for you specifically. Yeah is Warning graph reg indexing can be expensive. I looking into this and implementing it. So my intuition is just telling me, okay\n######################\nOutput:'}
02:07:10,770 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,773 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Jorge Lewis \nAnd which features we want to build first, and when, and all that. So, very tiring, huh?\n\n1:08:47 - Jorge Lewis \nSo, let's see. Also, wait.\n\n1:08:55 - Jorge Lewis \nWill requested access to something.\n\n1:09:28 - Jorge Lewis \nSo we want to get into the roadmap and kind of the features. So I'm going to borrow this from here. And if you go to the planning page, are you following along, by the way?\n\n1:09:37 - Biwas bhandari \nI'm just watching it in this screen.\n\n1:09:49 - Jorge Lewis \nI think the only feature we're building is the chatbot.\n\n1:10:09 - Jorge Lewis \nOn the front end, we just need a chatbot. And that chatbot's going to need to have all the capabilities.\n\n1:10:19 - Jorge Lewis \nI'm just kind of going off of nothing here. So we have the chatbot.\n\n1:10:27 - Jorge Lewis \nAnd this guy needs...\n\n1:10:39 - Jorge Lewis \nLet's start with just trick like or actually just two And then Needs a good strategy to write good content So the strategy to write good content is gonna be the hardest part because hmm And it's going to require a lot of figuring out the best way to make.\n\n1:11:14 - Jorge Lewis \nBecause I think the hard part about this. Yeah. I mean, the only the the unique value proposition of this is that we can convert anything into content.\n\n1:11:26 - Jorge Lewis \nLike any text in any conversation or transcript or meeting, anything like that, we can convert into content.\n\n1:11:34 - Biwas bhandari \nMm hmm.\n\n1:11:35 - Jorge Lewis \nAnd to do that, we need a system that's really good at that. And how can we tell this bot to make good content if we don't know how to make good content ourselves? So we have a lot of homework to do, and we have to figure out how to make good content.\n\n1:11:53 - Jorge Lewis \nThere's actually one guy I know. Oh, this is pretty funny. What's his name?\n\n1:12:01 - Jorge Lewis \nYes, luckily me. This guy.\n\n1:12:05 - Biwas bhandari \nNo.\n\n1:12:07 - Jorge Lewis \nI think he does, um, like he teaches people how to do content creation. Okay.\n\n1:12:15 - Jorge Lewis \nIt doesn't seem like it.\n\n1:12:23 - Jorge Lewis \nI don't know, but what we have to do is a lot of research and figuring out how to make, we need to figure out the graph we want to use, the structure, the cognitive architecture we want to use, and then That's one thing that's for the technical implementation and then also how to make good content. So how can we teach this chatbot to make good content?\n\n1:12:52 - Biwas bhandari \nSo one part is we need to, okay, we ourselves need to know how to make a good content at first, or we need to just research a bit on that. And for the technical part of the chatbot.\n\n1:13:09 - Jorge Lewis \nSo the chatbot has access to the files, but it's not using the files. It's using a knowledge, like I think the knowledge graph is the way to go for this.\n\n1:13:31 - Jorge Lewis \nYou know knowledge graphs, right?\n\n1:13:32 - Biwas bhandari \nYeah.\n\n1:13:34 - Jorge Lewis \nYeah.\n\n1:13:37 - Jorge Lewis \nSo just figuring out how do we make this chatbot do this well. And we can plan this all we want. The best way to go about it is probably to make an MVP in like three hours and see how how like a just normal chatbot tries to make content from a transcript. So I think the first step, like for me, my intuition just tells me, okay, let's create a knowledge graph from a bunch of transcripts. So I'm going to take all my, and I want to use existing data so that it just saves time. So I'm going to take all these reports, print out the transcripts, upload it to Superbit, or no, that's already over-complicating it. Just use those text files locally. Yeah.\n\n1:14:27 - Biwas bhandari \nAnd then we can just pass it. These are the con. Yeah. Pass it as a input instead of saving it in.\n\n1:14:37 - Jorge Lewis \nYeah. Take out, um, check out graph reg. This start the, this is what we'll be using to, to make this happen. At first it uses, um, it uses an LLM to make a graph, a graph like this. Then these are the steps of indexing it. And then at the end, it queries it using an LLM as well. So for vector databases, we have a model that creates the vector database. It decides, it knows what words are to place where in the vector space. For this one, it knows where to place things relative to other things. That's all these steps. So what we can do is play around and this is why I'm doing it in Python for one one reason is because Everything is in Python like this is in Python. So, okay One warning one warning for you specifically. Yeah is Warning graph reg indexing can be expensive. I looking into this and implementing it. So my intuition is just telling me, okay"}
02:07:10,815 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,816 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: place where in the vector space. For this one, it knows where to place things relative to other things. That\'s all these steps. So what we can do is play around and this is why I\'m doing it in Python for one one reason is because Everything is in Python like this is in Python. So, okay One warning one warning for you specifically. Yeah is Warning graph reg indexing can be expensive. I looking into this and implementing it. So my intuition is just telling me, okay, I\'m gonna start, I\'m gonna make a knowledge graph from all the transcripts I have, and then I\'m going to just try from there to just out of the box, see if the knowledge graph can make some content, like anything. If it does an okay job of that, I\'ll be like, okay, this is easier than I thought. If it doesn\'t, that\'s what I\'m expecting, then I\'ll have to look at things like, a flow of, okay, first we\'re going to gather all the topics in the idea of this, all the pieces of content, or we\'ll create a topic and then sub topics and then everything like that. And then we gather content from there. So like, just figure out the flow.\n\n1:16:28 - Biwas bhandari \nYeah. For me personally, I don\'t know what values to content provide. So I need to look on that too.\n\n1:16:35 - Jorge Lewis \nWhat values?\n\n1:16:36 - Biwas bhandari \nWhat are the benefits of content writing?\n\n1:16:40 - Jorge Lewis \nWhat do you mean benefits?\n\n1:16:42 - Biwas bhandari \nI mean, uh, what good kind of content, um, I mean, I don\'t know. Okay. I mean, I don\'t know what good values to content writing provides personally.\n\n1:16:55 - Jorge Lewis \nOh, you mean like you don\'t know what good content is, you mean, or no, no, no.\n\n1:17:01 - Biwas bhandari \nWhat, what is the benefit of writing content?\n\n1:17:06 - Jorge Lewis \nOh, I mean the benefit. How is that important?\n\n1:17:14 - Biwas bhandari \nI personally need to know, I think maybe in order to create this app, I need to do some research on content writing and all that, since I personally have no knowledge on all these things.\n\n1:17:26 - Jorge Lewis \nBut you want to write, you write blog articles, right? You like that?\n\n1:17:31 - Biwas bhandari \nNo.\n\n1:17:36 - Biwas bhandari \nI\'ve written one too. But I\'ve heard every developer saying every developer should write articles and blogs.\n\n1:17:44 - Jorge Lewis \nBut do you enjoy it?\n\n1:17:46 - Unidentified Speaker \nNo.\n\n1:17:50 - Biwas bhandari \nI like making videos instead of writing blogs.\n\n1:17:54 - Jorge Lewis \nOkay, that\'s already the reason, because you enjoy it. For most content, it depends what you\'re doing it for. For Startino, there\'s a couple reasons. First one is because it can attract clients. It shows our expertise. It shows we have an online presence and we\'re real people. Another reason is because I would enjoy I know the team would enjoy making those videos, like a competition of our team making the best chess or something. I would enjoy making that and I know other team members would enjoy it.\n\n1:18:26 - Jorge Lewis \nIt also might be a way to recruit talent. The reasons I think are kind of, they depend on you.\n\n1:18:36 - Jorge Lewis \nLike, why would you write content? I don\'t know. It really depends on you. For me, for my personal channel, for example, I like doing that because I get to reflect on what I respect, reflect on my life. I\'ve learned, but also because I can help other people that are in similar situations. And also because I know in the longterm, having a personal brand is very powerful.\n\n1:19:00 - Biwas bhandari \nYeah.\n\n1:19:10 - Jorge Lewis \nAlright, Quen\'s asking me to call, but I need to go use the restroom and I gotta go to Jiu-Jitsu.\n\n1:19:22 - Biwas bhandari \nYeah, I think we can end this session for today. Yeah, so...\n\n1:19:29 - Jorge Lewis \nAre you hopping on tonight?\n\n1:19:33 - Biwas bhandari \nYeah, I\'ll hop on.\n\n1:19:34 - Jorge Lewis \nAll right, um, I\'ll I\'ll try to hop on since I\'m excited. I might have the motivation But yeah, I\'m excited about this Hopefully, it\'s not too hard but like for me I\'m gonna be really annoyed because it\'s not gonna be perfect because yeah, he sucks at making content I hate reading chativity content every time I\'m on LinkedIn. I read chativity content.\n\n1:19:59 - Biwas bhandari \nI\'m just So annoying Yeah, if I go faster than you, I\'ll do some research on this topic.\n\n1:20:11 - Jorge Lewis \nYeah. If, if you want, you can merge your research with trying to use graph rag.\n\n1:20:16 - Biwas bhandari \nYeah.\n\n1:20:17 - Jorge Lewis \nUm, you just, it\'s the installation is really simple. There\'s a lot of tutorials online as well that I found quite useful\n######################\nOutput:'}
02:07:10,817 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,819 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "place where in the vector space. For this one, it knows where to place things relative to other things. That's all these steps. So what we can do is play around and this is why I'm doing it in Python for one one reason is because Everything is in Python like this is in Python. So, okay One warning one warning for you specifically. Yeah is Warning graph reg indexing can be expensive. I looking into this and implementing it. So my intuition is just telling me, okay, I'm gonna start, I'm gonna make a knowledge graph from all the transcripts I have, and then I'm going to just try from there to just out of the box, see if the knowledge graph can make some content, like anything. If it does an okay job of that, I'll be like, okay, this is easier than I thought. If it doesn't, that's what I'm expecting, then I'll have to look at things like, a flow of, okay, first we're going to gather all the topics in the idea of this, all the pieces of content, or we'll create a topic and then sub topics and then everything like that. And then we gather content from there. So like, just figure out the flow.\n\n1:16:28 - Biwas bhandari \nYeah. For me personally, I don't know what values to content provide. So I need to look on that too.\n\n1:16:35 - Jorge Lewis \nWhat values?\n\n1:16:36 - Biwas bhandari \nWhat are the benefits of content writing?\n\n1:16:40 - Jorge Lewis \nWhat do you mean benefits?\n\n1:16:42 - Biwas bhandari \nI mean, uh, what good kind of content, um, I mean, I don't know. Okay. I mean, I don't know what good values to content writing provides personally.\n\n1:16:55 - Jorge Lewis \nOh, you mean like you don't know what good content is, you mean, or no, no, no.\n\n1:17:01 - Biwas bhandari \nWhat, what is the benefit of writing content?\n\n1:17:06 - Jorge Lewis \nOh, I mean the benefit. How is that important?\n\n1:17:14 - Biwas bhandari \nI personally need to know, I think maybe in order to create this app, I need to do some research on content writing and all that, since I personally have no knowledge on all these things.\n\n1:17:26 - Jorge Lewis \nBut you want to write, you write blog articles, right? You like that?\n\n1:17:31 - Biwas bhandari \nNo.\n\n1:17:36 - Biwas bhandari \nI've written one too. But I've heard every developer saying every developer should write articles and blogs.\n\n1:17:44 - Jorge Lewis \nBut do you enjoy it?\n\n1:17:46 - Unidentified Speaker \nNo.\n\n1:17:50 - Biwas bhandari \nI like making videos instead of writing blogs.\n\n1:17:54 - Jorge Lewis \nOkay, that's already the reason, because you enjoy it. For most content, it depends what you're doing it for. For Startino, there's a couple reasons. First one is because it can attract clients. It shows our expertise. It shows we have an online presence and we're real people. Another reason is because I would enjoy I know the team would enjoy making those videos, like a competition of our team making the best chess or something. I would enjoy making that and I know other team members would enjoy it.\n\n1:18:26 - Jorge Lewis \nIt also might be a way to recruit talent. The reasons I think are kind of, they depend on you.\n\n1:18:36 - Jorge Lewis \nLike, why would you write content? I don't know. It really depends on you. For me, for my personal channel, for example, I like doing that because I get to reflect on what I respect, reflect on my life. I've learned, but also because I can help other people that are in similar situations. And also because I know in the longterm, having a personal brand is very powerful.\n\n1:19:00 - Biwas bhandari \nYeah.\n\n1:19:10 - Jorge Lewis \nAlright, Quen's asking me to call, but I need to go use the restroom and I gotta go to Jiu-Jitsu.\n\n1:19:22 - Biwas bhandari \nYeah, I think we can end this session for today. Yeah, so...\n\n1:19:29 - Jorge Lewis \nAre you hopping on tonight?\n\n1:19:33 - Biwas bhandari \nYeah, I'll hop on.\n\n1:19:34 - Jorge Lewis \nAll right, um, I'll I'll try to hop on since I'm excited. I might have the motivation But yeah, I'm excited about this Hopefully, it's not too hard but like for me I'm gonna be really annoyed because it's not gonna be perfect because yeah, he sucks at making content I hate reading chativity content every time I'm on LinkedIn. I read chativity content.\n\n1:19:59 - Biwas bhandari \nI'm just So annoying Yeah, if I go faster than you, I'll do some research on this topic.\n\n1:20:11 - Jorge Lewis \nYeah. If, if you want, you can merge your research with trying to use graph rag.\n\n1:20:16 - Biwas bhandari \nYeah.\n\n1:20:17 - Jorge Lewis \nUm, you just, it's the installation is really simple. There's a lot of tutorials online as well that I found quite useful"}
02:07:10,941 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,942 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,942 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,942 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,944 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: . Insert columns, table, create columns, status, assessor, status. Property done does not exist.\n\n51:57 - Unidentified Speaker \nData.\n\n51:59 - Jorge Lewis \nSo what\'s item.value?\n\n52:01 - Jorge Lewis \nWhat is it? What is...\n\n52:06 - Jorge Lewis \nOh, wait. Have you... No, you just... I think it\'s because you haven\'t... It hasn\'t updated your types yet, your ID.\n\n52:16 - Will Vincent Parrone \nOh, right, right, right.\n\n52:19 - Will Vincent Parrone \nMaybe?\n\n52:20 - Will Vincent Parrone \nLet me try to...\n\n52:23 - Jorge Lewis \nYou know what\'s funny? That\'s the most Vim thing I\'ve seen right there. You have to close the entire IDE to get it refreshed. Vim is just like, oh, it broke. Close it and reopen it.\n\n52:40 - Will Vincent Parrone \nAnd this is the IT equivalent of, have you tried turning it on and off? Oh, wait, it is working, huh?\n\n52:47 - Jorge Lewis \nBut you changed it to value. Try done. I wonder.\n\n52:50 - Unidentified Speaker \nWait.\n\n52:52 - Jorge Lewis \nBecause I have no clue what value.\n\n52:59 - Will Vincent Parrone \nThere\'s no error message. OK.\n\n53:01 - Jorge Lewis \nHow do you read the type? Can you open the type of value or item?\n\n53:15 - Will Vincent Parrone \nNot able to do it. Weird.\n\n53:18 - Jorge Lewis \nTry value.\n\n53:26 - Will Vincent Parrone \nValue extends body cell. Oh, right.\n\n53:30 - Jorge Lewis \nOkay, I can see it here. Let me send it to you. Let me send a screenshot.\n\n53:40 - Jorge Lewis \nSo item.\n\n53:44 - Jorge Lewis \nThis is probably just useful to know about the data table structure.\n\n53:49 - Jorge Lewis \nOkay, so I sense that\'s the item data structure, and then here\'s the value data structure.\n\n53:57 - Will Vincent Parrone \nWait, where did you send it? Discord?\n\n54:00 - Jorge Lewis \nRead.AI tool, sorry. Yeah, Discord.\n\n54:03 - Will Vincent Parrone \nOkay. Waiting for... Ah, okay. Read.AI tool, I suppose.\n\n54:13 - Unidentified Speaker \nDang.\n\n54:14 - Jorge Lewis \nJump to present. Click to jump to present, yeah.\n\n54:18 - Jorge Lewis \nSo Jonas just sent a screenshot.\n\n54:23 - Will Vincent Parrone \nYeah, I saw it either way, it\'s okay.\n\n54:28 - Will Vincent Parrone \nValue, data body, cell comment, data discovered.\n\n54:33 - Jorge Lewis \nIt\'s the same data type as a lead. So it is a lead but just it\'s synonymous with the lead but different.\n\n54:42 - Will Vincent Parrone \nYeah, so I was correct. I mean, partially correct.\n\n54:49 - Jorge Lewis \nSo you should be able to do item.done. But I think the language server or the type checker, what is it called?\n\n54:57 - Will Vincent Parrone \nIt doesn\'t like it. Language server.\n\n55:05 - Will Vincent Parrone \nItem. Oh, wait, wait, wait. Yep, yep, I can hear you.\n\n55:10 - Jorge Lewis \nYeah, is he with us?\n\n55:16 - Jorge Lewis \nWait.\n\n55:17 - Jorge Lewis \nYeah, we\'re not programming session real quick. We\'re tired of being bothered. I\'ll get back to you when we\'re done in like... 30 minutes-ish?\n\n55:30 - Jorge Lewis \nIs he awake?\n\n55:33 - Jorge Lewis \nYeah, he\'ll reply to you.\n\n55:35 - Jorge Lewis \nOkay, yeah, could you deal with that? Maybe try.\n\n55:50 - Will Vincent Parrone \nScrew it, I\'ll see if it works. I\'ll refresh.\n\n55:59 - Will Vincent Parrone \nOkay, I see, internal error. Okay, what the hell did I do? What the hell did I do?\n\n56:19 - Jorge Lewis \nTry again, I guess, I don\'t know, cuz it\'s a little bit, what even happened?\n\n56:24 - Will Vincent Parrone \nI don\'t know, is my server getting half plug-in code VSS did?\n\n56:31 - Will Vincent Parrone \nMaybe a stop overflow or something, let me try. Item.done. What the fuck is this?\n\n56:47 - Will Vincent Parrone \nI\'ll be right back, I\'m gonna use the restroom.\n\n56:49 - Will Vincent Parrone \nYep.\n\n58:39 - Will Vincent Parrone \nso let\'s see let\'s see let\'s see prospect username status discover dot header done what did I do wrong So why didn\'t item.done work?\n\n59:14 - Will Vincent Parrone \nBoth of them did not work. I tried item.done. I\'ll try to check.\n\n59:21 - Jorge Lewis \nMaybe casting item.done as a boolean?\n\n59:25 - Unidentified Speaker \nNo.\n\n59:33 - Will Vincent Parrone \nOh, wait. No.\n\n59:35 - Will Vincent Parrone \nLet me try to smash this first.\n\n59:44 - Will Vincent Parrone \nWait, get diff. What did I do wrong? What did I change? Okay, the spacings...\n\n59:53 - Will Vincent Parrone \nI changed the spacings. Oh no, this is not gonna help me.\n\n59:58 - Unidentified Speaker \nGod\n######################\nOutput:'}
02:07:10,944 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,947 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ". Insert columns, table, create columns, status, assessor, status. Property done does not exist.\n\n51:57 - Unidentified Speaker \nData.\n\n51:59 - Jorge Lewis \nSo what's item.value?\n\n52:01 - Jorge Lewis \nWhat is it? What is...\n\n52:06 - Jorge Lewis \nOh, wait. Have you... No, you just... I think it's because you haven't... It hasn't updated your types yet, your ID.\n\n52:16 - Will Vincent Parrone \nOh, right, right, right.\n\n52:19 - Will Vincent Parrone \nMaybe?\n\n52:20 - Will Vincent Parrone \nLet me try to...\n\n52:23 - Jorge Lewis \nYou know what's funny? That's the most Vim thing I've seen right there. You have to close the entire IDE to get it refreshed. Vim is just like, oh, it broke. Close it and reopen it.\n\n52:40 - Will Vincent Parrone \nAnd this is the IT equivalent of, have you tried turning it on and off? Oh, wait, it is working, huh?\n\n52:47 - Jorge Lewis \nBut you changed it to value. Try done. I wonder.\n\n52:50 - Unidentified Speaker \nWait.\n\n52:52 - Jorge Lewis \nBecause I have no clue what value.\n\n52:59 - Will Vincent Parrone \nThere's no error message. OK.\n\n53:01 - Jorge Lewis \nHow do you read the type? Can you open the type of value or item?\n\n53:15 - Will Vincent Parrone \nNot able to do it. Weird.\n\n53:18 - Jorge Lewis \nTry value.\n\n53:26 - Will Vincent Parrone \nValue extends body cell. Oh, right.\n\n53:30 - Jorge Lewis \nOkay, I can see it here. Let me send it to you. Let me send a screenshot.\n\n53:40 - Jorge Lewis \nSo item.\n\n53:44 - Jorge Lewis \nThis is probably just useful to know about the data table structure.\n\n53:49 - Jorge Lewis \nOkay, so I sense that's the item data structure, and then here's the value data structure.\n\n53:57 - Will Vincent Parrone \nWait, where did you send it? Discord?\n\n54:00 - Jorge Lewis \nRead.AI tool, sorry. Yeah, Discord.\n\n54:03 - Will Vincent Parrone \nOkay. Waiting for... Ah, okay. Read.AI tool, I suppose.\n\n54:13 - Unidentified Speaker \nDang.\n\n54:14 - Jorge Lewis \nJump to present. Click to jump to present, yeah.\n\n54:18 - Jorge Lewis \nSo Jonas just sent a screenshot.\n\n54:23 - Will Vincent Parrone \nYeah, I saw it either way, it's okay.\n\n54:28 - Will Vincent Parrone \nValue, data body, cell comment, data discovered.\n\n54:33 - Jorge Lewis \nIt's the same data type as a lead. So it is a lead but just it's synonymous with the lead but different.\n\n54:42 - Will Vincent Parrone \nYeah, so I was correct. I mean, partially correct.\n\n54:49 - Jorge Lewis \nSo you should be able to do item.done. But I think the language server or the type checker, what is it called?\n\n54:57 - Will Vincent Parrone \nIt doesn't like it. Language server.\n\n55:05 - Will Vincent Parrone \nItem. Oh, wait, wait, wait. Yep, yep, I can hear you.\n\n55:10 - Jorge Lewis \nYeah, is he with us?\n\n55:16 - Jorge Lewis \nWait.\n\n55:17 - Jorge Lewis \nYeah, we're not programming session real quick. We're tired of being bothered. I'll get back to you when we're done in like... 30 minutes-ish?\n\n55:30 - Jorge Lewis \nIs he awake?\n\n55:33 - Jorge Lewis \nYeah, he'll reply to you.\n\n55:35 - Jorge Lewis \nOkay, yeah, could you deal with that? Maybe try.\n\n55:50 - Will Vincent Parrone \nScrew it, I'll see if it works. I'll refresh.\n\n55:59 - Will Vincent Parrone \nOkay, I see, internal error. Okay, what the hell did I do? What the hell did I do?\n\n56:19 - Jorge Lewis \nTry again, I guess, I don't know, cuz it's a little bit, what even happened?\n\n56:24 - Will Vincent Parrone \nI don't know, is my server getting half plug-in code VSS did?\n\n56:31 - Will Vincent Parrone \nMaybe a stop overflow or something, let me try. Item.done. What the fuck is this?\n\n56:47 - Will Vincent Parrone \nI'll be right back, I'm gonna use the restroom.\n\n56:49 - Will Vincent Parrone \nYep.\n\n58:39 - Will Vincent Parrone \nso let's see let's see let's see prospect username status discover dot header done what did I do wrong So why didn't item.done work?\n\n59:14 - Will Vincent Parrone \nBoth of them did not work. I tried item.done. I'll try to check.\n\n59:21 - Jorge Lewis \nMaybe casting item.done as a boolean?\n\n59:25 - Unidentified Speaker \nNo.\n\n59:33 - Will Vincent Parrone \nOh, wait. No.\n\n59:35 - Will Vincent Parrone \nLet me try to smash this first.\n\n59:44 - Will Vincent Parrone \nWait, get diff. What did I do wrong? What did I change? Okay, the spacings...\n\n59:53 - Will Vincent Parrone \nI changed the spacings. Oh no, this is not gonna help me.\n\n59:58 - Unidentified Speaker \nGod"}
02:07:10,957 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Will Vincent Parrone \nSo, what are the improvements that you think I should do, like, It\'s not on how I voice my messages. I think it\'s being a bit more inquisitive. Questioning, I suppose.\n\n1:22:02 - Jorge Lewis \nSo, of course, it depends on your style then.\n\n1:22:14 - Will Vincent Parrone \nMm-hmm.\n\n1:22:21 - Will Vincent Parrone \nSorry.\n\n1:22:22 - Jorge Lewis \nYeah, I think so as well. Like, you know, the very short messages kind of like a lot more lenient. QAnon has very direct messages. You can find your own style. But there\'s some things that need that all forms of communication from conflicts.\n\n1:22:46 - Jorge Lewis \nSo what I would like for me, if this were me, I would, I\'m going to type it in your, in our person on the end, but don\'t, don\'t kind of, I don\'t want you to kind of take this as a fact, like just for me, how I would do it, right?\n\n1:23:03 - Will Vincent Parrone \nYeah, basically I\'ll just try to get the essence of it and figure out the, how I\'m going to write it in my own words.\n\n1:23:11 - Jorge Lewis \nOh, are you there?\n\n1:23:20 - Will Vincent Parrone \nYep. I think your internet is a little bit I think you cut out by there. Hello, hello. Can you hear me? Yeah, yeah, yeah, yeah.\n\n1:23:27 - Unidentified Speaker \nHello.\n\n1:23:28 - Will Vincent Parrone \nHello.\n\n1:23:32 - Will Vincent Parrone \nCan you hear me?\n\n1:23:34 - Jorge Lewis \nYep, I can hear you.\n\n1:23:36 - Jorge Lewis \nIs that me? Yes, okay, okay. And then you can use that as inspiration. Everyone has their own style, so don\'t take it as like a fact.\n\n1:23:46 - Will Vincent Parrone \nOkay, got it. Looking at it now.\n\n1:23:58 - Jorge Lewis \nHmm.\n\n1:24:03 - Jorge Lewis \nHold on, my Wi-Fi is literally like...\n\n1:24:07 - Will Vincent Parrone \nYeah, I\'ll turn off screen sharing for now.\n\n1:24:14 - Jorge Lewis \nHaha, thanks.\n\n1:24:17 - Jorge Lewis \nMan, this is the worst it\'s been so far. I don\'t know, bro, I\'m in Hong Kong, one of the places with the fastest internet. I don\'t have like, I can\'t even do a voice, a video call.\n\n1:24:28 - Will Vincent Parrone \nJesus Christ, how much is the internet there?\n\n1:24:42 - Will Vincent Parrone \nHello, hello, hello. Can you hear me, Jorge?\n\n1:24:47 - Jorge Lewis \nOh, bro, it\'s expensive. All data, right?\n\n1:24:52 - Unidentified Speaker \nYeah.\n\n1:24:53 - Will Vincent Parrone \nOh, God. We have like 10 seconds delay.\n\n1:24:58 - Jorge Lewis \nIt sounds like there\'s a big delay, though.\n\n1:25:09 - Will Vincent Parrone \nYeah. Maybe we can end this call now. And I work on the user sign-up flow for now in Figma.\n\n1:25:23 - Jorge Lewis \nIs it better now?\n\n1:25:25 - Will Vincent Parrone \nNot sure.\n\n1:25:45 - Jorge Lewis \nOkay, have a nice day.\n\n1:25:46 - Unidentified Speaker \nBye-bye.\n\n1:25:55 - Will Vincent Parrone \nyou\n######################\nOutput:'}
02:07:10,957 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,960 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Will Vincent Parrone \nSo, what are the improvements that you think I should do, like, It's not on how I voice my messages. I think it's being a bit more inquisitive. Questioning, I suppose.\n\n1:22:02 - Jorge Lewis \nSo, of course, it depends on your style then.\n\n1:22:14 - Will Vincent Parrone \nMm-hmm.\n\n1:22:21 - Will Vincent Parrone \nSorry.\n\n1:22:22 - Jorge Lewis \nYeah, I think so as well. Like, you know, the very short messages kind of like a lot more lenient. QAnon has very direct messages. You can find your own style. But there's some things that need that all forms of communication from conflicts.\n\n1:22:46 - Jorge Lewis \nSo what I would like for me, if this were me, I would, I'm going to type it in your, in our person on the end, but don't, don't kind of, I don't want you to kind of take this as a fact, like just for me, how I would do it, right?\n\n1:23:03 - Will Vincent Parrone \nYeah, basically I'll just try to get the essence of it and figure out the, how I'm going to write it in my own words.\n\n1:23:11 - Jorge Lewis \nOh, are you there?\n\n1:23:20 - Will Vincent Parrone \nYep. I think your internet is a little bit I think you cut out by there. Hello, hello. Can you hear me? Yeah, yeah, yeah, yeah.\n\n1:23:27 - Unidentified Speaker \nHello.\n\n1:23:28 - Will Vincent Parrone \nHello.\n\n1:23:32 - Will Vincent Parrone \nCan you hear me?\n\n1:23:34 - Jorge Lewis \nYep, I can hear you.\n\n1:23:36 - Jorge Lewis \nIs that me? Yes, okay, okay. And then you can use that as inspiration. Everyone has their own style, so don't take it as like a fact.\n\n1:23:46 - Will Vincent Parrone \nOkay, got it. Looking at it now.\n\n1:23:58 - Jorge Lewis \nHmm.\n\n1:24:03 - Jorge Lewis \nHold on, my Wi-Fi is literally like...\n\n1:24:07 - Will Vincent Parrone \nYeah, I'll turn off screen sharing for now.\n\n1:24:14 - Jorge Lewis \nHaha, thanks.\n\n1:24:17 - Jorge Lewis \nMan, this is the worst it's been so far. I don't know, bro, I'm in Hong Kong, one of the places with the fastest internet. I don't have like, I can't even do a voice, a video call.\n\n1:24:28 - Will Vincent Parrone \nJesus Christ, how much is the internet there?\n\n1:24:42 - Will Vincent Parrone \nHello, hello, hello. Can you hear me, Jorge?\n\n1:24:47 - Jorge Lewis \nOh, bro, it's expensive. All data, right?\n\n1:24:52 - Unidentified Speaker \nYeah.\n\n1:24:53 - Will Vincent Parrone \nOh, God. We have like 10 seconds delay.\n\n1:24:58 - Jorge Lewis \nIt sounds like there's a big delay, though.\n\n1:25:09 - Will Vincent Parrone \nYeah. Maybe we can end this call now. And I work on the user sign-up flow for now in Figma.\n\n1:25:23 - Jorge Lewis \nIs it better now?\n\n1:25:25 - Will Vincent Parrone \nNot sure.\n\n1:25:45 - Jorge Lewis \nOkay, have a nice day.\n\n1:25:46 - Unidentified Speaker \nBye-bye.\n\n1:25:55 - Will Vincent Parrone \nyou"}
02:07:10,962 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: No.\n\n59:33 - Will Vincent Parrone \nOh, wait. No.\n\n59:35 - Will Vincent Parrone \nLet me try to smash this first.\n\n59:44 - Will Vincent Parrone \nWait, get diff. What did I do wrong? What did I change? Okay, the spacings...\n\n59:53 - Will Vincent Parrone \nI changed the spacings. Oh no, this is not gonna help me.\n\n59:58 - Unidentified Speaker \nGod.\n\n1:00:02 - Will Vincent Parrone \nOkay, I have an idea.\n\n1:00:19 - Will Vincent Parrone \nOkay, restart the server.\n\n1:00:24 - Will Vincent Parrone \nHopefully.\n\n1:00:28 - Will Vincent Parrone \nOf course, why did I not check the console logs first?\n\n1:00:37 - Will Vincent Parrone \nSo it\'s not.\n\n1:00:47 - Will Vincent Parrone \nOkay, I believe it\'s not the table\'s fault.\n\n1:00:55 - Will Vincent Parrone \nBecause the error happened even though...\n\n1:00:58 - Jorge Lewis \nWait, can I see your error again?\n\n1:01:02 - Will Vincent Parrone \nWait.\n\n1:01:07 - Will Vincent Parrone \nHere we go.\n\n1:01:16 - Will Vincent Parrone \nI honestly think someone\'s hacking my phone, right? My AA server right now.\n\n1:01:22 - Will Vincent Parrone \nHere you go, transfer with what error?\n\n1:01:27 - Jorge Lewis \nLook at- look at- go down, go down.\n\n1:01:32 - Jorge Lewis \nSo, look at, um... Okay, okay. Look, read the error. Transfer failed with one error. Unexpected character. And it\'s, uh...\n\n1:01:49 - Will Vincent Parrone \nLet\'S see.\n\n1:01:49 - Jorge Lewis \nSuperbase TS 1.0. But it\'s weird because there\'s nothing wrong there.\n\n1:02:00 - Will Vincent Parrone \nOr maybe there is. I don\'t know.\n\n1:02:03 - Jorge Lewis \nNo, I\'m looking at it on my thing. There\'s not.\n\n1:02:25 - Jorge Lewis \nI\'m with Will right now in a pair programming session. If you don\'t mind waiting like 15 minutes.\n\n1:02:38 - Will Vincent Parrone \nOkay, fine.\n\n1:02:39 - Unidentified Speaker \nOkay, thanks.\n\n1:02:43 - Will Vincent Parrone \nOkay, what\'s What\'s my super base looking like then?\n\n1:02:51 - Jorge Lewis \nNo, no, it\'s in types. It\'s in types and then super base. So, yeah, there\'s nothing wrong with it.\n\n1:02:59 - Will Vincent Parrone \nHmm. Okay. I\'ll try to restart it again then.\n\n1:03:05 - Jorge Lewis \nIt\'s a problem with byte.yes.build.\n\n1:03:12 - Will Vincent Parrone \nDang.\n\n1:03:17 - Will Vincent Parrone \nWait, what\'s htop saying? Is this a Stack Overflow? No, this is not a Stack Overflow problem.\n\n1:03:27 - Will Vincent Parrone \nHow are my other sites?\n\n1:03:37 - Will Vincent Parrone \nYep, this is an isolated event.\n\n1:03:47 - Will Vincent Parrone \nThis is beautiful. I love this.\n\n1:03:49 - Unidentified Speaker \nOkay.\n\n1:04:05 - Will Vincent Parrone \nWeb slash super base.\n\n1:04:34 - Jorge Lewis \nActually, I think I might know what happened.\n\n1:04:39 - Jorge Lewis \nI think... I might have...\n\n1:04:43 - Jorge Lewis \nSay... Huh...\n\n1:04:47 - Jorge Lewis \nLet me just...\n\n1:04:50 - Jorge Lewis \nNo...\n\n1:04:54 - Jorge Lewis \nLet me actually just delete it and bring it back.\n\n1:05:02 - Jorge Lewis \nBecause what it looks like is something related to the binary, or at least the file of the types doesn\'t look too happy.\n\n1:05:13 - Will Vincent Parrone \nIn which case, maybe a fresh install would work, fresh pnpm install.\n\n1:05:20 - Jorge Lewis \nA fresh PMPM, at least I\'m doing the gen types call first, which did not work. So I guess, yeah, fresh PMPM. But what\'s, what broke it?\n\n1:05:40 - Will Vincent Parrone \nIt\'s probably related to the done value. Something screwed the server up with that. Now let\'s try PMPM model.\n\n1:05:50 - Will Vincent Parrone \nThen let\'s try it again.\n\n1:06:26 - Will Vincent Parrone \nYeah, I think it\'s working now. Oh no, it\'s not.\n\n1:06:34 - Will Vincent Parrone \nThis has gotten a bit more interesting.\n\n1:06:42 - Will Vincent Parrone \nPut in a Read.AI column. Transform failed due to an error. Error when evaluating SSR module.\n\n1:06:48 - Unidentified Speaker \nHmm.\n\n1:06:54 - Will Vincent Parrone \nInteresting. Evaluation.\n\n1:07:05 - Will Vincent Parrone \nI need to use another PC for this.\n\n1:07:10 - Will Vincent Parrone \nso Okay, I have no idea what\'s happening Okay.\n\n1:09:48 - Jorge Lewis \nWhat a strange issue.\n\n1:09:50 - Will\n######################\nOutput:'}
02:07:10,962 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,966 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "No.\n\n59:33 - Will Vincent Parrone \nOh, wait. No.\n\n59:35 - Will Vincent Parrone \nLet me try to smash this first.\n\n59:44 - Will Vincent Parrone \nWait, get diff. What did I do wrong? What did I change? Okay, the spacings...\n\n59:53 - Will Vincent Parrone \nI changed the spacings. Oh no, this is not gonna help me.\n\n59:58 - Unidentified Speaker \nGod.\n\n1:00:02 - Will Vincent Parrone \nOkay, I have an idea.\n\n1:00:19 - Will Vincent Parrone \nOkay, restart the server.\n\n1:00:24 - Will Vincent Parrone \nHopefully.\n\n1:00:28 - Will Vincent Parrone \nOf course, why did I not check the console logs first?\n\n1:00:37 - Will Vincent Parrone \nSo it's not.\n\n1:00:47 - Will Vincent Parrone \nOkay, I believe it's not the table's fault.\n\n1:00:55 - Will Vincent Parrone \nBecause the error happened even though...\n\n1:00:58 - Jorge Lewis \nWait, can I see your error again?\n\n1:01:02 - Will Vincent Parrone \nWait.\n\n1:01:07 - Will Vincent Parrone \nHere we go.\n\n1:01:16 - Will Vincent Parrone \nI honestly think someone's hacking my phone, right? My AA server right now.\n\n1:01:22 - Will Vincent Parrone \nHere you go, transfer with what error?\n\n1:01:27 - Jorge Lewis \nLook at- look at- go down, go down.\n\n1:01:32 - Jorge Lewis \nSo, look at, um... Okay, okay. Look, read the error. Transfer failed with one error. Unexpected character. And it's, uh...\n\n1:01:49 - Will Vincent Parrone \nLet'S see.\n\n1:01:49 - Jorge Lewis \nSuperbase TS 1.0. But it's weird because there's nothing wrong there.\n\n1:02:00 - Will Vincent Parrone \nOr maybe there is. I don't know.\n\n1:02:03 - Jorge Lewis \nNo, I'm looking at it on my thing. There's not.\n\n1:02:25 - Jorge Lewis \nI'm with Will right now in a pair programming session. If you don't mind waiting like 15 minutes.\n\n1:02:38 - Will Vincent Parrone \nOkay, fine.\n\n1:02:39 - Unidentified Speaker \nOkay, thanks.\n\n1:02:43 - Will Vincent Parrone \nOkay, what's What's my super base looking like then?\n\n1:02:51 - Jorge Lewis \nNo, no, it's in types. It's in types and then super base. So, yeah, there's nothing wrong with it.\n\n1:02:59 - Will Vincent Parrone \nHmm. Okay. I'll try to restart it again then.\n\n1:03:05 - Jorge Lewis \nIt's a problem with byte.yes.build.\n\n1:03:12 - Will Vincent Parrone \nDang.\n\n1:03:17 - Will Vincent Parrone \nWait, what's htop saying? Is this a Stack Overflow? No, this is not a Stack Overflow problem.\n\n1:03:27 - Will Vincent Parrone \nHow are my other sites?\n\n1:03:37 - Will Vincent Parrone \nYep, this is an isolated event.\n\n1:03:47 - Will Vincent Parrone \nThis is beautiful. I love this.\n\n1:03:49 - Unidentified Speaker \nOkay.\n\n1:04:05 - Will Vincent Parrone \nWeb slash super base.\n\n1:04:34 - Jorge Lewis \nActually, I think I might know what happened.\n\n1:04:39 - Jorge Lewis \nI think... I might have...\n\n1:04:43 - Jorge Lewis \nSay... Huh...\n\n1:04:47 - Jorge Lewis \nLet me just...\n\n1:04:50 - Jorge Lewis \nNo...\n\n1:04:54 - Jorge Lewis \nLet me actually just delete it and bring it back.\n\n1:05:02 - Jorge Lewis \nBecause what it looks like is something related to the binary, or at least the file of the types doesn't look too happy.\n\n1:05:13 - Will Vincent Parrone \nIn which case, maybe a fresh install would work, fresh pnpm install.\n\n1:05:20 - Jorge Lewis \nA fresh PMPM, at least I'm doing the gen types call first, which did not work. So I guess, yeah, fresh PMPM. But what's, what broke it?\n\n1:05:40 - Will Vincent Parrone \nIt's probably related to the done value. Something screwed the server up with that. Now let's try PMPM model.\n\n1:05:50 - Will Vincent Parrone \nThen let's try it again.\n\n1:06:26 - Will Vincent Parrone \nYeah, I think it's working now. Oh no, it's not.\n\n1:06:34 - Will Vincent Parrone \nThis has gotten a bit more interesting.\n\n1:06:42 - Will Vincent Parrone \nPut in a Read.AI column. Transform failed due to an error. Error when evaluating SSR module.\n\n1:06:48 - Unidentified Speaker \nHmm.\n\n1:06:54 - Will Vincent Parrone \nInteresting. Evaluation.\n\n1:07:05 - Will Vincent Parrone \nI need to use another PC for this.\n\n1:07:10 - Will Vincent Parrone \nso Okay, I have no idea what's happening Okay.\n\n1:09:48 - Jorge Lewis \nWhat a strange issue.\n\n1:09:50 - Will"}
02:07:10,967 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: just So annoying Yeah, if I go faster than you, I\'ll do some research on this topic.\n\n1:20:11 - Jorge Lewis \nYeah. If, if you want, you can merge your research with trying to use graph rag.\n\n1:20:16 - Biwas bhandari \nYeah.\n\n1:20:17 - Jorge Lewis \nUm, you just, it\'s the installation is really simple. There\'s a lot of tutorials online as well that I found quite useful. I haven\'t used them yet, but they were very simple.\n\n1:20:25 - Biwas bhandari \nOkay.\n\n1:20:26 - Jorge Lewis \nAll right, bro. Um, yeah, thanks for your time. Thanks for the brainstorming. And, um, I\'ll maybe see you later tonight, if not tomorrow.\n\n1:20:33 - Biwas bhandari \nyeah okay thank you for the great session yeah thank you bye bye yeah\n######################\nOutput:'}
02:07:10,967 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,970 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "just So annoying Yeah, if I go faster than you, I'll do some research on this topic.\n\n1:20:11 - Jorge Lewis \nYeah. If, if you want, you can merge your research with trying to use graph rag.\n\n1:20:16 - Biwas bhandari \nYeah.\n\n1:20:17 - Jorge Lewis \nUm, you just, it's the installation is really simple. There's a lot of tutorials online as well that I found quite useful. I haven't used them yet, but they were very simple.\n\n1:20:25 - Biwas bhandari \nOkay.\n\n1:20:26 - Jorge Lewis \nAll right, bro. Um, yeah, thanks for your time. Thanks for the brainstorming. And, um, I'll maybe see you later tonight, if not tomorrow.\n\n1:20:33 - Biwas bhandari \nyeah okay thank you for the great session yeah thank you bye bye yeah"}
02:07:10,985 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:10,988 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Discussing Graph Designs \nFri, Jun 28, 2024\n\n2:26 - Unidentified Speaker \nHello.\n\n2:32 - Unidentified Speaker \nOkay.\n\n2:58 - Biwas bhandari \nOkay, so this is what I came up with instead of this thing routing and all against us.\n\n3:22 - Unidentified Speaker \nYou are muted.\n\n3:47 - Unidentified Speaker \nCan you hear me?\n\n3:51 - Jonas Lindberg \nYeah, George Fry speaking.\n\n3:55 - Unidentified Speaker \nTest, test, test.\n\n3:59 - Conference Room (Jorge Lewis) - Speaker 1 \nI can hear an echo. I mean, yes.\n\n4:02 - Jonas Lindberg \nYou can mute me, I think. Excellent.\n\n4:05 - Jonas Lindberg \nOh, can I?\n\n4:09 - Jonas Lindberg \nNo, but then everyone else is hearing an echo as well. No.\n\n4:16 - Unidentified Speaker \nThey weren\'t when I was.\n\n4:21 - Unidentified Speaker \nNow?\n\n4:23 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, mute.\n\n4:24 - Conference Room (Jorge Lewis) - Speaker 2 \nI muted you.\n\n4:25 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, the mute is for everyone, though.\n\n4:28 - Unidentified Speaker \nSo we can\'t.\n\n4:29 - Jonas Lindberg \nCan\'t you mute individuals?\n\n4:32 - Jonas Lindberg \nDoesn\'t seem like it.\n\n4:37 - Jonas Lindberg \nYeah, now you know how I had us.\n\n4:41 - Jonas Lindberg \nThis mic is way better, though, I think. The camera one?\n\n4:44 - Jonas Lindberg \nYeah. Yeah, surprisingly, it\'s quite good.\n\n4:51 - Jonas Lindberg \nCan you hear, like, the music outside? Can you hear me?\n\n4:57 - Unidentified Speaker \nYeah, I guess.\n\n4:59 - Jonas Lindberg \nYeah, but it\'s not clear.\n\n5:02 - Jonas Lindberg \nOh, yeah, when you\'re leaning back. I mean, it was the same thing for when I was speaking, I think. No, you weren\'t quite good.\n\n5:09 - Jonas Lindberg \nI mean, I could hear myself.\n\n5:12 - Jonas Lindberg \nIt was meh.\n\n5:15 - Unidentified Speaker \nWe\'re dead.\n\n5:15 - Jonas Lindberg \nWhere is me?\n\n5:25 - Unidentified Speaker \nSpeak of the legend.\n\n5:31 - Jonas Lindberg \nAlright, welcome back. Jonas and I got ourselves some beers.\n\n5:36 - Unidentified Speaker \nYeah.\n\n5:39 - Jonas Lindberg \nIt was free.\n\n5:40 - Jonas Lindberg \nFrom the festival right outside, yeah. The concert outside.\n\n5:43 - Jonas Lindberg \nThe concert, yeah. The karaoke, actually.\n\n5:46 - Jonas Lindberg \nOh, were they?\n\n5:50 - Unidentified Speaker \nWhere? We\'re in a co-working space.\n\n5:56 - Unidentified Speaker \nIt\'s 8 p.m.\n\n5:56 - Jonas Lindberg \nat the moment. Wait, is he saying how old?\n\n6:00 - Chinmay Pandya \nYeah, like, what\'s your age? How old are you? Would you like to guess?\n\n6:04 - Jonas Lindberg \n25. 25 who?\n\n6:12 - Biwas bhandari \nFor both, around 24.\n\n6:14 - Unidentified Speaker \nOkay.\n\n6:17 - Jonas Lindberg \nAnd Maddy was?\n\n6:18 - Jonas Lindberg \nWhat\'s your guess? How old are you?\n\n6:20 - Biwas bhandari \nWell, I saw a YouTube video of Jorge. He was saying he was 18 years old.\n\n6:27 - Jonas Lindberg \nOkay. Yeah.\n\n6:30 - Jonas Lindberg \nJorge. Well, I am 20.\n\n6:34 - Biwas bhandari \nOkay, ISO is one of the video software engineer or something in YouTube.\n\n6:40 - Unidentified Speaker \nYouTube?\n\n6:41 - Biwas bhandari \nWhat?\n\n6:42 - Biwas bhandari \nThere is one video that you saw, yeah. Is that a video?\n\n6:45 - Jonas Lindberg \nYeah, there\'s a video of Jorge in YouTube? Is it VTube?\n\n6:49 - Jonas Lindberg \nOkay, where did I find it?\n\n6:53 - Chinmay Pandya \nSo, Jonas is 20.\n\n6:59 - Unidentified Speaker \nI\'m 20. Jorge? 18.\n\n7:03 - Chinmay Pandya \nYou\'re 18? Yes, sir.\n\n7:06 - Unidentified Speaker \nYeah.\n\n7:06 - Chinmay Pandya \nYou\'re younger than me. Yes.\n\n7:12 - Jonas Lindberg \nYeah, we\'ve been in the game a while. We\'ve been trying to start, like, companies and stuff for, like, ever since. How old are you?\n\n7:21 - Unidentified Speaker \n14, so. Yeah.\n\n7:26 - Jonas Lindberg \nSo, yeah, we\'ve gotten a lot of experience, yeah, through that.\n\n7:34 - Chinmay Pandya \nI thought you guys were like really seniors.\n\n7:39 - Jonas Lindberg \nWe have the experience of seniors, really. Because you mentioned you had six years of experience, I thought. Yeah, I mean, I started when I was 12, so.\n\n7:\n######################\nOutput:'}
02:07:10,988 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:10,991 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Discussing Graph Designs \nFri, Jun 28, 2024\n\n2:26 - Unidentified Speaker \nHello.\n\n2:32 - Unidentified Speaker \nOkay.\n\n2:58 - Biwas bhandari \nOkay, so this is what I came up with instead of this thing routing and all against us.\n\n3:22 - Unidentified Speaker \nYou are muted.\n\n3:47 - Unidentified Speaker \nCan you hear me?\n\n3:51 - Jonas Lindberg \nYeah, George Fry speaking.\n\n3:55 - Unidentified Speaker \nTest, test, test.\n\n3:59 - Conference Room (Jorge Lewis) - Speaker 1 \nI can hear an echo. I mean, yes.\n\n4:02 - Jonas Lindberg \nYou can mute me, I think. Excellent.\n\n4:05 - Jonas Lindberg \nOh, can I?\n\n4:09 - Jonas Lindberg \nNo, but then everyone else is hearing an echo as well. No.\n\n4:16 - Unidentified Speaker \nThey weren't when I was.\n\n4:21 - Unidentified Speaker \nNow?\n\n4:23 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, mute.\n\n4:24 - Conference Room (Jorge Lewis) - Speaker 2 \nI muted you.\n\n4:25 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, the mute is for everyone, though.\n\n4:28 - Unidentified Speaker \nSo we can't.\n\n4:29 - Jonas Lindberg \nCan't you mute individuals?\n\n4:32 - Jonas Lindberg \nDoesn't seem like it.\n\n4:37 - Jonas Lindberg \nYeah, now you know how I had us.\n\n4:41 - Jonas Lindberg \nThis mic is way better, though, I think. The camera one?\n\n4:44 - Jonas Lindberg \nYeah. Yeah, surprisingly, it's quite good.\n\n4:51 - Jonas Lindberg \nCan you hear, like, the music outside? Can you hear me?\n\n4:57 - Unidentified Speaker \nYeah, I guess.\n\n4:59 - Jonas Lindberg \nYeah, but it's not clear.\n\n5:02 - Jonas Lindberg \nOh, yeah, when you're leaning back. I mean, it was the same thing for when I was speaking, I think. No, you weren't quite good.\n\n5:09 - Jonas Lindberg \nI mean, I could hear myself.\n\n5:12 - Jonas Lindberg \nIt was meh.\n\n5:15 - Unidentified Speaker \nWe're dead.\n\n5:15 - Jonas Lindberg \nWhere is me?\n\n5:25 - Unidentified Speaker \nSpeak of the legend.\n\n5:31 - Jonas Lindberg \nAlright, welcome back. Jonas and I got ourselves some beers.\n\n5:36 - Unidentified Speaker \nYeah.\n\n5:39 - Jonas Lindberg \nIt was free.\n\n5:40 - Jonas Lindberg \nFrom the festival right outside, yeah. The concert outside.\n\n5:43 - Jonas Lindberg \nThe concert, yeah. The karaoke, actually.\n\n5:46 - Jonas Lindberg \nOh, were they?\n\n5:50 - Unidentified Speaker \nWhere? We're in a co-working space.\n\n5:56 - Unidentified Speaker \nIt's 8 p.m.\n\n5:56 - Jonas Lindberg \nat the moment. Wait, is he saying how old?\n\n6:00 - Chinmay Pandya \nYeah, like, what's your age? How old are you? Would you like to guess?\n\n6:04 - Jonas Lindberg \n25. 25 who?\n\n6:12 - Biwas bhandari \nFor both, around 24.\n\n6:14 - Unidentified Speaker \nOkay.\n\n6:17 - Jonas Lindberg \nAnd Maddy was?\n\n6:18 - Jonas Lindberg \nWhat's your guess? How old are you?\n\n6:20 - Biwas bhandari \nWell, I saw a YouTube video of Jorge. He was saying he was 18 years old.\n\n6:27 - Jonas Lindberg \nOkay. Yeah.\n\n6:30 - Jonas Lindberg \nJorge. Well, I am 20.\n\n6:34 - Biwas bhandari \nOkay, ISO is one of the video software engineer or something in YouTube.\n\n6:40 - Unidentified Speaker \nYouTube?\n\n6:41 - Biwas bhandari \nWhat?\n\n6:42 - Biwas bhandari \nThere is one video that you saw, yeah. Is that a video?\n\n6:45 - Jonas Lindberg \nYeah, there's a video of Jorge in YouTube? Is it VTube?\n\n6:49 - Jonas Lindberg \nOkay, where did I find it?\n\n6:53 - Chinmay Pandya \nSo, Jonas is 20.\n\n6:59 - Unidentified Speaker \nI'm 20. Jorge? 18.\n\n7:03 - Chinmay Pandya \nYou're 18? Yes, sir.\n\n7:06 - Unidentified Speaker \nYeah.\n\n7:06 - Chinmay Pandya \nYou're younger than me. Yes.\n\n7:12 - Jonas Lindberg \nYeah, we've been in the game a while. We've been trying to start, like, companies and stuff for, like, ever since. How old are you?\n\n7:21 - Unidentified Speaker \n14, so. Yeah.\n\n7:26 - Jonas Lindberg \nSo, yeah, we've gotten a lot of experience, yeah, through that.\n\n7:34 - Chinmay Pandya \nI thought you guys were like really seniors.\n\n7:39 - Jonas Lindberg \nWe have the experience of seniors, really. Because you mentioned you had six years of experience, I thought. Yeah, I mean, I started when I was 12, so.\n\n7:"}
02:07:10,998 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,0 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Unidentified Speaker \n14, so. Yeah.\n\n7:26 - Jonas Lindberg \nSo, yeah, we\'ve gotten a lot of experience, yeah, through that.\n\n7:34 - Chinmay Pandya \nI thought you guys were like really seniors.\n\n7:39 - Jonas Lindberg \nWe have the experience of seniors, really. Because you mentioned you had six years of experience, I thought. Yeah, I mean, I started when I was 12, so.\n\n7:51 - Jonas Lindberg \nYeah, I started ninth grade, like, coding, and then me and Jorge were, like, doing game development and more younger people projects than what we are currently, and now we\'re trying to make money. With our experience, that\'s from when I was 18, I got a job as a software engineering in a Norwegian consultancy, worked on bank applications, and also, what was it? Some internal software used by the oil and gas industry in Norway.\n\n8:27 - Jonas Lindberg \nIt seems to be getting loud outside.\n\n8:29 - Jonas Lindberg \nYeah.\n\n8:31 - Chinmay Pandya \nThat\'s impressive, I can say. At the age of 12, I started watching anime.\n\n8:43 - Chinmay Pandya \nBecause you cannot have the freedom to do anything unless you pass out from your college.\n\n8:52 - Unidentified Speaker \nYup.\n\n8:53 - Biwas bhandari \nBut I didn\'t get my mobile until I was 18. Now we can change that.\n\n8:58 - Conference Room (Jorge Lewis) - Speaker 1 \nIf things go well between us, we\'ll be able to give you a really good thing to do. If you want to move past our company, then you\'ll be able to find a job pretty easily, hopefully.\n\n9:07 - Chinmay Pandya \nVivaaz bhai, how old are you? I\'m going to be 21 this year.\n\n9:13 - Biwas bhandari \nYou\'re the oldest. What are they discussing, Jorge?\n\n9:16 - Conference Room (Jorge Lewis) - Speaker 1 \nIt\'s your end-to-end knowledge.\n\n9:26 - Unidentified Speaker \nHindi knowledge.\n\n9:29 - Chinmay Pandya \nHe\'s looks 21, the youngest and he\'s the oldest.\n\n9:34 - Jonas Lindberg \nSo how old are you guys? I\'m 20.\n\n9:41 - Biwas bhandari \nI\'ll be 21 December.\n\n9:43 - Jonas Lindberg \nNice, nice.\n\n9:44 - Unidentified Speaker \nOkay.\n\n9:47 - Jonas Lindberg \nLet\'s not confuse the fact that I\'m younger than you guys and anything else.\n\n9:58 - Jonas Lindberg \nAnyways, yeah, let\'s get back to it.\n\n9:59 - Jonas Lindberg \nYeah, let\'s get back to diagramming.\n\n10:02 - Jonas Lindberg \nI\'ll share my screen just so we can be on one thing.\n\n10:14 - Jonas Lindberg \nOkay, actually, before we go into the graphs...\n\n10:20 - Conference Room (Jorge Lewis) - Speaker 1 \nSo before we go into the graphs, I want to...\n\n10:26 - Conference Room (Jorge Lewis) - Speaker 1 \nSo before we go into the graphs since that\'s more flexible I kind of want to talk about the current state of the project and what\'s the plan so currently we have We were in the middle of migrating, you guys probably know this part already, we were migrating from Python to TypeScript, we were in the middle, we set everything, we set the foundations up, we connected to the database, connected it to the front end with just a simple one function, and we were in the process of making it actually work with LandGraph. Currently, right now, the biggest problem we\'re facing, other than just setting up the actual graph, is passing the message history to the chat. So I think I\'m sharing my screen. So when we\'re calling a stream and we initialize it with this list of messages, the problem is that it\'s not somehow getting all the messages. So that\'s the current bug we\'re facing.\n\n11:27 - Conference Room (Jorge Lewis) - Speaker 1 \nMaybe you guys have experience with this. I don\'t know. I want to say that in my testing, I noticed that passing messages worked.\n\n11:35 - Conference Room (Jorge Lewis) - Speaker 2 \nBut if I created messages manually, So when this was just like a list of messages it works Okay, like it multiple Yeah, I think maybe just better use a normal list like like before That didn\'t work either. I think it\'s the parsing from the database to messages that doesn\'t work. But that\'s what I was testing before we got in this meeting. I think I was at the edge of maybe solving it, I don\'t know.\n\n12:22 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, so we\'ll take a look at that later. But that\'s where we\'re currently at. And in terms of where we need to be, where we need to be is by Wednesday, end of day Wednesday, we need to have the the project deployed and the client can test it, Kuin. Kuin is his name, I\'m gonna use his name, so that Kuin can test it. The capabilities you need to be able to do is to just have a conversation with the bot, so making it so that it can have a conversation like we discussed, like the example I sent and like the one we had today. So, yeah.\n\n13:02 - Conference Room (Jorge Lewis) -\n######################\nOutput:'}
02:07:11,0 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,3 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Unidentified Speaker \n14, so. Yeah.\n\n7:26 - Jonas Lindberg \nSo, yeah, we've gotten a lot of experience, yeah, through that.\n\n7:34 - Chinmay Pandya \nI thought you guys were like really seniors.\n\n7:39 - Jonas Lindberg \nWe have the experience of seniors, really. Because you mentioned you had six years of experience, I thought. Yeah, I mean, I started when I was 12, so.\n\n7:51 - Jonas Lindberg \nYeah, I started ninth grade, like, coding, and then me and Jorge were, like, doing game development and more younger people projects than what we are currently, and now we're trying to make money. With our experience, that's from when I was 18, I got a job as a software engineering in a Norwegian consultancy, worked on bank applications, and also, what was it? Some internal software used by the oil and gas industry in Norway.\n\n8:27 - Jonas Lindberg \nIt seems to be getting loud outside.\n\n8:29 - Jonas Lindberg \nYeah.\n\n8:31 - Chinmay Pandya \nThat's impressive, I can say. At the age of 12, I started watching anime.\n\n8:43 - Chinmay Pandya \nBecause you cannot have the freedom to do anything unless you pass out from your college.\n\n8:52 - Unidentified Speaker \nYup.\n\n8:53 - Biwas bhandari \nBut I didn't get my mobile until I was 18. Now we can change that.\n\n8:58 - Conference Room (Jorge Lewis) - Speaker 1 \nIf things go well between us, we'll be able to give you a really good thing to do. If you want to move past our company, then you'll be able to find a job pretty easily, hopefully.\n\n9:07 - Chinmay Pandya \nVivaaz bhai, how old are you? I'm going to be 21 this year.\n\n9:13 - Biwas bhandari \nYou're the oldest. What are they discussing, Jorge?\n\n9:16 - Conference Room (Jorge Lewis) - Speaker 1 \nIt's your end-to-end knowledge.\n\n9:26 - Unidentified Speaker \nHindi knowledge.\n\n9:29 - Chinmay Pandya \nHe's looks 21, the youngest and he's the oldest.\n\n9:34 - Jonas Lindberg \nSo how old are you guys? I'm 20.\n\n9:41 - Biwas bhandari \nI'll be 21 December.\n\n9:43 - Jonas Lindberg \nNice, nice.\n\n9:44 - Unidentified Speaker \nOkay.\n\n9:47 - Jonas Lindberg \nLet's not confuse the fact that I'm younger than you guys and anything else.\n\n9:58 - Jonas Lindberg \nAnyways, yeah, let's get back to it.\n\n9:59 - Jonas Lindberg \nYeah, let's get back to diagramming.\n\n10:02 - Jonas Lindberg \nI'll share my screen just so we can be on one thing.\n\n10:14 - Jonas Lindberg \nOkay, actually, before we go into the graphs...\n\n10:20 - Conference Room (Jorge Lewis) - Speaker 1 \nSo before we go into the graphs, I want to...\n\n10:26 - Conference Room (Jorge Lewis) - Speaker 1 \nSo before we go into the graphs since that's more flexible I kind of want to talk about the current state of the project and what's the plan so currently we have We were in the middle of migrating, you guys probably know this part already, we were migrating from Python to TypeScript, we were in the middle, we set everything, we set the foundations up, we connected to the database, connected it to the front end with just a simple one function, and we were in the process of making it actually work with LandGraph. Currently, right now, the biggest problem we're facing, other than just setting up the actual graph, is passing the message history to the chat. So I think I'm sharing my screen. So when we're calling a stream and we initialize it with this list of messages, the problem is that it's not somehow getting all the messages. So that's the current bug we're facing.\n\n11:27 - Conference Room (Jorge Lewis) - Speaker 1 \nMaybe you guys have experience with this. I don't know. I want to say that in my testing, I noticed that passing messages worked.\n\n11:35 - Conference Room (Jorge Lewis) - Speaker 2 \nBut if I created messages manually, So when this was just like a list of messages it works Okay, like it multiple Yeah, I think maybe just better use a normal list like like before That didn't work either. I think it's the parsing from the database to messages that doesn't work. But that's what I was testing before we got in this meeting. I think I was at the edge of maybe solving it, I don't know.\n\n12:22 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, so we'll take a look at that later. But that's where we're currently at. And in terms of where we need to be, where we need to be is by Wednesday, end of day Wednesday, we need to have the the project deployed and the client can test it, Kuin. Kuin is his name, I'm gonna use his name, so that Kuin can test it. The capabilities you need to be able to do is to just have a conversation with the bot, so making it so that it can have a conversation like we discussed, like the example I sent and like the one we had today. So, yeah.\n\n13:02 - Conference Room (Jorge Lewis) -"}
02:07:11,85 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,87 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: need to have the the project deployed and the client can test it, Kuin. Kuin is his name, I\'m gonna use his name, so that Kuin can test it. The capabilities you need to be able to do is to just have a conversation with the bot, so making it so that it can have a conversation like we discussed, like the example I sent and like the one we had today. So, yeah.\n\n13:02 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in terms of what the plan is, who\'s going to do what, we can go over it maybe now? So since you two are going to be paired together, it\'ll be kind of up to you guys to decide if we have maybe two prototypes we want to test, you guys can go into each one and test those out, or however you guys want to do it, that\'s up to you guys.\n\n13:32 - Conference Room (Jorge Lewis) - Speaker 1 \nJonas, do you want to tackle the message bug, or do you want to hand it? Do you want to see if they can take it on?\n\n13:38 - Conference Room (Jorge Lewis) - Speaker 2 \nI want to tackle it for at least this day. But if I don\'t solve it today, I will probably have to go.\n\n13:47 - Unidentified Speaker \nOK.\n\n13:47 - Conference Room (Jorge Lewis) - Speaker 1 \nSo today, Jonas will work on that little bug that I mentioned. If he\'s not able to do it, then we\'ll pass it to you guys, since you guys are probably more experienced with LandGraph.\n\n13:54 - Unidentified Speaker \nYeah, cool.\n\n13:59 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so yes, let\'s get it to the graph. Who would like to go first? So actually, I think Jonas should go first, since his one, our ones are, what the\n\n14:12 - Unidentified Speaker \nI can\'t zoom out.\n\n14:13 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, that\'s the max. I guess we\'ll go through Jonas\'s graph first, since his one is just the conversation, not the actual line graph. So yeah, Jonas, you go ahead, I\'ll mute.\n\n14:30 - Jonas Lindberg \nSo yeah, this diagram is more to specify what it should be capable of It doesn\'t really go into the technicals of how things should be pushed to the DB and how things should be retrieved properly, because I think that\'s more of a technical issue that can be solved no matter how the conversation goes out. But this is basically the parts of the conversation where someone will be sending a message that will be visible to the user.\n\n14:59 - Jonas Lindberg \nI have top left here. It\'s the user starting the check-in. When the user starts the check-in, it\'ll always go to the collector first. And the collector will then request something from the user. For example, how far have you walked today? Then afterwards, hopefully the user gives their request of information. If they reject, or if they say, I don\'t know, or something like that, it\'ll probably go back to the collector again for the collector to be like, OK, can you estimate? Or OK, something like that.\n\n15:37 - Jonas Lindberg \nAnd also, let\'s say the user gives a complicated answer. Maybe the user says, I walked around my block. Then the collector\'s job is to say, okay, well, how far was that? And maybe kind of tease and say, the average block is maybe 1KM. Would you say that\'s accurate? So that\'s his job. Yeah. Okay.\n\n15:59 - Jonas Lindberg \nJust extract the information from the user.\n\n16:04 - Jonas Lindberg \nMore point, yeah. When the information is extracted from the user, And the user, for the first time in this loop, goes to the coach. It always goes through the analyst, which analyzes the data, as well as pointing out if any previous data is relevant. So the analyst\'s job can be to detect long-term patterns and more complicated stuff than just the coach acting on the data now. And the analyst will pass that to the coach. So, of course, then the coach is on the info, and afterwards it goes back to the user. Now, during the check-in, as I\'ve written here, after the coach has spoken, we need to determine if it should go back to the collector to go on to the next item. Basically, if the user just says, OK, sure, that\'s fine, then it will go back to the collector, and the collector will ask for more information. Or if the user says something like, why should I do that? I don\'t understand. I think I\'m doing an OK pace now. I don\'t want to increase it. If it says something like that, Then it should go to the coach again so that the coach can comment on what the user said without it going to the collector and the collector requesting information for it, because that\'s not always going to fit in. Sometimes it needs to be like a back and forth. Why would I do that? Because it\'s good for you. Why is it good for me? Because it is. And then finally, when they agree, the discussion with the coach, it goes back to the collector again to move on to the next item. At which point, the loop restarts with the user giving the information. Or if they don\'t, it goes back to the collector, tries to get the information. Afterwards, the analyst analyzes it, points out things for the\n######################\nOutput:'}
02:07:11,87 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,90 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "need to have the the project deployed and the client can test it, Kuin. Kuin is his name, I'm gonna use his name, so that Kuin can test it. The capabilities you need to be able to do is to just have a conversation with the bot, so making it so that it can have a conversation like we discussed, like the example I sent and like the one we had today. So, yeah.\n\n13:02 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in terms of what the plan is, who's going to do what, we can go over it maybe now? So since you two are going to be paired together, it'll be kind of up to you guys to decide if we have maybe two prototypes we want to test, you guys can go into each one and test those out, or however you guys want to do it, that's up to you guys.\n\n13:32 - Conference Room (Jorge Lewis) - Speaker 1 \nJonas, do you want to tackle the message bug, or do you want to hand it? Do you want to see if they can take it on?\n\n13:38 - Conference Room (Jorge Lewis) - Speaker 2 \nI want to tackle it for at least this day. But if I don't solve it today, I will probably have to go.\n\n13:47 - Unidentified Speaker \nOK.\n\n13:47 - Conference Room (Jorge Lewis) - Speaker 1 \nSo today, Jonas will work on that little bug that I mentioned. If he's not able to do it, then we'll pass it to you guys, since you guys are probably more experienced with LandGraph.\n\n13:54 - Unidentified Speaker \nYeah, cool.\n\n13:59 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so yes, let's get it to the graph. Who would like to go first? So actually, I think Jonas should go first, since his one, our ones are, what the\n\n14:12 - Unidentified Speaker \nI can't zoom out.\n\n14:13 - Conference Room (Jorge Lewis) - Speaker 1 \nOh, that's the max. I guess we'll go through Jonas's graph first, since his one is just the conversation, not the actual line graph. So yeah, Jonas, you go ahead, I'll mute.\n\n14:30 - Jonas Lindberg \nSo yeah, this diagram is more to specify what it should be capable of It doesn't really go into the technicals of how things should be pushed to the DB and how things should be retrieved properly, because I think that's more of a technical issue that can be solved no matter how the conversation goes out. But this is basically the parts of the conversation where someone will be sending a message that will be visible to the user.\n\n14:59 - Jonas Lindberg \nI have top left here. It's the user starting the check-in. When the user starts the check-in, it'll always go to the collector first. And the collector will then request something from the user. For example, how far have you walked today? Then afterwards, hopefully the user gives their request of information. If they reject, or if they say, I don't know, or something like that, it'll probably go back to the collector again for the collector to be like, OK, can you estimate? Or OK, something like that.\n\n15:37 - Jonas Lindberg \nAnd also, let's say the user gives a complicated answer. Maybe the user says, I walked around my block. Then the collector's job is to say, okay, well, how far was that? And maybe kind of tease and say, the average block is maybe 1KM. Would you say that's accurate? So that's his job. Yeah. Okay.\n\n15:59 - Jonas Lindberg \nJust extract the information from the user.\n\n16:04 - Jonas Lindberg \nMore point, yeah. When the information is extracted from the user, And the user, for the first time in this loop, goes to the coach. It always goes through the analyst, which analyzes the data, as well as pointing out if any previous data is relevant. So the analyst's job can be to detect long-term patterns and more complicated stuff than just the coach acting on the data now. And the analyst will pass that to the coach. So, of course, then the coach is on the info, and afterwards it goes back to the user. Now, during the check-in, as I've written here, after the coach has spoken, we need to determine if it should go back to the collector to go on to the next item. Basically, if the user just says, OK, sure, that's fine, then it will go back to the collector, and the collector will ask for more information. Or if the user says something like, why should I do that? I don't understand. I think I'm doing an OK pace now. I don't want to increase it. If it says something like that, Then it should go to the coach again so that the coach can comment on what the user said without it going to the collector and the collector requesting information for it, because that's not always going to fit in. Sometimes it needs to be like a back and forth. Why would I do that? Because it's good for you. Why is it good for me? Because it is. And then finally, when they agree, the discussion with the coach, it goes back to the collector again to move on to the next item. At which point, the loop restarts with the user giving the information. Or if they don't, it goes back to the collector, tries to get the information. Afterwards, the analyst analyzes it, points out things for the"}
02:07:11,109 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,110 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: . Why would I do that? Because it\'s good for you. Why is it good for me? Because it is. And then finally, when they agree, the discussion with the coach, it goes back to the collector again to move on to the next item. At which point, the loop restarts with the user giving the information. Or if they don\'t, it goes back to the collector, tries to get the information. Afterwards, the analyst analyzes it, points out things for the coach to coach on. And then onto the coach, the loop continues until the coaching is completely done.\n\n17:56 - Jonas Lindberg \nAny questions?\n\n18:05 - Jonas Lindberg \nNah, I got it.\n\n18:06 - Jonas Lindberg \nNah, seems pretty straight forward.\n\n18:08 - Jonas Lindberg \nYep, sounds good.\n\n18:11 - Jonas Lindberg \nThank you.\n\n18:13 - Jonas Lindberg \nCan we take it to the next Skylar?\n\n18:15 - Chinmay Pandya \nThat sounds more logical than mine.\n\n18:17 - Jonas Lindberg \nOkay, so what\'s what?\n\n18:23 - Jonas Lindberg \nAre these old now?\n\n18:25 - Unidentified Speaker \nYeah.\n\n18:25 - Jonas Lindberg \nOkay, how about we move that somewhere else. So, who\'s this one that I\'m on?\n\n18:40 - Chinmay Pandya \nWhat I was thinking was also similar to Jonas, but he drew a better graph than me with all the nodes. What I was thinking was the same, is that the user can have two edges, but whenever the user checks in, it will always go to the check-in node. And this this will call the previous data from the data and then it will pass to the analyst and it will always go from the analyst to the coach whenever it goes from the check-in node so the analyst analyzes the past data and this is The analyst will analyze the past data and the today\'s data from the check-in and it will pass on to the coach and then the coach can decide to give advice and once it has given advice, the user can also obviously like Yona said, user can counter and coach can give follow-ups or he can counter back and when the user feels satisfied he can end and if he asks another question it will go again back to a check-in and so yeah was I able to make it clear or coach is coached on it, and it\'s done.\n\n20:28 - Conference Room (Jorge Lewis) - Speaker 1 \nHow do we depict in this graph that we\'re going to the next item? Because we need to have it so that the check, I mean, the coach can also be responsible. But I think it would be more reasonable if the check-in node is responsible for making sure the, or asking for more data.\n\n20:49 - Chinmay Pandya \nYeah, that\'s an additional thing which you almost mentioned. His graph is more logical. At the time of check-in, if we ask more data, so we\'ll have more user input on what he did.\n\n21:04 - Unidentified Speaker \nSo...\n\n21:08 - Conference Room (Jorge Lewis) - Speaker 1 \nWould it make more sense if we did...\n\n21:12 - Conference Room (Jorge Lewis) - Speaker 1 \nSorry for messing up your graph here, but...\n\n21:21 - Unidentified Speaker \nHold Alt to...\n\n21:22 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, there we go.\n\n21:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo instead this is, um, so would this, would this still kind of make sense for your, for your idea?\n\n21:49 - Unidentified Speaker \nYeah.\n\n21:50 - Unidentified Speaker \nYeah.\n\n21:50 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then, and then it\'s the supervisor\'s job to determine is the user passing new data that the check-in node should handle, or is the user responding to a coach\'s message?\n\n22:04 - Unidentified Speaker \nYeah. Okay.\n\n22:08 - Chinmay Pandya \nSo if the user is countering the coach, then the supervisor knows that I have to call the coach next, but if the user is passing on new data or the user is setting new goals, then it will pass into the check-in.\n\n22:23 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then this line here, I don\'t know if you can see this one. Is this still relevant?\n\n22:29 - Chinmay Pandya \nBecause we added the supervisor, this is not relevant. Yeah.\n\n22:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo then, so when the check-in node gets new data, and he updates the database, he\'ll tell the analyst, the analyst will tell the coach, and then the coach will, okay, cool, nice. Okay, makes sense.\n\n22:46 - Unidentified Speaker \nAnd any other questions, guys?\n\n22:49 - Conference Room (Jorge Lewis) - Speaker 2 \nOne, is the check-in node basically the interaction between the user and the collector, or the collector tries to get information out of the user?\n\n22:58 - Unidentified Speaker \nI can\'t hear you. Oh.\n\n23:06 - Jonas Lindberg \nIs the check-in node basically the collector and the user working together to get the data out of the user? So, yeah. Yeah.\n\n23:17 - Unidentified Speaker \nOkay.\n\n23:17 - Chinmay Pandya \nYeah. The check-in is the collector. I just wrote a check-in because I wanted for it to\n######################\nOutput:'}
02:07:11,111 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,113 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ". Why would I do that? Because it's good for you. Why is it good for me? Because it is. And then finally, when they agree, the discussion with the coach, it goes back to the collector again to move on to the next item. At which point, the loop restarts with the user giving the information. Or if they don't, it goes back to the collector, tries to get the information. Afterwards, the analyst analyzes it, points out things for the coach to coach on. And then onto the coach, the loop continues until the coaching is completely done.\n\n17:56 - Jonas Lindberg \nAny questions?\n\n18:05 - Jonas Lindberg \nNah, I got it.\n\n18:06 - Jonas Lindberg \nNah, seems pretty straight forward.\n\n18:08 - Jonas Lindberg \nYep, sounds good.\n\n18:11 - Jonas Lindberg \nThank you.\n\n18:13 - Jonas Lindberg \nCan we take it to the next Skylar?\n\n18:15 - Chinmay Pandya \nThat sounds more logical than mine.\n\n18:17 - Jonas Lindberg \nOkay, so what's what?\n\n18:23 - Jonas Lindberg \nAre these old now?\n\n18:25 - Unidentified Speaker \nYeah.\n\n18:25 - Jonas Lindberg \nOkay, how about we move that somewhere else. So, who's this one that I'm on?\n\n18:40 - Chinmay Pandya \nWhat I was thinking was also similar to Jonas, but he drew a better graph than me with all the nodes. What I was thinking was the same, is that the user can have two edges, but whenever the user checks in, it will always go to the check-in node. And this this will call the previous data from the data and then it will pass to the analyst and it will always go from the analyst to the coach whenever it goes from the check-in node so the analyst analyzes the past data and this is The analyst will analyze the past data and the today's data from the check-in and it will pass on to the coach and then the coach can decide to give advice and once it has given advice, the user can also obviously like Yona said, user can counter and coach can give follow-ups or he can counter back and when the user feels satisfied he can end and if he asks another question it will go again back to a check-in and so yeah was I able to make it clear or coach is coached on it, and it's done.\n\n20:28 - Conference Room (Jorge Lewis) - Speaker 1 \nHow do we depict in this graph that we're going to the next item? Because we need to have it so that the check, I mean, the coach can also be responsible. But I think it would be more reasonable if the check-in node is responsible for making sure the, or asking for more data.\n\n20:49 - Chinmay Pandya \nYeah, that's an additional thing which you almost mentioned. His graph is more logical. At the time of check-in, if we ask more data, so we'll have more user input on what he did.\n\n21:04 - Unidentified Speaker \nSo...\n\n21:08 - Conference Room (Jorge Lewis) - Speaker 1 \nWould it make more sense if we did...\n\n21:12 - Conference Room (Jorge Lewis) - Speaker 1 \nSorry for messing up your graph here, but...\n\n21:21 - Unidentified Speaker \nHold Alt to...\n\n21:22 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, there we go.\n\n21:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo instead this is, um, so would this, would this still kind of make sense for your, for your idea?\n\n21:49 - Unidentified Speaker \nYeah.\n\n21:50 - Unidentified Speaker \nYeah.\n\n21:50 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then, and then it's the supervisor's job to determine is the user passing new data that the check-in node should handle, or is the user responding to a coach's message?\n\n22:04 - Unidentified Speaker \nYeah. Okay.\n\n22:08 - Chinmay Pandya \nSo if the user is countering the coach, then the supervisor knows that I have to call the coach next, but if the user is passing on new data or the user is setting new goals, then it will pass into the check-in.\n\n22:23 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then this line here, I don't know if you can see this one. Is this still relevant?\n\n22:29 - Chinmay Pandya \nBecause we added the supervisor, this is not relevant. Yeah.\n\n22:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo then, so when the check-in node gets new data, and he updates the database, he'll tell the analyst, the analyst will tell the coach, and then the coach will, okay, cool, nice. Okay, makes sense.\n\n22:46 - Unidentified Speaker \nAnd any other questions, guys?\n\n22:49 - Conference Room (Jorge Lewis) - Speaker 2 \nOne, is the check-in node basically the interaction between the user and the collector, or the collector tries to get information out of the user?\n\n22:58 - Unidentified Speaker \nI can't hear you. Oh.\n\n23:06 - Jonas Lindberg \nIs the check-in node basically the collector and the user working together to get the data out of the user? So, yeah. Yeah.\n\n23:17 - Unidentified Speaker \nOkay.\n\n23:17 - Chinmay Pandya \nYeah. The check-in is the collector. I just wrote a check-in because I wanted for it to"}
02:07:11,147 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,148 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,149 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 40:12 - Hasnain sayyed \nCome on, come on, come on.\n\n40:13 - Hasnain sayyed \nYeah. I think it\'s updated. Yes. It\'s updated.\n\n40:20 - Unidentified Speaker \nLuckily.\n\n40:21 - Jorge Lewis \nAll right, cool. Um, okay. So that\'s, that\'s nice. All that done. And now we can, we can, I think we can delete all except maybe two.\n\n40:32 - Unidentified Speaker \nOkay.\n\n40:35 - Jorge Lewis \nUm, In case you didn\'t know, if you click the button, the checkbox button on the same row as the labels, it does all. Yeah, yeah.\n\n40:51 - Hasnain sayyed \nThe dark UI, it\'s hard to find the options.\n\n40:56 - Jorge Lewis \nAh, you\'re on a laptop. Yeah, you\'re on a laptop.\n\n41:01 - Jorge Lewis \nYeah, I have the same problem. When it\'s nighttime for me and I put my monitor on like a lower brightness, all the dark UI starts to kind of fade in.\n\n41:15 - Jorge Lewis \nNow we can go into the code and start working.\n\n41:26 - Jorge Lewis \nLet\'s see what we\'re missing from this that we might need. We need to tell the agent.\n\n41:35 - Jorge Lewis \nWe need to tell the agent, the synthetic profile, who it is or what its objective is. Because like me as a user, I know what I\'m doing. So I think we can add a column for prompts. So if you go to the, if you scroll left a little bit.\n\n41:58 - Jorge Lewis \nSorry, yeah, left, left. Yeah, no, the other way, the other way.\n\n42:04 - Jorge Lewis \nMore, more. There\'s a prompts column that I\'m looking for.\n\n42:07 - Hasnain sayyed \nYeah, it\'s there.\n\n42:10 - Jorge Lewis \nSo here, so this column in a real profile is connected to the admin page. But since this synthetic user is not accessing the admin page, I think we can change it. I think we can change the structure of it.\n\n42:28 - Jorge Lewis \nI wonder if Yeah, I think that should be fine. Let\'s do that. So in the structure of the...\n\n42:42 - Jorge Lewis \nI\'ll also share my screen, by the way.\n\n42:44 - Jorge Lewis \nYeah, yeah, please, please.\n\n42:48 - Jorge Lewis \nAnd that way we can just go back and forth.\n\n42:50 - Hasnain sayyed \nYeah, yeah. What I\'m thinking is...\n\n42:55 - Hasnain sayyed \nShould we add an option to the admin panel, like, or get a, like, if the flow that we have decided will add a similar kind of user, because we haven\'t created any option to, you know, change the user character or the few short prompt, whatever. So we can have some options to admin that, like four or five examples, we have to, create that data. And whenever the user clicks on, whenever the admin clicks, like, yeah, I need this character, I need this synthetic user character, maybe like a goal will be different for that synthetic user. Have you got the point?\n\n43:43 - Jorge Lewis \nYeah, so you see my screen share.\n\n43:59 - Jorge Lewis \nWe have input fields for the prompt We have input fields for the prompt so they They can go in here and modify the prompts in the same way. I think we can modify the prompts of the the characteristics of the the Synthetic guy. So for example, what I can do is I\'ll I\'ll kind of, actually let me take a screenshot of this. So what I want is a button here that says synthetic users. Something like this maybe. And when it opens it, let me just kind of make this empty.\n\n44:53 - Jorge Lewis \nOkay, so pretend like I\'ve just, there. So here, what I think we can do is have, so I think what we\'ll have is two tabs. We\'ll have manage users.\n\n45:24 - Jorge Lewis \nAnd then we\'ll have a new user.\n\n45:33 - Jorge Lewis \nSo the managed users, what it\'s going to do is help with being able to remove, or actually just, okay, I have an idea actually. So when you go to, synthetic users, the UI will look like a table with all of the properties. And then we can have a button at the top. Can I move this? A button at the top.\n\n46:14 - Jorge Lewis \nAdd new synthetic user. And when you click this, it opens a pop-up.\n\n46:25 - Jorge Lewis \nnew pop-up or a model like yeah a model model yeah what do we see and then we have we can give it a new name hmm so pretty much all of it So we get a new name, a new personality, the objective.\n\n47:02 - Jorge Lewis \nThis one can be null. So I guess all of them can be null and we can have a default.\n\n47:14 - Hasnain sayyed \nGot it.\n\n47:21 - Jorge Lewis \nSo for example, the objective, when it\'s default, could literally be nothing. We just tell the bot who it is and what it\'s doing, and we let it, like, kind of just, you know, we tell it, pretend you\'re a person that\'s trying to achieve this goal, and you\'re chatting, you\'re trying to improve your life with a chatbot, with a life coach here\n######################\nOutput:'}
02:07:11,149 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,152 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "40:12 - Hasnain sayyed \nCome on, come on, come on.\n\n40:13 - Hasnain sayyed \nYeah. I think it's updated. Yes. It's updated.\n\n40:20 - Unidentified Speaker \nLuckily.\n\n40:21 - Jorge Lewis \nAll right, cool. Um, okay. So that's, that's nice. All that done. And now we can, we can, I think we can delete all except maybe two.\n\n40:32 - Unidentified Speaker \nOkay.\n\n40:35 - Jorge Lewis \nUm, In case you didn't know, if you click the button, the checkbox button on the same row as the labels, it does all. Yeah, yeah.\n\n40:51 - Hasnain sayyed \nThe dark UI, it's hard to find the options.\n\n40:56 - Jorge Lewis \nAh, you're on a laptop. Yeah, you're on a laptop.\n\n41:01 - Jorge Lewis \nYeah, I have the same problem. When it's nighttime for me and I put my monitor on like a lower brightness, all the dark UI starts to kind of fade in.\n\n41:15 - Jorge Lewis \nNow we can go into the code and start working.\n\n41:26 - Jorge Lewis \nLet's see what we're missing from this that we might need. We need to tell the agent.\n\n41:35 - Jorge Lewis \nWe need to tell the agent, the synthetic profile, who it is or what its objective is. Because like me as a user, I know what I'm doing. So I think we can add a column for prompts. So if you go to the, if you scroll left a little bit.\n\n41:58 - Jorge Lewis \nSorry, yeah, left, left. Yeah, no, the other way, the other way.\n\n42:04 - Jorge Lewis \nMore, more. There's a prompts column that I'm looking for.\n\n42:07 - Hasnain sayyed \nYeah, it's there.\n\n42:10 - Jorge Lewis \nSo here, so this column in a real profile is connected to the admin page. But since this synthetic user is not accessing the admin page, I think we can change it. I think we can change the structure of it.\n\n42:28 - Jorge Lewis \nI wonder if Yeah, I think that should be fine. Let's do that. So in the structure of the...\n\n42:42 - Jorge Lewis \nI'll also share my screen, by the way.\n\n42:44 - Jorge Lewis \nYeah, yeah, please, please.\n\n42:48 - Jorge Lewis \nAnd that way we can just go back and forth.\n\n42:50 - Hasnain sayyed \nYeah, yeah. What I'm thinking is...\n\n42:55 - Hasnain sayyed \nShould we add an option to the admin panel, like, or get a, like, if the flow that we have decided will add a similar kind of user, because we haven't created any option to, you know, change the user character or the few short prompt, whatever. So we can have some options to admin that, like four or five examples, we have to, create that data. And whenever the user clicks on, whenever the admin clicks, like, yeah, I need this character, I need this synthetic user character, maybe like a goal will be different for that synthetic user. Have you got the point?\n\n43:43 - Jorge Lewis \nYeah, so you see my screen share.\n\n43:59 - Jorge Lewis \nWe have input fields for the prompt We have input fields for the prompt so they They can go in here and modify the prompts in the same way. I think we can modify the prompts of the the characteristics of the the Synthetic guy. So for example, what I can do is I'll I'll kind of, actually let me take a screenshot of this. So what I want is a button here that says synthetic users. Something like this maybe. And when it opens it, let me just kind of make this empty.\n\n44:53 - Jorge Lewis \nOkay, so pretend like I've just, there. So here, what I think we can do is have, so I think what we'll have is two tabs. We'll have manage users.\n\n45:24 - Jorge Lewis \nAnd then we'll have a new user.\n\n45:33 - Jorge Lewis \nSo the managed users, what it's going to do is help with being able to remove, or actually just, okay, I have an idea actually. So when you go to, synthetic users, the UI will look like a table with all of the properties. And then we can have a button at the top. Can I move this? A button at the top.\n\n46:14 - Jorge Lewis \nAdd new synthetic user. And when you click this, it opens a pop-up.\n\n46:25 - Jorge Lewis \nnew pop-up or a model like yeah a model model yeah what do we see and then we have we can give it a new name hmm so pretty much all of it So we get a new name, a new personality, the objective.\n\n47:02 - Jorge Lewis \nThis one can be null. So I guess all of them can be null and we can have a default.\n\n47:14 - Hasnain sayyed \nGot it.\n\n47:21 - Jorge Lewis \nSo for example, the objective, when it's default, could literally be nothing. We just tell the bot who it is and what it's doing, and we let it, like, kind of just, you know, we tell it, pretend you're a person that's trying to achieve this goal, and you're chatting, you're trying to improve your life with a chatbot, with a life coach here"}
02:07:11,154 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: one \nAnd then something within the nginx file, sudo vim etc nginx. It\'s still wrong.\n\n27:09 - Will Vincent Parrone \nIs there no show config? I might have I might have CSRFs.\n\n27:31 - Will Vincent Parrone \nOh, check origin.\n\n27:33 - Jorge Lewis \nWhat\'s the CSRF? I\'ve never seen it before.\n\n27:37 - Will Vincent Parrone \nIt\'s basically the course, it\'s course related because I\'m not using localhost.\n\n27:45 - Jorge Lewis \nto run.\n\n27:49 - Will Vincent Parrone \nI\'m basically hosting this in another server, in a Vultr cloud server. That\'s why I can use it from any device as long as I remember the password.\n\n28:08 - Will Vincent Parrone \nWhich I actually am starting to forget now. What\'s the name again? Checkorigin.\n\n28:15 - Will Vincent Parrone \nCheck origin. There we go.\n\n28:24 - Will Vincent Parrone \nAnd I know this is going to work now because I am a god. So it\'s available.\n\n28:36 - Jorge Lewis \nDefault. Now I have to.\n\n28:38 - Jorge Lewis \nThis is Windows, so.\n\n28:46 - Jorge Lewis \nBro, RIP. I\'m prompt. You should be using at least PowerShell.\n\n28:53 - Will Vincent Parrone \nReally?\n\n28:55 - Jorge Lewis \nYeah, I prefer using PowerShell, but also WSL works. Like, do you have WSL?\n\n29:04 - Will Vincent Parrone \nActually...\n\n29:08 - Will Vincent Parrone \nYeah. Yeah, I do. I haven\'t really used it though.\n\n29:20 - Will Vincent Parrone \n5, 1, I just got used to 7, ordinary shell commands. 5.\n\n29:31 - Jorge Lewis \nBut your vulture is Linux.\n\n29:36 - Will Vincent Parrone \nYeah, wait, wait, wait. Sorry. Let me try to center my thoughts first. I was really focused on doing the ng-stuff. What was the question again?\n\n29:49 - Jorge Lewis \nWhy don\'t you use WSM?\n\n29:51 - Will Vincent Parrone \nOh, right. It\'s because I keep on forgetting to initialize them, to like start them.\n\n30:03 - Unidentified Speaker \nGotcha.\n\n30:06 - Jorge Lewis \nI mean, I don\'t, I can\'t imagine working with commando prompts, but I mean, if you\'re used to it, then it works.\n\n30:14 - Will Vincent Parrone \nYeah, that\'s. Actually, that\'s what\'s been changing with me recently. My whole mentality is if it works, it works, but I am slightly learning that maybe that\'s a wrong way of doing things.\n\n30:28 - Jorge Lewis \nIt seems like a balance. For me, when I tried switching to NeoVim, or a better example is I tried switching to Linux, to NixOS, but it\'s more sexy, it\'s more flashy. It\'s like, oh, I use Linux, I use NixOS. I use Vim, by the way, but it just doesn\'t work for me. What works for me is Windows, because of what I do. It\'s all very dependent on what you do.\n\n30:58 - Jorge Lewis \nThat\'s fair.\n\n31:00 - Jorge Lewis \nFor me, I can work so much more efficiently with...\n\n31:06 - Jorge Lewis \nThat happens to me all the time as well. I keep opening those random Windows apps.\n\n31:11 - Will Vincent Parrone \nYeah, I also... This is why I\'m really gonna change this to... I\'m gonna change this to Linux probably tomorrow.\n\n31:26 - Will Vincent Parrone \nThis is a bit...\n\n31:34 - Will Vincent Parrone \nAnnoying to... Yeah, maybe like for most people, for me, I should start on trying new things more often.\n\n31:45 - Jorge Lewis \nYeah, that\'s the tough thing. It\'s like what works, works is great. But then learning to like growing is just trying these new things that make you feel uncomfortable. Like it was super uncomfortable for me to learn NeoVim, but I learned it. I tried it and it just doesn\'t work. Like now I know at least. So if people say, oh, you should use NeoVim. I can say, oh, I did. Because a lot of things, when people say, oh, use NeoVim, or sorry, use Vim at least, it\'s just because they heard Providion say it once and twice and ten times, and now they\'re just robots saying, oh, use Vim. Use Linux.\n\n32:21 - Will Vincent Parrone \nYeah. Wait, what\'s the name of the env file again? This is it, right? The public super base URL.\n\n32:29 - Jorge Lewis \nYeah, are you... Let me send you the new one because... Okay. U.S. Edited it a little bit.\n\n32:41 - Will Vincent Parrone \nOkay. I remember. Go ahead. There\'s just this aspect.\n\n32:48 - Jorge Lewis \nAlso, make sure you pull from Alpha because I\'ve been making some changes. Alright, so I\'m saying Google Meets. There\'s just one more variable.\n\n32:57 - Will Vincent Parrone \nOkay. I\'m in Alpha.\n\n33:01 - Will Vincent Parrone \nUm...\n\n33:07 - Will Vincent Parrone \nOkay, public base URL localhost 8080, okay.\n\n33:12 - Jorge Lewis \nYeah, viewers had a little bit of a confusion with some of the variables and what they were doing, but\n######################\nOutput:'}
02:07:11,161 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,164 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "one \nAnd then something within the nginx file, sudo vim etc nginx. It's still wrong.\n\n27:09 - Will Vincent Parrone \nIs there no show config? I might have I might have CSRFs.\n\n27:31 - Will Vincent Parrone \nOh, check origin.\n\n27:33 - Jorge Lewis \nWhat's the CSRF? I've never seen it before.\n\n27:37 - Will Vincent Parrone \nIt's basically the course, it's course related because I'm not using localhost.\n\n27:45 - Jorge Lewis \nto run.\n\n27:49 - Will Vincent Parrone \nI'm basically hosting this in another server, in a Vultr cloud server. That's why I can use it from any device as long as I remember the password.\n\n28:08 - Will Vincent Parrone \nWhich I actually am starting to forget now. What's the name again? Checkorigin.\n\n28:15 - Will Vincent Parrone \nCheck origin. There we go.\n\n28:24 - Will Vincent Parrone \nAnd I know this is going to work now because I am a god. So it's available.\n\n28:36 - Jorge Lewis \nDefault. Now I have to.\n\n28:38 - Jorge Lewis \nThis is Windows, so.\n\n28:46 - Jorge Lewis \nBro, RIP. I'm prompt. You should be using at least PowerShell.\n\n28:53 - Will Vincent Parrone \nReally?\n\n28:55 - Jorge Lewis \nYeah, I prefer using PowerShell, but also WSL works. Like, do you have WSL?\n\n29:04 - Will Vincent Parrone \nActually...\n\n29:08 - Will Vincent Parrone \nYeah. Yeah, I do. I haven't really used it though.\n\n29:20 - Will Vincent Parrone \n5, 1, I just got used to 7, ordinary shell commands. 5.\n\n29:31 - Jorge Lewis \nBut your vulture is Linux.\n\n29:36 - Will Vincent Parrone \nYeah, wait, wait, wait. Sorry. Let me try to center my thoughts first. I was really focused on doing the ng-stuff. What was the question again?\n\n29:49 - Jorge Lewis \nWhy don't you use WSM?\n\n29:51 - Will Vincent Parrone \nOh, right. It's because I keep on forgetting to initialize them, to like start them.\n\n30:03 - Unidentified Speaker \nGotcha.\n\n30:06 - Jorge Lewis \nI mean, I don't, I can't imagine working with commando prompts, but I mean, if you're used to it, then it works.\n\n30:14 - Will Vincent Parrone \nYeah, that's. Actually, that's what's been changing with me recently. My whole mentality is if it works, it works, but I am slightly learning that maybe that's a wrong way of doing things.\n\n30:28 - Jorge Lewis \nIt seems like a balance. For me, when I tried switching to NeoVim, or a better example is I tried switching to Linux, to NixOS, but it's more sexy, it's more flashy. It's like, oh, I use Linux, I use NixOS. I use Vim, by the way, but it just doesn't work for me. What works for me is Windows, because of what I do. It's all very dependent on what you do.\n\n30:58 - Jorge Lewis \nThat's fair.\n\n31:00 - Jorge Lewis \nFor me, I can work so much more efficiently with...\n\n31:06 - Jorge Lewis \nThat happens to me all the time as well. I keep opening those random Windows apps.\n\n31:11 - Will Vincent Parrone \nYeah, I also... This is why I'm really gonna change this to... I'm gonna change this to Linux probably tomorrow.\n\n31:26 - Will Vincent Parrone \nThis is a bit...\n\n31:34 - Will Vincent Parrone \nAnnoying to... Yeah, maybe like for most people, for me, I should start on trying new things more often.\n\n31:45 - Jorge Lewis \nYeah, that's the tough thing. It's like what works, works is great. But then learning to like growing is just trying these new things that make you feel uncomfortable. Like it was super uncomfortable for me to learn NeoVim, but I learned it. I tried it and it just doesn't work. Like now I know at least. So if people say, oh, you should use NeoVim. I can say, oh, I did. Because a lot of things, when people say, oh, use NeoVim, or sorry, use Vim at least, it's just because they heard Providion say it once and twice and ten times, and now they're just robots saying, oh, use Vim. Use Linux.\n\n32:21 - Will Vincent Parrone \nYeah. Wait, what's the name of the env file again? This is it, right? The public super base URL.\n\n32:29 - Jorge Lewis \nYeah, are you... Let me send you the new one because... Okay. U.S. Edited it a little bit.\n\n32:41 - Will Vincent Parrone \nOkay. I remember. Go ahead. There's just this aspect.\n\n32:48 - Jorge Lewis \nAlso, make sure you pull from Alpha because I've been making some changes. Alright, so I'm saying Google Meets. There's just one more variable.\n\n32:57 - Will Vincent Parrone \nOkay. I'm in Alpha.\n\n33:01 - Will Vincent Parrone \nUm...\n\n33:07 - Will Vincent Parrone \nOkay, public base URL localhost 8080, okay.\n\n33:12 - Jorge Lewis \nYeah, viewers had a little bit of a confusion with some of the variables and what they were doing, but"}
02:07:11,170 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,171 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,172 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: as well. Like it won\'t exceed 10 questions, maybe.\n\n53:31 - Jorge Lewis \nSo for time interval, I like time interval more, but what\'s the lowest we can set it at? Because one minute, I don\'t think they can have enough messages. Maybe?\n\n53:42 - Unidentified Speaker \nYeah, right.\n\n53:48 - Jorge Lewis \nWe can play around with the number. We can set it later. Also, one concern I have that I think will be kind of annoying is, so the synthetic user, how will he or when will he send a message? Because how that will work is, this guy sends a message to this guy, this guy responds immediately, the bot responds immediately. And then the synthetic user, because he\'s in LLM, will receive the response and respond immediately as well. And it\'ll keep going. There\'s no way to say, okay, um, yeah, no, not even waiting for it. Like for example, a normal user, they wake up, they\'ll open the app, they\'ll talk, chat with the user, the chatbot and say, Hey, um, hi. They\'ll have a conversation. The phone, the usual, put the phone down. But in our case, the synthetic user, how do we tell him to put the phone down?\n\n54:49 - Unidentified Speaker \nYeah.\n\n54:53 - Hasnain sayyed \nOne, one, one idea.\n\n54:59 - Jorge Lewis \nOne idea is that we separate, um, we give the, the synthetic user, their concept of a, um, of, of a conversation and the synthetic user will know, or we\'ll have an objective for each conversation. And when it reaches that objective, it closes the conversation and then it, um, it calls a function saying let\'s time elapse and it lets an hour or two pass fake, fake one hour or two.\n\n55:32 - Hasnain sayyed \nUh, okay. I got it. Um, but I\'m thinking like how we create that function, like, uh, while conversation between two points, we have to create a loop kind of thing that this is the basic, uh, brute force approach or else we have to based on we have to create a function like based on the like response from the synthetic user it will it will think like if the synthetic user wants to ask another question like wants to give another answer or not or like it will stop at that point this is the two solutions I can think like the\n\n56:17 - Jorge Lewis \nIs the loop, so I have an idea, but it might be the same as a loop. It\'s like a brute force, like you said. A conversation is five minutes. So that after five minutes, they stop talking and we let time to pass. Is that what you\'re suggesting?\n\n56:34 - Jorge Lewis \nYeah, correct, correct.\n\n56:36 - Jorge Lewis \nI think we can do that, yeah.\n\n56:40 - Jorge Lewis \nBut like right now, we don\'t have to worry about that. We can just make it have, We can just let it go back and forth. We don\'t have to worry. And then later we can worry about controlling the time. How does that sound?\n\n56:54 - Hasnain sayyed \nCorrect. We can change the time, whatever we want. It\'s just one variable we have to change.\n\n57:02 - Hasnain sayyed \nYeah, OK, cool.\n\n57:04 - Hasnain sayyed \nYeah, there are normal edge cases in the background, like the synthetic user has to chat one day at a time, like only one day, five minutes or two minutes, whatever we set. It won\'t have to reiterate. Yeah, that\'s the normal edge case.\n\n57:21 - Jorge Lewis \nWe can add all these edge cases, I think, one by one if we need to, right?\n\n57:24 - Hasnain sayyed \nYeah. We have, we have to add a column here. We have to add, uh, like, uh, uh, maybe the last time, uh, he chatted and, uh, based on the last time, uh, it will add 24 hours, whether, uh, it is, uh, like, uh, greater, like it will compare the current time and the last time. And whether there is a gap of 24 hours or not, if there is not a 24 hours gap, then it won\'t execute that function or if there is a gap.\n\n58:07 - Hasnain sayyed \nOne point I have, the one most important question is, it is not a WebSocket, right? It is a HTTP request. Like, how can, how could we let the synthetic user run by itself? Like, okay, the condition satisfies, like, yeah. There is a gap between 24 hours maybe. Then how the synthetic agent will let know like, yeah, there is a 24 hours gap. Like the API hit.\n\n58:39 - Jorge Lewis \nThat\'s a good point. I think we\'ll have to use some sort of either edge servers or edge functions or, um, yeah, I think something related to edge functions.\n\n58:57 - Hasnain sayyed \nOkay.\n\n59:00 - Jorge Lewis \nBut we, yeah, so we\'ll worry about time later since that can be added on top of, um, and by the way, just a quick concept of how we can control all the time is in data in super base, we can store the time, um, like normal, like, uh, as normal, but in the, in the system, the code, we divide\n######################\nOutput:'}
02:07:11,172 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,175 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "as well. Like it won't exceed 10 questions, maybe.\n\n53:31 - Jorge Lewis \nSo for time interval, I like time interval more, but what's the lowest we can set it at? Because one minute, I don't think they can have enough messages. Maybe?\n\n53:42 - Unidentified Speaker \nYeah, right.\n\n53:48 - Jorge Lewis \nWe can play around with the number. We can set it later. Also, one concern I have that I think will be kind of annoying is, so the synthetic user, how will he or when will he send a message? Because how that will work is, this guy sends a message to this guy, this guy responds immediately, the bot responds immediately. And then the synthetic user, because he's in LLM, will receive the response and respond immediately as well. And it'll keep going. There's no way to say, okay, um, yeah, no, not even waiting for it. Like for example, a normal user, they wake up, they'll open the app, they'll talk, chat with the user, the chatbot and say, Hey, um, hi. They'll have a conversation. The phone, the usual, put the phone down. But in our case, the synthetic user, how do we tell him to put the phone down?\n\n54:49 - Unidentified Speaker \nYeah.\n\n54:53 - Hasnain sayyed \nOne, one, one idea.\n\n54:59 - Jorge Lewis \nOne idea is that we separate, um, we give the, the synthetic user, their concept of a, um, of, of a conversation and the synthetic user will know, or we'll have an objective for each conversation. And when it reaches that objective, it closes the conversation and then it, um, it calls a function saying let's time elapse and it lets an hour or two pass fake, fake one hour or two.\n\n55:32 - Hasnain sayyed \nUh, okay. I got it. Um, but I'm thinking like how we create that function, like, uh, while conversation between two points, we have to create a loop kind of thing that this is the basic, uh, brute force approach or else we have to based on we have to create a function like based on the like response from the synthetic user it will it will think like if the synthetic user wants to ask another question like wants to give another answer or not or like it will stop at that point this is the two solutions I can think like the\n\n56:17 - Jorge Lewis \nIs the loop, so I have an idea, but it might be the same as a loop. It's like a brute force, like you said. A conversation is five minutes. So that after five minutes, they stop talking and we let time to pass. Is that what you're suggesting?\n\n56:34 - Jorge Lewis \nYeah, correct, correct.\n\n56:36 - Jorge Lewis \nI think we can do that, yeah.\n\n56:40 - Jorge Lewis \nBut like right now, we don't have to worry about that. We can just make it have, We can just let it go back and forth. We don't have to worry. And then later we can worry about controlling the time. How does that sound?\n\n56:54 - Hasnain sayyed \nCorrect. We can change the time, whatever we want. It's just one variable we have to change.\n\n57:02 - Hasnain sayyed \nYeah, OK, cool.\n\n57:04 - Hasnain sayyed \nYeah, there are normal edge cases in the background, like the synthetic user has to chat one day at a time, like only one day, five minutes or two minutes, whatever we set. It won't have to reiterate. Yeah, that's the normal edge case.\n\n57:21 - Jorge Lewis \nWe can add all these edge cases, I think, one by one if we need to, right?\n\n57:24 - Hasnain sayyed \nYeah. We have, we have to add a column here. We have to add, uh, like, uh, uh, maybe the last time, uh, he chatted and, uh, based on the last time, uh, it will add 24 hours, whether, uh, it is, uh, like, uh, greater, like it will compare the current time and the last time. And whether there is a gap of 24 hours or not, if there is not a 24 hours gap, then it won't execute that function or if there is a gap.\n\n58:07 - Hasnain sayyed \nOne point I have, the one most important question is, it is not a WebSocket, right? It is a HTTP request. Like, how can, how could we let the synthetic user run by itself? Like, okay, the condition satisfies, like, yeah. There is a gap between 24 hours maybe. Then how the synthetic agent will let know like, yeah, there is a 24 hours gap. Like the API hit.\n\n58:39 - Jorge Lewis \nThat's a good point. I think we'll have to use some sort of either edge servers or edge functions or, um, yeah, I think something related to edge functions.\n\n58:57 - Hasnain sayyed \nOkay.\n\n59:00 - Jorge Lewis \nBut we, yeah, so we'll worry about time later since that can be added on top of, um, and by the way, just a quick concept of how we can control all the time is in data in super base, we can store the time, um, like normal, like, uh, as normal, but in the, in the system, the code, we divide"}
02:07:11,176 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: to get information out of the user?\n\n22:58 - Unidentified Speaker \nI can\'t hear you. Oh.\n\n23:06 - Jonas Lindberg \nIs the check-in node basically the collector and the user working together to get the data out of the user? So, yeah. Yeah.\n\n23:17 - Unidentified Speaker \nOkay.\n\n23:17 - Chinmay Pandya \nYeah. The check-in is the collector. I just wrote a check-in because I wanted for it to be clear to me that whenever the user enters new data, it will go to the check-in.\n\n23:30 - Unidentified Speaker \nYeah. Okay.\n\n23:35 - Unidentified Speaker \nYeah.\n\n23:36 - Jonas Lindberg \nSounds good.\n\n23:38 - Unidentified Speaker \nAll right.\n\n23:39 - Jonas Lindberg \nUm, he was, yeah.\n\n23:45 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay.\n\n23:56 - Biwas bhandari \nso basically a user will input something and this chat prompt will decide either it should go to collector or not we can give it logic like if the user checks in then call this function otherwise just chat with the coach and if it chats with the coach it will update in the collector and then it will again return to the user And it\'s basically similar users added their supervisor instead of that prompt.\n\n24:33 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, it looks, I think it\'s identical to, it\'s a little bit different, but I noticed a mistake on Xinmei\'s one that I forgot to do was that the coach should actually be returning to the user. Same for the collector. No point going back to the supervisor.\n\n24:55 - Biwas bhandari \nInstead of supervisor, we can just train, give a logic to the chat prompt. It will be easier.\n\n25:03 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, and then the key feature, the key difference I see is that the coach is connected to the data analyst.\n\n25:10 - Unidentified Speaker \nYep. Do you wanna go through that?\n\n25:15 - Biwas bhandari \nOkay, so in the, yes, when a user will just check in, it will pass it to the collector. And the collector again pass it to the coach and it will pass it, not coach. The collector will pass it to the data analyst.\n\n25:36 - Chinmay Pandya \nSo this makes more sense.\n\n25:42 - Conference Room (Jorge Lewis) - Speaker 1 \nThe arrows, you guys, your graphs are so big that I can\'t see the arrows.\n\n25:49 - Unidentified Speaker \nWell, yep.\n\n25:51 - Biwas bhandari \nThe user will input something and this chat prompt will determine either is the user just checked in or just wants to chat with the coach. And if it wants to check in, it will pass it to the collector and the collector will pass it to the data analyst and the coach and coach will return it to the user.\n\n26:11 - Biwas bhandari \nOkay. It\'s good.\n\n26:12 - Unidentified Speaker \nYes.\n\n26:12 - Biwas bhandari \nWell, I think that\'s good.\n\n26:30 - Chinmay Pandya \nEdge from coach to collector.\n\n26:32 - Unidentified Speaker \nYeah, yeah, exactly.\n\n26:34 - Conference Room (Jorge Lewis) - Speaker 1 \nI was about to ask that.\n\n26:45 - Biwas bhandari \nDid I make it clear or is there any questions? This one.\n\n26:51 - Conference Room (Jorge Lewis) - Speaker 1 \nWhat does the edge between coach and collector represent? Or when does it get triggered?\n\n26:57 - Biwas bhandari \nWhen the user will ask, like you said, why should I do it? How should I do it? And it will update to the collector. No, no. Coach to collector, bro.\n\n27:07 - Unidentified Speaker \nHuh?\n\n27:08 - Chinmay Pandya \nCoach to collector.\n\n27:11 - Unidentified Speaker \nCoach to collector?\n\n27:12 - Biwas bhandari \nWhy would it go to coach to collector?\n\n27:14 - Chinmay Pandya \nYou don\'t have to put it in the database.\n\n27:19 - Biwas bhandari \nI think the conversation between user and coach should also be stored. That\'s why.\n\n27:27 - Conference Room (Jorge Lewis) - Speaker 1 \nSo, so this, so this one is to, okay.\n\n27:32 - Unidentified Speaker \nHmm.\n\n27:35 - Conference Room (Jorge Lewis) - Speaker 2 \nCorrect me if I\'m wrong, but we, I think we can remove the chat prompt nodes and basically just connect coach and collector directly to the user. And that will be basically why you, yeah.\n\n27:57 - Conference Room (Jorge Lewis) - Speaker 1 \nLike that. And keep the user one? Like the user to collector, that arrow?\n\n28:08 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, that\'s when the user is starting to check in, it\'ll go to the collector. Same in my graph, like when the user is starting to check.\n\n28:17 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, conditionals are dotted. OK. So, I mean, just for in terms of the actual line graph, there needs to be a supervisor node to determine who to go to. The user can\'t, so let me just add that.\n######################\nOutput:'}
02:07:11,176 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,179 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "to get information out of the user?\n\n22:58 - Unidentified Speaker \nI can't hear you. Oh.\n\n23:06 - Jonas Lindberg \nIs the check-in node basically the collector and the user working together to get the data out of the user? So, yeah. Yeah.\n\n23:17 - Unidentified Speaker \nOkay.\n\n23:17 - Chinmay Pandya \nYeah. The check-in is the collector. I just wrote a check-in because I wanted for it to be clear to me that whenever the user enters new data, it will go to the check-in.\n\n23:30 - Unidentified Speaker \nYeah. Okay.\n\n23:35 - Unidentified Speaker \nYeah.\n\n23:36 - Jonas Lindberg \nSounds good.\n\n23:38 - Unidentified Speaker \nAll right.\n\n23:39 - Jonas Lindberg \nUm, he was, yeah.\n\n23:45 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay.\n\n23:56 - Biwas bhandari \nso basically a user will input something and this chat prompt will decide either it should go to collector or not we can give it logic like if the user checks in then call this function otherwise just chat with the coach and if it chats with the coach it will update in the collector and then it will again return to the user And it's basically similar users added their supervisor instead of that prompt.\n\n24:33 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, it looks, I think it's identical to, it's a little bit different, but I noticed a mistake on Xinmei's one that I forgot to do was that the coach should actually be returning to the user. Same for the collector. No point going back to the supervisor.\n\n24:55 - Biwas bhandari \nInstead of supervisor, we can just train, give a logic to the chat prompt. It will be easier.\n\n25:03 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, and then the key feature, the key difference I see is that the coach is connected to the data analyst.\n\n25:10 - Unidentified Speaker \nYep. Do you wanna go through that?\n\n25:15 - Biwas bhandari \nOkay, so in the, yes, when a user will just check in, it will pass it to the collector. And the collector again pass it to the coach and it will pass it, not coach. The collector will pass it to the data analyst.\n\n25:36 - Chinmay Pandya \nSo this makes more sense.\n\n25:42 - Conference Room (Jorge Lewis) - Speaker 1 \nThe arrows, you guys, your graphs are so big that I can't see the arrows.\n\n25:49 - Unidentified Speaker \nWell, yep.\n\n25:51 - Biwas bhandari \nThe user will input something and this chat prompt will determine either is the user just checked in or just wants to chat with the coach. And if it wants to check in, it will pass it to the collector and the collector will pass it to the data analyst and the coach and coach will return it to the user.\n\n26:11 - Biwas bhandari \nOkay. It's good.\n\n26:12 - Unidentified Speaker \nYes.\n\n26:12 - Biwas bhandari \nWell, I think that's good.\n\n26:30 - Chinmay Pandya \nEdge from coach to collector.\n\n26:32 - Unidentified Speaker \nYeah, yeah, exactly.\n\n26:34 - Conference Room (Jorge Lewis) - Speaker 1 \nI was about to ask that.\n\n26:45 - Biwas bhandari \nDid I make it clear or is there any questions? This one.\n\n26:51 - Conference Room (Jorge Lewis) - Speaker 1 \nWhat does the edge between coach and collector represent? Or when does it get triggered?\n\n26:57 - Biwas bhandari \nWhen the user will ask, like you said, why should I do it? How should I do it? And it will update to the collector. No, no. Coach to collector, bro.\n\n27:07 - Unidentified Speaker \nHuh?\n\n27:08 - Chinmay Pandya \nCoach to collector.\n\n27:11 - Unidentified Speaker \nCoach to collector?\n\n27:12 - Biwas bhandari \nWhy would it go to coach to collector?\n\n27:14 - Chinmay Pandya \nYou don't have to put it in the database.\n\n27:19 - Biwas bhandari \nI think the conversation between user and coach should also be stored. That's why.\n\n27:27 - Conference Room (Jorge Lewis) - Speaker 1 \nSo, so this, so this one is to, okay.\n\n27:32 - Unidentified Speaker \nHmm.\n\n27:35 - Conference Room (Jorge Lewis) - Speaker 2 \nCorrect me if I'm wrong, but we, I think we can remove the chat prompt nodes and basically just connect coach and collector directly to the user. And that will be basically why you, yeah.\n\n27:57 - Conference Room (Jorge Lewis) - Speaker 1 \nLike that. And keep the user one? Like the user to collector, that arrow?\n\n28:08 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, that's when the user is starting to check in, it'll go to the collector. Same in my graph, like when the user is starting to check.\n\n28:17 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, conditionals are dotted. OK. So, I mean, just for in terms of the actual line graph, there needs to be a supervisor node to determine who to go to. The user can't, so let me just add that."}
02:07:11,222 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,225 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Yeah, that\'s when the user is starting to check in, it\'ll go to the collector. Same in my graph, like when the user is starting to check.\n\n28:17 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, conditionals are dotted. OK. So, I mean, just for in terms of the actual line graph, there needs to be a supervisor node to determine who to go to. The user can\'t, so let me just add that.\n\n28:33 - Unidentified Speaker \nYeah. Well, okay, so.\n\n28:45 - Conference Room (Jorge Lewis) - Speaker 2 \nThe collector has to be able to speak with the user to get back and forth.\n\n28:56 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so it\'s funny we\'ve we\'ve gone we\'ve I think this is now the actual exact same as yeah, it\'s the exact same as she lies away No It\'s the, uh, no, no, the graph is, uh, wait, what is one coach to, okay. Instead of, so there\'s one.\n\n29:35 - Unidentified Speaker \nHello?\n\n29:36 - Chinmay Pandya \nIn his graph, it\'s like it will move to coach and the coach will request analysis from the analyst in mind at the time of checking, it will move always to the analyst then to the coach.\n\n29:49 - Unidentified Speaker \nI see. Yeah, yeah.\n\n29:51 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, cool. Let\'s go through my one and then we can kind of come to a conclusion.\n\n29:57 - Chinmay Pandya \nSo you can decide routing without a supervisor.\n\n30:03 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, but I, yeah, it\'s a bit of a design choice. It\'s like, do you want to delegate the task to a language model to determine from the conversation or do we want to trust the other agents to put a text in their answer?\n\n30:18 - Chinmay Pandya \nYeah, so if we do not want to use a supervisor agent node, then we can use the router logic, which sits between the edges. Sorry, say it again.\n\n30:45 - Conference Room (Jorge Lewis) - Speaker 2 \nFor questions where it\'s like, do we want to delegate this test to a model or to something like that, I think diagram both of them, just so we have both diagrams. And then in the future, we can try both and see which works best.\n\n30:57 - Unidentified Speaker \nYeah. Yeah.\n\n30:58 - Conference Room (Jorge Lewis) - Speaker 1 \nWhen it\'s things that we don\'t know for sure, we\'re better off trying than trying to be like, hmm. I mean, I guess sometimes you can think it through, though.\n\n31:05 - Unidentified Speaker \nYeah.\n\n31:05 - Conference Room (Jorge Lewis) - Speaker 2 \nI think just trying is the most reliable way to get it. And sometimes you think things through, and then you leave. Yeah. Yeah.\n\n31:12 - Conference Room (Jorge Lewis) - Speaker 1 \nCool.\n\n31:15 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so I\'ll go through my one. Did you guys hear all that by the way?\n\n31:27 - Unidentified Speaker \nHello.\n\n31:28 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah. Did you guys hear the, what Jonas was saying?\n\n31:32 - Chinmay Pandya \nNo, we couldn\'t hear what he said. Not quite clearly.\n\n31:36 - Unidentified Speaker \nOkay.\n\n31:37 - Conference Room (Jorge Lewis) - Speaker 1 \nUm, he said that\'s when we have things like that, we don\'t know for sure. It\'s better to just try them out in the code and see which one actually performs better. Because sometimes through discussion, it\'s not enough to actually get a real world understanding of it.\n\n31:53 - Unidentified Speaker \nYeah.\n\n31:55 - Chinmay Pandya \nIf it works or not, unless we. Language models are so unpredictable.\n\n31:59 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then also when you\'re trying to code it in that process, you understand like new under the table, like problems and stuff. Yeah. Um, okay. So I\'ll go through mine and then we can kind of conclude. So. Let me try to remember, what\'s the, why I have two?\n\n32:19 - Unidentified Speaker \nOkay.\n\n32:25 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, the bottom one is better. The bottom one\'s better. I\'ll explain the top one after, but just the bottom one\'s better. So first of all, we start with user, and the concept of this is where the collector will receive every message first, And if the message is related to the collector\'s task, so for example, if the user is passing the message, or if the user says, let\'s check in, or if the user says, dude, I\'m done with my check in, you\'re so boring, let\'s stop the check in any of those things, the collector will call his tools and complete those actions. But if the user is not invoking is not like trying to invoke one of those tools, the collector without responding or without doing any actions, Or maybe he will do some actions. We\'ll pass it to the coach, and the coach will make a response. So for example, if the user\n######################\nOutput:'}
02:07:11,225 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,229 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Yeah, that's when the user is starting to check in, it'll go to the collector. Same in my graph, like when the user is starting to check.\n\n28:17 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, conditionals are dotted. OK. So, I mean, just for in terms of the actual line graph, there needs to be a supervisor node to determine who to go to. The user can't, so let me just add that.\n\n28:33 - Unidentified Speaker \nYeah. Well, okay, so.\n\n28:45 - Conference Room (Jorge Lewis) - Speaker 2 \nThe collector has to be able to speak with the user to get back and forth.\n\n28:56 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so it's funny we've we've gone we've I think this is now the actual exact same as yeah, it's the exact same as she lies away No It's the, uh, no, no, the graph is, uh, wait, what is one coach to, okay. Instead of, so there's one.\n\n29:35 - Unidentified Speaker \nHello?\n\n29:36 - Chinmay Pandya \nIn his graph, it's like it will move to coach and the coach will request analysis from the analyst in mind at the time of checking, it will move always to the analyst then to the coach.\n\n29:49 - Unidentified Speaker \nI see. Yeah, yeah.\n\n29:51 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, cool. Let's go through my one and then we can kind of come to a conclusion.\n\n29:57 - Chinmay Pandya \nSo you can decide routing without a supervisor.\n\n30:03 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, but I, yeah, it's a bit of a design choice. It's like, do you want to delegate the task to a language model to determine from the conversation or do we want to trust the other agents to put a text in their answer?\n\n30:18 - Chinmay Pandya \nYeah, so if we do not want to use a supervisor agent node, then we can use the router logic, which sits between the edges. Sorry, say it again.\n\n30:45 - Conference Room (Jorge Lewis) - Speaker 2 \nFor questions where it's like, do we want to delegate this test to a model or to something like that, I think diagram both of them, just so we have both diagrams. And then in the future, we can try both and see which works best.\n\n30:57 - Unidentified Speaker \nYeah. Yeah.\n\n30:58 - Conference Room (Jorge Lewis) - Speaker 1 \nWhen it's things that we don't know for sure, we're better off trying than trying to be like, hmm. I mean, I guess sometimes you can think it through, though.\n\n31:05 - Unidentified Speaker \nYeah.\n\n31:05 - Conference Room (Jorge Lewis) - Speaker 2 \nI think just trying is the most reliable way to get it. And sometimes you think things through, and then you leave. Yeah. Yeah.\n\n31:12 - Conference Room (Jorge Lewis) - Speaker 1 \nCool.\n\n31:15 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so I'll go through my one. Did you guys hear all that by the way?\n\n31:27 - Unidentified Speaker \nHello.\n\n31:28 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah. Did you guys hear the, what Jonas was saying?\n\n31:32 - Chinmay Pandya \nNo, we couldn't hear what he said. Not quite clearly.\n\n31:36 - Unidentified Speaker \nOkay.\n\n31:37 - Conference Room (Jorge Lewis) - Speaker 1 \nUm, he said that's when we have things like that, we don't know for sure. It's better to just try them out in the code and see which one actually performs better. Because sometimes through discussion, it's not enough to actually get a real world understanding of it.\n\n31:53 - Unidentified Speaker \nYeah.\n\n31:55 - Chinmay Pandya \nIf it works or not, unless we. Language models are so unpredictable.\n\n31:59 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd then also when you're trying to code it in that process, you understand like new under the table, like problems and stuff. Yeah. Um, okay. So I'll go through mine and then we can kind of conclude. So. Let me try to remember, what's the, why I have two?\n\n32:19 - Unidentified Speaker \nOkay.\n\n32:25 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, the bottom one is better. The bottom one's better. I'll explain the top one after, but just the bottom one's better. So first of all, we start with user, and the concept of this is where the collector will receive every message first, And if the message is related to the collector's task, so for example, if the user is passing the message, or if the user says, let's check in, or if the user says, dude, I'm done with my check in, you're so boring, let's stop the check in any of those things, the collector will call his tools and complete those actions. But if the user is not invoking is not like trying to invoke one of those tools, the collector without responding or without doing any actions, Or maybe he will do some actions. We'll pass it to the coach, and the coach will make a response. So for example, if the user"}
02:07:11,325 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,327 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: the user says, dude, I\'m done with my check in, you\'re so boring, let\'s stop the check in any of those things, the collector will call his tools and complete those actions. But if the user is not invoking is not like trying to invoke one of those tools, the collector without responding or without doing any actions, Or maybe he will do some actions. We\'ll pass it to the coach, and the coach will make a response. So for example, if the user says, let\'s check in, the collector will call his tool that says start check-in, and he\'ll pass it to coach. Or the collector will respond and gather the data. As soon as the data is collected, it\'ll go to coach. The coach will provide some feedback. If the user is responding to that feedback, it\'ll go to the collector first. The collector will see, will tell it, or will teach it how to understand when it\'s responding to the coach, and it\'ll hand it off to the coach directly. So it\'s kind of being in the middle of a supervisor, but also just telling it, hey, if this is applicable to you, do something. If it\'s not, just hand it off to the coach, which is always a direct line. So it\'ll always pass it to the coach. Although this is not the case, actually. Sometimes when the user says, let\'s check in, the collector should say, OK, he should prompt the user to ask or give information. There\'s no one else in.\n\n34:11 - Conference Room (Jorge Lewis) - Speaker 2 \nMy speaker\'s not loud enough.\n\n34:15 - Unidentified Speaker \nIt isn\'t.\n\n34:16 - Conference Room (Jorge Lewis) - Speaker 2 \nMine is. Mine isn\'t.\n\n34:18 - Conference Room (Jorge Lewis) - Speaker 1 \nI can show you. You can just get the Chrome extension. My speakers like start buzzing.\n\n34:27 - Unidentified Speaker \nIs yours not?\n\n34:33 - Conference Room (Jorge Lewis) - Speaker 1 \nNo. So for the collector, if the collector calls new or update check-in, so as in the user gives new data, he\'ll pass it to the analyst and the analyst will then go to the coach. But if it\'s something like, if he\'s starting a check-in or if he\'s ending a check-in, it\'ll most likely go to the coach.\n\n34:55 - Conference Room (Jorge Lewis) - Speaker 1 \nDoes that make sense or can I have some questions?\n\n35:00 - Chinmay Pandya \nYeah, so who will ask the follow-ups?\n\n35:04 - Unidentified Speaker \nSorry?\n\n35:05 - Chinmay Pandya \nWho will ask the follow-ups or if let\'s say the user has checked in, so the collector has either two choices, either go to the coach, not call any tools, or either call his tools to get previous data. But what if you want to have a conversation between collector and user to get more data before it passes to the coach?\n\n35:32 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, so then if the data has not, so usually this edge will only be triggered when updates check, when update check-in is called, usually. I think there\'s probably some more nuanced cases.\n\n35:51 - Conference Room (Jorge Lewis) - Speaker 1 \nSo for example, the user says, I walked around the block, my house\'s block, and the collector will see that and say, okay, that\'s not enough information for me to update the database. So let me go back to the user and ask for more information or try to pry it out. Otherwise, if we know we have the information we need, then we\'re going to pass it to the coach. Not the analyst. Or then the analyst first and then the coach. But when would this line ever go? This line would go when it\'s not new data. So if it\'s, if the user is responding to a coach, so like, let\'s say the coach says you should walk five, five KM instead of one, by the way, I don\'t know why we\'re using miles. So everyone, like literally everyone in the, in this entire project uses KM. So you guys use KM, right? Yeah. Yeah. So, okay. Even the client uses it.\n\n36:38 - Conference Room (Jorge Lewis) - Speaker 2 \nWouldn\'t that go use for coach then? Why pass it to collector just for the collector to go? I don\'t need to do anything to this.\n\n36:45 - Conference Room (Jorge Lewis) - Speaker 1 \nNo, because then otherwise we\'d need a router every single time and it would be actually cost more than a collector itself.\n\n36:51 - Unidentified Speaker \nOkay.\n\n36:52 - Conference Room (Jorge Lewis) - Speaker 2 \nSo it\'s basically if we want to leave it like the responsibility to the collector. Yeah.\n\n36:56 - Conference Room (Jorge Lewis) - Speaker 1 \nSo it\'s just saying collector may or may not do anything, but making a route to collector by default solves the problem of introducing an extra supervisor.\n\n37:03 - Conference Room (Jorge Lewis) - Speaker 2 \nCould you add the comment on that line instead of just update check-in, just no new relevant info, or just the coach is having a conversation, the collector does nothing.\n\n37:12 - Unidentified Speaker \nYeah, just default, I think.\n\n37:14 - Conference Room (Jorge Lewis) - Speaker 1 \nThe collector does nothing. Yeah, collector does nothing.\n\n37:\n######################\nOutput:'}
02:07:11,327 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,330 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "the user says, dude, I'm done with my check in, you're so boring, let's stop the check in any of those things, the collector will call his tools and complete those actions. But if the user is not invoking is not like trying to invoke one of those tools, the collector without responding or without doing any actions, Or maybe he will do some actions. We'll pass it to the coach, and the coach will make a response. So for example, if the user says, let's check in, the collector will call his tool that says start check-in, and he'll pass it to coach. Or the collector will respond and gather the data. As soon as the data is collected, it'll go to coach. The coach will provide some feedback. If the user is responding to that feedback, it'll go to the collector first. The collector will see, will tell it, or will teach it how to understand when it's responding to the coach, and it'll hand it off to the coach directly. So it's kind of being in the middle of a supervisor, but also just telling it, hey, if this is applicable to you, do something. If it's not, just hand it off to the coach, which is always a direct line. So it'll always pass it to the coach. Although this is not the case, actually. Sometimes when the user says, let's check in, the collector should say, OK, he should prompt the user to ask or give information. There's no one else in.\n\n34:11 - Conference Room (Jorge Lewis) - Speaker 2 \nMy speaker's not loud enough.\n\n34:15 - Unidentified Speaker \nIt isn't.\n\n34:16 - Conference Room (Jorge Lewis) - Speaker 2 \nMine is. Mine isn't.\n\n34:18 - Conference Room (Jorge Lewis) - Speaker 1 \nI can show you. You can just get the Chrome extension. My speakers like start buzzing.\n\n34:27 - Unidentified Speaker \nIs yours not?\n\n34:33 - Conference Room (Jorge Lewis) - Speaker 1 \nNo. So for the collector, if the collector calls new or update check-in, so as in the user gives new data, he'll pass it to the analyst and the analyst will then go to the coach. But if it's something like, if he's starting a check-in or if he's ending a check-in, it'll most likely go to the coach.\n\n34:55 - Conference Room (Jorge Lewis) - Speaker 1 \nDoes that make sense or can I have some questions?\n\n35:00 - Chinmay Pandya \nYeah, so who will ask the follow-ups?\n\n35:04 - Unidentified Speaker \nSorry?\n\n35:05 - Chinmay Pandya \nWho will ask the follow-ups or if let's say the user has checked in, so the collector has either two choices, either go to the coach, not call any tools, or either call his tools to get previous data. But what if you want to have a conversation between collector and user to get more data before it passes to the coach?\n\n35:32 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, so then if the data has not, so usually this edge will only be triggered when updates check, when update check-in is called, usually. I think there's probably some more nuanced cases.\n\n35:51 - Conference Room (Jorge Lewis) - Speaker 1 \nSo for example, the user says, I walked around the block, my house's block, and the collector will see that and say, okay, that's not enough information for me to update the database. So let me go back to the user and ask for more information or try to pry it out. Otherwise, if we know we have the information we need, then we're going to pass it to the coach. Not the analyst. Or then the analyst first and then the coach. But when would this line ever go? This line would go when it's not new data. So if it's, if the user is responding to a coach, so like, let's say the coach says you should walk five, five KM instead of one, by the way, I don't know why we're using miles. So everyone, like literally everyone in the, in this entire project uses KM. So you guys use KM, right? Yeah. Yeah. So, okay. Even the client uses it.\n\n36:38 - Conference Room (Jorge Lewis) - Speaker 2 \nWouldn't that go use for coach then? Why pass it to collector just for the collector to go? I don't need to do anything to this.\n\n36:45 - Conference Room (Jorge Lewis) - Speaker 1 \nNo, because then otherwise we'd need a router every single time and it would be actually cost more than a collector itself.\n\n36:51 - Unidentified Speaker \nOkay.\n\n36:52 - Conference Room (Jorge Lewis) - Speaker 2 \nSo it's basically if we want to leave it like the responsibility to the collector. Yeah.\n\n36:56 - Conference Room (Jorge Lewis) - Speaker 1 \nSo it's just saying collector may or may not do anything, but making a route to collector by default solves the problem of introducing an extra supervisor.\n\n37:03 - Conference Room (Jorge Lewis) - Speaker 2 \nCould you add the comment on that line instead of just update check-in, just no new relevant info, or just the coach is having a conversation, the collector does nothing.\n\n37:12 - Unidentified Speaker \nYeah, just default, I think.\n\n37:14 - Conference Room (Jorge Lewis) - Speaker 1 \nThe collector does nothing. Yeah, collector does nothing.\n\n37:"}
02:07:11,342 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,342 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,342 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,344 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: functions.\n\n58:57 - Hasnain sayyed \nOkay.\n\n59:00 - Jorge Lewis \nBut we, yeah, so we\'ll worry about time later since that can be added on top of, um, and by the way, just a quick concept of how we can control all the time is in data in super base, we can store the time, um, like normal, like, uh, as normal, but in the, in the system, the code, we divide it by a multiplier. So that\'s one, one minute for us.\n\n59:25 - Jorge Lewis \nwe multiply it by a multiplier, not divide it. So 20 seconds for us, we multiply it by 100, that\'s 2,000 for them.\n\n59:44 - Jorge Lewis \nAnyways, all right, let\'s get into it. So you can open VS Code, share a live share link. So it\'s 1.30, we\'ve already done an hour. Let\'s do 30 more minutes if you don\'t mind. Just so we can get some coding in.\n\n59:55 - Hasnain sayyed \nYeah, sure.\n\n1:00:24 - Hasnain sayyed \nOkay, I have sent in the chat.\n\n1:00:49 - Hasnain sayyed \nCan you access it?\n\n1:00:57 - Jorge Lewis \nTrying now.\n\n1:01:08 - Hasnain sayyed \nShould I create a column here that the last time maybe, because that\'s the starting point to write the function, the last time compared by the current time.\n\n1:01:32 - Jorge Lewis \nSorry, could you say that again? I was working on the VS code thing.\n\n1:01:37 - Hasnain sayyed \nOkay, so I was telling like, we have to like, as I said, before, we have to add a time variable in the synthetic table, like the last run.\n\n1:01:54 - Hasnain sayyed \nYeah, last executed. Oh, yeah. So We can compare the last executed with the current time. And if that is not more than 24 hours, then that synthetic user won\'t execute. And if it is more than two hours or maybe equal to, then we can execute.\n\n1:02:18 - Jorge Lewis \nYeah, but what I would suggest is we ignore the time controlling first because that will expand the scope a lot and there\'s so many different edge cases to manage that it\'ll kind of not allow us to focus on getting something first. So we have this task, we have to make a simulation system. We need this system, we want to, we want to get something done, something that we can see the smallest thing that we can see is going to be one conversation back and forth. We don\'t need to worry about time. It\'s just a user having the synthetic user having a conversation with the ball. You can have a stop button so that they don\'t forever go on.\n\n1:03:03 - Unidentified Speaker \nOkay.\n\n1:03:05 - Jorge Lewis \nAnd then later you can already be excited to see that you can have conversations. And, um, yeah.\n\n1:03:14 - Hasnain sayyed \nGot it.\n\n1:03:17 - Hasnain sayyed \nSo first thing, what should we start like with the super base creating functions or what else? What do you suggest?\n\n1:03:27 - Jorge Lewis \nSo I\'ll leave it up to you. I\'m going to, I\'m going to leave it up to you. You, you can think, okay, we\'ve got a couple of things to do. I\'m just picking one. Usually it works pretty well. Just starting. It\'s hard to find the right answer because they\'re all OK.\n\n1:03:47 - Hasnain sayyed \nBecause the main thing that is coming to my mind is that function to create.\n\n1:04:07 - Hasnain sayyed \nI\'m thinking how to execute that.\n\n1:04:18 - Hasnain sayyed \nOkay, so one thing we can do is and getting this for this. You we have to create a rag over here like the sorry the graph sorry the graph will be similar to this everything will be similar to this folder but that will make the easy and the starting point will be\n\n1:06:14 - Hasnain sayyed \ngraph Okay.\n\n1:06:17 - Hasnain sayyed \nEverything I think will be similar, uh, to this folder itself. Uh, just, uh, this folder is calling the real user. It will, in this folder, we will be calling the synthetic user. And additionally, uh, the top layer will be the edge case that we have talked like the time variable.\n\n1:06:35 - Jorge Lewis \nRight.\n\n1:06:37 - Jorge Lewis \nWe, we, I don\'t think so. Are you, are you suggesting we just copy and paste the AI folder?\n\n1:06:49 - Hasnain sayyed \nUh, yes. Or I don\'t like, are you saying that the not copy pasting, like, uh, in the synthetic user, it will be having a chat with, uh, AI agent, right. Uh, and the AI agent code won\'t invoke by itself. We have to, uh, create a flow between, uh, these two, uh, the synthetic and the AI agent. So, uh, in the current folder itself in the AI agent, uh, folder, there is a chat between real user and the AI agent. So the code for the AI agent will similar\n######################\nOutput:'}
02:07:11,344 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,348 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "functions.\n\n58:57 - Hasnain sayyed \nOkay.\n\n59:00 - Jorge Lewis \nBut we, yeah, so we'll worry about time later since that can be added on top of, um, and by the way, just a quick concept of how we can control all the time is in data in super base, we can store the time, um, like normal, like, uh, as normal, but in the, in the system, the code, we divide it by a multiplier. So that's one, one minute for us.\n\n59:25 - Jorge Lewis \nwe multiply it by a multiplier, not divide it. So 20 seconds for us, we multiply it by 100, that's 2,000 for them.\n\n59:44 - Jorge Lewis \nAnyways, all right, let's get into it. So you can open VS Code, share a live share link. So it's 1.30, we've already done an hour. Let's do 30 more minutes if you don't mind. Just so we can get some coding in.\n\n59:55 - Hasnain sayyed \nYeah, sure.\n\n1:00:24 - Hasnain sayyed \nOkay, I have sent in the chat.\n\n1:00:49 - Hasnain sayyed \nCan you access it?\n\n1:00:57 - Jorge Lewis \nTrying now.\n\n1:01:08 - Hasnain sayyed \nShould I create a column here that the last time maybe, because that's the starting point to write the function, the last time compared by the current time.\n\n1:01:32 - Jorge Lewis \nSorry, could you say that again? I was working on the VS code thing.\n\n1:01:37 - Hasnain sayyed \nOkay, so I was telling like, we have to like, as I said, before, we have to add a time variable in the synthetic table, like the last run.\n\n1:01:54 - Hasnain sayyed \nYeah, last executed. Oh, yeah. So We can compare the last executed with the current time. And if that is not more than 24 hours, then that synthetic user won't execute. And if it is more than two hours or maybe equal to, then we can execute.\n\n1:02:18 - Jorge Lewis \nYeah, but what I would suggest is we ignore the time controlling first because that will expand the scope a lot and there's so many different edge cases to manage that it'll kind of not allow us to focus on getting something first. So we have this task, we have to make a simulation system. We need this system, we want to, we want to get something done, something that we can see the smallest thing that we can see is going to be one conversation back and forth. We don't need to worry about time. It's just a user having the synthetic user having a conversation with the ball. You can have a stop button so that they don't forever go on.\n\n1:03:03 - Unidentified Speaker \nOkay.\n\n1:03:05 - Jorge Lewis \nAnd then later you can already be excited to see that you can have conversations. And, um, yeah.\n\n1:03:14 - Hasnain sayyed \nGot it.\n\n1:03:17 - Hasnain sayyed \nSo first thing, what should we start like with the super base creating functions or what else? What do you suggest?\n\n1:03:27 - Jorge Lewis \nSo I'll leave it up to you. I'm going to, I'm going to leave it up to you. You, you can think, okay, we've got a couple of things to do. I'm just picking one. Usually it works pretty well. Just starting. It's hard to find the right answer because they're all OK.\n\n1:03:47 - Hasnain sayyed \nBecause the main thing that is coming to my mind is that function to create.\n\n1:04:07 - Hasnain sayyed \nI'm thinking how to execute that.\n\n1:04:18 - Hasnain sayyed \nOkay, so one thing we can do is and getting this for this. You we have to create a rag over here like the sorry the graph sorry the graph will be similar to this everything will be similar to this folder but that will make the easy and the starting point will be\n\n1:06:14 - Hasnain sayyed \ngraph Okay.\n\n1:06:17 - Hasnain sayyed \nEverything I think will be similar, uh, to this folder itself. Uh, just, uh, this folder is calling the real user. It will, in this folder, we will be calling the synthetic user. And additionally, uh, the top layer will be the edge case that we have talked like the time variable.\n\n1:06:35 - Jorge Lewis \nRight.\n\n1:06:37 - Jorge Lewis \nWe, we, I don't think so. Are you, are you suggesting we just copy and paste the AI folder?\n\n1:06:49 - Hasnain sayyed \nUh, yes. Or I don't like, are you saying that the not copy pasting, like, uh, in the synthetic user, it will be having a chat with, uh, AI agent, right. Uh, and the AI agent code won't invoke by itself. We have to, uh, create a flow between, uh, these two, uh, the synthetic and the AI agent. So, uh, in the current folder itself in the AI agent, uh, folder, there is a chat between real user and the AI agent. So the code for the AI agent will similar"}
02:07:11,351 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 52 - Will Vincent Parrone \nI\'ll say this. This is what Q1 had said. Remember, in terms of sequence, they could have signed up for the newsletter before the Y experience. And they can call to the mobile app. Try the Y experience and want to sign up. So basically, people from the newsletter would be signing in. Should we do some kind of creating an account if a person came from the newsletter, like the workflow of it?\n\n1:16:25 - Jorge Lewis \nYeah, described, so we\'re still, I feel like we\'re still aligned. I feel like he just misinterpreted what we do. So in FigJam, make a user flow of this user process and use these images here. So create a user flow saying, okay, and it\'s already there online on FigJam. If you open the depth spec, there\'s actually a section for the user flow, just called discovery. And in that discovery, what you should do is kind of duplicate it. Can you open FigJam?\n\n1:17:01 - Will Vincent Parrone \nWait, let me see.\n\n1:17:19 - Will Vincent Parrone \nHere we go.\n\n1:17:24 - Jorge Lewis \nSo I duplicate the discovery section over here, full user auth flow. In here, search and expand upon it to create the full version with the technical thing. So saying, signs up, replacing that with more in-depth things like how they sign up.\n\n1:17:47 - Will Vincent Parrone \nAnd then reply to them, yeah.\n\n1:17:49 - Will Vincent Parrone \nSounds like a plan to me then.\n\n1:17:51 - Jorge Lewis \nI think, let them know, say, um, that sounds, that sounds right. Let me make a FigDem to make, to double check.\n\n1:18:01 - Unidentified Speaker \nOkay.\n\n1:18:02 - Will Vincent Parrone \nI\'ll message them on Discord then. Wait, let me message Kuan now to see if I get what you\'re saying.\n\n1:18:23 - Will Vincent Parrone \nJust to make sure that we\'re also perfectly aligned, I\'ll be creating a user on how the sign up experience would look like,\n\n1:18:42 - Will Vincent Parrone \nSounds like a plan.\n\n1:18:54 - Will Vincent Parrone \nincluding again.\n\n1:19:00 - Unidentified Speaker \nYep.\n\n1:19:03 - Will Vincent Parrone \nThis looks good to me. Anything else?\n\n1:19:07 - Jorge Lewis \nLet me check the message out.\n\n1:19:13 - Jorge Lewis \nSo your message, it doesn\'t feel like, so I mean, he says perfect, but for me, it would be even more clear for sure thing. Like that, It just sounds like all you\'re saying, it sounds like he said something and then all you said was yes. But what does yes mean? Does it mean yes, that\'s what we have in mind or yes, I\'m going to change my mind? Yes, thanks for the clarification. So when we say sure thing, what do you mean by that?\n\n1:19:44 - Will Vincent Parrone \nI just basically, I\'m just basically saying that I understand. I\'ll keep note of what you\'ve said. That\'s what I meant by sure thing.\n\n1:20:00 - Jorge Lewis \nBut we don\'t want to be just keeping note. We want to make sure that we can give more than that. So for example, he says, this is what we\'ve discussed. How does that interact with what you guys are planning? It\'s pointless to say, I understand, just as a first thing.\n\n1:20:27 - Jorge Lewis \nBecause there\'s things that we need to clear up.\n\n1:20:32 - Jorge Lewis \nWe can\'t avoid the conflict of having cleared things up. That\'s what it feels like, Because there\'s a conflict which is, we talked about the UX being via the mentor chat with action buttons. Do you understand what he means?\n\n1:20:45 - Will Vincent Parrone \nI think right now, he is talking about the mockups.\n\n1:20:54 - Jorge Lewis \nWait.\n\n1:20:56 - Jorge Lewis \nSo the answer is no. It doesn\'t sound like you know what he means. Neither do I. Like, I don\'t know exactly what he means. So it\'s, we can\'t just say yes. We\'re better off to saying, okay, to make sure that we\'re aligned. Like don\'t, because saying it\'s, um, it\'s like a false sense of security for him. And it\'s bad because if he thinks, if it creates an assumption that we understand, and then later down the road, it could bite us in the ass. This one specific example may not be the case, but for things like this, I\'ve definitely seen it happen. I wouldn\'t be stressing it as much if I didn\'t see this happen before.\n\n1:21:38 - Jorge Lewis \nIf you feel what I\'m saying.\n\n1:21:40 - Will Vincent Parrone \nOkay, okay. I hear what you\'re saying.\n\n1:21:48 - Will Vincent Parrone \nSo, what are the improvements that you think I should do, like, It\'s not on how I voice my messages. I think it\'s being a bit more inquisitive. Questioning, I suppose.\n\n1:22:02 - Jorge Lewis \nSo, of course, it depends on your style then.\n\n1:22:14 - Will Vincent Parrone \nMm-hmm.\n\n1:22:21 - Will Vincent Parrone \nSorry.\n\n1:\n######################\nOutput:'}
02:07:11,351 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,355 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "52 - Will Vincent Parrone \nI'll say this. This is what Q1 had said. Remember, in terms of sequence, they could have signed up for the newsletter before the Y experience. And they can call to the mobile app. Try the Y experience and want to sign up. So basically, people from the newsletter would be signing in. Should we do some kind of creating an account if a person came from the newsletter, like the workflow of it?\n\n1:16:25 - Jorge Lewis \nYeah, described, so we're still, I feel like we're still aligned. I feel like he just misinterpreted what we do. So in FigJam, make a user flow of this user process and use these images here. So create a user flow saying, okay, and it's already there online on FigJam. If you open the depth spec, there's actually a section for the user flow, just called discovery. And in that discovery, what you should do is kind of duplicate it. Can you open FigJam?\n\n1:17:01 - Will Vincent Parrone \nWait, let me see.\n\n1:17:19 - Will Vincent Parrone \nHere we go.\n\n1:17:24 - Jorge Lewis \nSo I duplicate the discovery section over here, full user auth flow. In here, search and expand upon it to create the full version with the technical thing. So saying, signs up, replacing that with more in-depth things like how they sign up.\n\n1:17:47 - Will Vincent Parrone \nAnd then reply to them, yeah.\n\n1:17:49 - Will Vincent Parrone \nSounds like a plan to me then.\n\n1:17:51 - Jorge Lewis \nI think, let them know, say, um, that sounds, that sounds right. Let me make a FigDem to make, to double check.\n\n1:18:01 - Unidentified Speaker \nOkay.\n\n1:18:02 - Will Vincent Parrone \nI'll message them on Discord then. Wait, let me message Kuan now to see if I get what you're saying.\n\n1:18:23 - Will Vincent Parrone \nJust to make sure that we're also perfectly aligned, I'll be creating a user on how the sign up experience would look like,\n\n1:18:42 - Will Vincent Parrone \nSounds like a plan.\n\n1:18:54 - Will Vincent Parrone \nincluding again.\n\n1:19:00 - Unidentified Speaker \nYep.\n\n1:19:03 - Will Vincent Parrone \nThis looks good to me. Anything else?\n\n1:19:07 - Jorge Lewis \nLet me check the message out.\n\n1:19:13 - Jorge Lewis \nSo your message, it doesn't feel like, so I mean, he says perfect, but for me, it would be even more clear for sure thing. Like that, It just sounds like all you're saying, it sounds like he said something and then all you said was yes. But what does yes mean? Does it mean yes, that's what we have in mind or yes, I'm going to change my mind? Yes, thanks for the clarification. So when we say sure thing, what do you mean by that?\n\n1:19:44 - Will Vincent Parrone \nI just basically, I'm just basically saying that I understand. I'll keep note of what you've said. That's what I meant by sure thing.\n\n1:20:00 - Jorge Lewis \nBut we don't want to be just keeping note. We want to make sure that we can give more than that. So for example, he says, this is what we've discussed. How does that interact with what you guys are planning? It's pointless to say, I understand, just as a first thing.\n\n1:20:27 - Jorge Lewis \nBecause there's things that we need to clear up.\n\n1:20:32 - Jorge Lewis \nWe can't avoid the conflict of having cleared things up. That's what it feels like, Because there's a conflict which is, we talked about the UX being via the mentor chat with action buttons. Do you understand what he means?\n\n1:20:45 - Will Vincent Parrone \nI think right now, he is talking about the mockups.\n\n1:20:54 - Jorge Lewis \nWait.\n\n1:20:56 - Jorge Lewis \nSo the answer is no. It doesn't sound like you know what he means. Neither do I. Like, I don't know exactly what he means. So it's, we can't just say yes. We're better off to saying, okay, to make sure that we're aligned. Like don't, because saying it's, um, it's like a false sense of security for him. And it's bad because if he thinks, if it creates an assumption that we understand, and then later down the road, it could bite us in the ass. This one specific example may not be the case, but for things like this, I've definitely seen it happen. I wouldn't be stressing it as much if I didn't see this happen before.\n\n1:21:38 - Jorge Lewis \nIf you feel what I'm saying.\n\n1:21:40 - Will Vincent Parrone \nOkay, okay. I hear what you're saying.\n\n1:21:48 - Will Vincent Parrone \nSo, what are the improvements that you think I should do, like, It's not on how I voice my messages. I think it's being a bit more inquisitive. Questioning, I suppose.\n\n1:22:02 - Jorge Lewis \nSo, of course, it depends on your style then.\n\n1:22:14 - Will Vincent Parrone \nMm-hmm.\n\n1:22:21 - Will Vincent Parrone \nSorry.\n\n1:"}
02:07:11,358 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: an extra supervisor.\n\n37:03 - Conference Room (Jorge Lewis) - Speaker 2 \nCould you add the comment on that line instead of just update check-in, just no new relevant info, or just the coach is having a conversation, the collector does nothing.\n\n37:12 - Unidentified Speaker \nYeah, just default, I think.\n\n37:14 - Conference Room (Jorge Lewis) - Speaker 1 \nThe collector does nothing. Yeah, collector does nothing.\n\n37:21 - Chinmay Pandya \nSo whenever the user enters a prompt or check-in, and if the data is not enough, then will the collector add that to the database first or ask more questions?\n\n37:33 - Unidentified Speaker \nSorry, just repeat that.\n\n37:35 - Chinmay Pandya \nIf the user enters something which is not enough, not enough to analyze, like you said, he walked, he just walked around and if the collector wants to know more data before he passes to the analyzer, then will he update the database, the pieces of information he gets when he gets those pieces, or will he update the information once he gets enough pieces?\n\n38:04 - Conference Room (Jorge Lewis) - Speaker 1 \nHe, he has to do it when he gets enough pieces because in the data, this is a, oh, this is the wrong project.\n\n38:12 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah.\n\n38:13 - Conference Room (Jorge Lewis) - Speaker 1 \nUm, so, so in the database, there\'s columns specifically for the items. So things like, um, the NKM, how far has the user walked? So if the user has given anything other than that, the collector needs the number of kilometers the user has walked. Um, so if the user says I walked around.\n\n38:34 - Conference Room (Jorge Lewis) - Speaker 1 \nI walked around a football pitch three times. The collector could interpret this and say, okay, so, or if the user says something like that, then the collector, if he\'s very certain that the distance of a football pitch, then he can do it.\n\n38:51 - Unidentified Speaker \nYeah.\n\n38:56 - Chinmay Pandya \nSo if you add a node in between, which has the function to decide whether the information is enough or not. And then when the information is enough, then it will pass to the collector. So the collector won\'t have to decide additional logic to maintain whether the information is enough or not. Collector can just have two functions, whether call from the database or pass it to the coach.\n\n39:32 - Chinmay Pandya \nRight now, collector has three logics. Call from the database, pass it to the coach, or check whether data is enough or not. So if the data is not enough, we can add another node which decides if the data is enough or not before passing it to the collector.\n\n39:48 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, I see. I think both will work. Your one is kind of more robust. I\'m trying to think of any downsides of introducing an extra node in the middle here.\n\n40:09 - Conference Room (Jorge Lewis) - Speaker 2 \nI haven\'t heard any of the context, but I don\'t think we should avoid introducing nodes.\n\n40:15 - Conference Room (Jorge Lewis) - Speaker 1 \nThere is actually a problem, though, with speed, with time. Because once we introduce too many nodes, the duration for a response becomes actually unbearable.\n\n40:26 - Conference Room (Jorge Lewis) - Speaker 1 \nWe can improve that with faster models, of course, but we\'re trying to keep, like, ideally, it\'s just not going through a lot of nodes.\n\n40:32 - Conference Room (Jorge Lewis) - Speaker 2 \nWhat about, like, limited loop structures, like the one I created, where it\'s, like, they take part in one part of the loop, then jump to another part of the loop, then jump? Like, if we straight up implemented my whole flowchart as a graph, how would that work?\n\n40:48 - Conference Room (Jorge Lewis) - Speaker 2 \nBecause usually then it\'s only going for like two months at a time.\n\n40:51 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in my experience, what I made with the Python graph, actually, the collector was doing what I... My graph here is actually what was the case before, except the analysis is a little bit different. The collector in my previous one was doing the three logics. So understanding if we have enough info, passing it to the coach or updating the database.\n\n41:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd it was able to do it quite accurately as well. It was like, for example, if I said I walked to cam and then another message later on, I said, Oh, actually I walked an additional eight, then it was able to update it accordingly. Um, I didn\'t do rigorous testing. So, so maybe, but I think to start off, we can start with this. And then if we know if in our testing, we figure out, okay, this, this guy\'s pretty inaccurate when we try to like, test its limits in terms of like making more complicated answers, then we can introduce one. Does that work or do you think otherwise?\n\n41:47 - Chinmay Pandya \nYeah, I think we should try with a simpler model first.\n\n41:53 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so from all of these\n######################\nOutput:'}
02:07:11,358 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,363 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "an extra supervisor.\n\n37:03 - Conference Room (Jorge Lewis) - Speaker 2 \nCould you add the comment on that line instead of just update check-in, just no new relevant info, or just the coach is having a conversation, the collector does nothing.\n\n37:12 - Unidentified Speaker \nYeah, just default, I think.\n\n37:14 - Conference Room (Jorge Lewis) - Speaker 1 \nThe collector does nothing. Yeah, collector does nothing.\n\n37:21 - Chinmay Pandya \nSo whenever the user enters a prompt or check-in, and if the data is not enough, then will the collector add that to the database first or ask more questions?\n\n37:33 - Unidentified Speaker \nSorry, just repeat that.\n\n37:35 - Chinmay Pandya \nIf the user enters something which is not enough, not enough to analyze, like you said, he walked, he just walked around and if the collector wants to know more data before he passes to the analyzer, then will he update the database, the pieces of information he gets when he gets those pieces, or will he update the information once he gets enough pieces?\n\n38:04 - Conference Room (Jorge Lewis) - Speaker 1 \nHe, he has to do it when he gets enough pieces because in the data, this is a, oh, this is the wrong project.\n\n38:12 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah.\n\n38:13 - Conference Room (Jorge Lewis) - Speaker 1 \nUm, so, so in the database, there's columns specifically for the items. So things like, um, the NKM, how far has the user walked? So if the user has given anything other than that, the collector needs the number of kilometers the user has walked. Um, so if the user says I walked around.\n\n38:34 - Conference Room (Jorge Lewis) - Speaker 1 \nI walked around a football pitch three times. The collector could interpret this and say, okay, so, or if the user says something like that, then the collector, if he's very certain that the distance of a football pitch, then he can do it.\n\n38:51 - Unidentified Speaker \nYeah.\n\n38:56 - Chinmay Pandya \nSo if you add a node in between, which has the function to decide whether the information is enough or not. And then when the information is enough, then it will pass to the collector. So the collector won't have to decide additional logic to maintain whether the information is enough or not. Collector can just have two functions, whether call from the database or pass it to the coach.\n\n39:32 - Chinmay Pandya \nRight now, collector has three logics. Call from the database, pass it to the coach, or check whether data is enough or not. So if the data is not enough, we can add another node which decides if the data is enough or not before passing it to the collector.\n\n39:48 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, I see. I think both will work. Your one is kind of more robust. I'm trying to think of any downsides of introducing an extra node in the middle here.\n\n40:09 - Conference Room (Jorge Lewis) - Speaker 2 \nI haven't heard any of the context, but I don't think we should avoid introducing nodes.\n\n40:15 - Conference Room (Jorge Lewis) - Speaker 1 \nThere is actually a problem, though, with speed, with time. Because once we introduce too many nodes, the duration for a response becomes actually unbearable.\n\n40:26 - Conference Room (Jorge Lewis) - Speaker 1 \nWe can improve that with faster models, of course, but we're trying to keep, like, ideally, it's just not going through a lot of nodes.\n\n40:32 - Conference Room (Jorge Lewis) - Speaker 2 \nWhat about, like, limited loop structures, like the one I created, where it's, like, they take part in one part of the loop, then jump to another part of the loop, then jump? Like, if we straight up implemented my whole flowchart as a graph, how would that work?\n\n40:48 - Conference Room (Jorge Lewis) - Speaker 2 \nBecause usually then it's only going for like two months at a time.\n\n40:51 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in my experience, what I made with the Python graph, actually, the collector was doing what I... My graph here is actually what was the case before, except the analysis is a little bit different. The collector in my previous one was doing the three logics. So understanding if we have enough info, passing it to the coach or updating the database.\n\n41:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAnd it was able to do it quite accurately as well. It was like, for example, if I said I walked to cam and then another message later on, I said, Oh, actually I walked an additional eight, then it was able to update it accordingly. Um, I didn't do rigorous testing. So, so maybe, but I think to start off, we can start with this. And then if we know if in our testing, we figure out, okay, this, this guy's pretty inaccurate when we try to like, test its limits in terms of like making more complicated answers, then we can introduce one. Does that work or do you think otherwise?\n\n41:47 - Chinmay Pandya \nYeah, I think we should try with a simpler model first.\n\n41:53 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so from all of these"}
02:07:11,374 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,376 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: this is the today\'s check-in and it returns an array of anything.\n\n51:12 - Conference Room (Jorge Lewis) - Speaker 1 \nOh yeah, there should be single there.\n\n51:15 - Chinmay Pandya \nYeah, I tried adding single, but since I didn\'t know superface that well. Yeah, no, I\'ll go, I\'ll go.\n\n51:21 - Conference Room (Jorge Lewis) - Speaker 1 \nAsk your boss.\n\n51:22 - Unidentified Speaker \nOkay, cool.\n\n51:23 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, there should be a single there, my bad. That was, yeah, pretty cool. Cool.\n\n51:29 - Unidentified Speaker \nSo, I\'ll love you guys.\n\n51:31 - Conference Room (Jorge Lewis) - Speaker 1 \nI\'ll let you guys go through whatever you guys need to go through. And then tomorrow we can regroup.\n\n51:38 - Biwas bhandari \nYeah, can I have this? Let me try this.\n\n51:47 - Conference Room (Jorge Lewis) - Speaker 1 \nHello, hello? You have to set the output.\n\n51:50 - Conference Room (Jorge Lewis) - Speaker 2 \nClick up here. Then you can set the system output. Oh.\n\n51:55 - Unidentified Speaker \nYeah.\n\n51:55 - Biwas bhandari \nYou\'ll be Firefox. Oh.\n\n51:59 - Conference Room (Jorge Lewis) - Speaker 1 \nHello?\n\n52:01 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, you have to turn the volume up a lot. It\'s the same thing for me.\n\n52:04 - Conference Room (Jorge Lewis) - Speaker 1 \nThat is not speaking.\n\n52:07 - Unidentified Speaker \nYeah.\n\n52:07 - Conference Room (Jorge Lewis) - Speaker 1 \nCan you guys speak? Yeah, it\'s working. Oh, there. Okay. I was checking on the graph.\n\n52:14 - Conference Room (Jorge Lewis) - Speaker 2 \nSo one thing I wanted to ask is, are you guys going to be peer programming, or how is this going to be organized?\n\n52:23 - Conference Room (Jorge Lewis) - Speaker 1 \nFor me, what I think is best, I\'ve never tried, I don\'t have experience with it, but just hypothesis is that maybe like a combination, maybe 40% peer programming and then solo. And that way, the peer programming is a mix of staying aligned, but also learning from each other.\n\n52:42 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, so when you guys are getting on, probably message each other that you\'re online, and if both people are online at the same time, try to get in the call as fast as possible, sync up on everything, just get used to working in a team. And if you feel it\'s appropriate, start a pair programming sessions. I can say from experience that pair programming is one of the best ways to learn how to program and how to run a project ever.\n\n53:11 - Chinmay Pandya \nCool, cool, cool.\n\n53:15 - Unidentified Speaker \nAlright, sounds good.\n\n53:18 - Conference Room (Jorge Lewis) - Speaker 1 \nSo I\'ll see you guys tomorrow then.\n\n53:22 - Unidentified Speaker \nLet me know if you guys have any questions.\n\n53:26 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, thanks so much for your guys\' time. It\'s been a bit of a long night, but yeah, enjoyed it. I had fun meeting you guys.\n\n53:36 - Biwas bhandari \nOkay bye bye, have a good night.\n\n53:38 - Biwas bhandari \nWhat time do you work? During the day, from 2 to 11 am. At night, I work more. Around 1 am.\n\n53:42 - Chinmay Pandya \nYou work more at night? I sleep at 1 am. My work is in the morning and afternoon.\n\n53:48 - Biwas bhandari \nYours is in the afternoon and night.\n\n54:05 - Chinmay Pandya \nSo do you live at 2pm? At night or in the afternoon?\n\n54:08 - Biwas bhandari \nNo, no, in the afternoon. Yeah, yeah. From 2 to 5 in the afternoon.\n\n54:13 - Chinmay Pandya \nYeah, okay.\n\n54:13 - Biwas bhandari \nOkay, so I live at that time as well.\n\n54:18 - Chinmay Pandya \nI mean, I live from 9 to 1 in the morning and from 2 to 5 in the afternoon. So, I\'ll see you from 2 5 afternoon. You can come online then. We can collaborate. Okay, okay.\n\n54:28 - Chinmay Pandya \nOkay, bro.\n\n55:12 - Chinmay Pandya \nWhen did you start working on Lightning?\n\n55:15 - Biwas bhandari \nFirst I worked on it twice, using TypeScript. Then I switched to Python. And made 2-3 projects.\n\n55:25 - Biwas bhandari \nAnd that guy messaged.\n\n55:27 - Biwas bhandari \nDid you do any internship work? Not internship, I did both remote work. They were from Nepal, but they stayed in San Francisco. America.\n\n55:41 - Biwas bhandari \nThey gave me the job.\n\n55:43 - Biwas bhandari \nSo, I\n######################\nOutput:'}
02:07:11,376 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,378 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "this is the today's check-in and it returns an array of anything.\n\n51:12 - Conference Room (Jorge Lewis) - Speaker 1 \nOh yeah, there should be single there.\n\n51:15 - Chinmay Pandya \nYeah, I tried adding single, but since I didn't know superface that well. Yeah, no, I'll go, I'll go.\n\n51:21 - Conference Room (Jorge Lewis) - Speaker 1 \nAsk your boss.\n\n51:22 - Unidentified Speaker \nOkay, cool.\n\n51:23 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, there should be a single there, my bad. That was, yeah, pretty cool. Cool.\n\n51:29 - Unidentified Speaker \nSo, I'll love you guys.\n\n51:31 - Conference Room (Jorge Lewis) - Speaker 1 \nI'll let you guys go through whatever you guys need to go through. And then tomorrow we can regroup.\n\n51:38 - Biwas bhandari \nYeah, can I have this? Let me try this.\n\n51:47 - Conference Room (Jorge Lewis) - Speaker 1 \nHello, hello? You have to set the output.\n\n51:50 - Conference Room (Jorge Lewis) - Speaker 2 \nClick up here. Then you can set the system output. Oh.\n\n51:55 - Unidentified Speaker \nYeah.\n\n51:55 - Biwas bhandari \nYou'll be Firefox. Oh.\n\n51:59 - Conference Room (Jorge Lewis) - Speaker 1 \nHello?\n\n52:01 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, you have to turn the volume up a lot. It's the same thing for me.\n\n52:04 - Conference Room (Jorge Lewis) - Speaker 1 \nThat is not speaking.\n\n52:07 - Unidentified Speaker \nYeah.\n\n52:07 - Conference Room (Jorge Lewis) - Speaker 1 \nCan you guys speak? Yeah, it's working. Oh, there. Okay. I was checking on the graph.\n\n52:14 - Conference Room (Jorge Lewis) - Speaker 2 \nSo one thing I wanted to ask is, are you guys going to be peer programming, or how is this going to be organized?\n\n52:23 - Conference Room (Jorge Lewis) - Speaker 1 \nFor me, what I think is best, I've never tried, I don't have experience with it, but just hypothesis is that maybe like a combination, maybe 40% peer programming and then solo. And that way, the peer programming is a mix of staying aligned, but also learning from each other.\n\n52:42 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, so when you guys are getting on, probably message each other that you're online, and if both people are online at the same time, try to get in the call as fast as possible, sync up on everything, just get used to working in a team. And if you feel it's appropriate, start a pair programming sessions. I can say from experience that pair programming is one of the best ways to learn how to program and how to run a project ever.\n\n53:11 - Chinmay Pandya \nCool, cool, cool.\n\n53:15 - Unidentified Speaker \nAlright, sounds good.\n\n53:18 - Conference Room (Jorge Lewis) - Speaker 1 \nSo I'll see you guys tomorrow then.\n\n53:22 - Unidentified Speaker \nLet me know if you guys have any questions.\n\n53:26 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, thanks so much for your guys' time. It's been a bit of a long night, but yeah, enjoyed it. I had fun meeting you guys.\n\n53:36 - Biwas bhandari \nOkay bye bye, have a good night.\n\n53:38 - Biwas bhandari \nWhat time do you work? During the day, from 2 to 11 am. At night, I work more. Around 1 am.\n\n53:42 - Chinmay Pandya \nYou work more at night? I sleep at 1 am. My work is in the morning and afternoon.\n\n53:48 - Biwas bhandari \nYours is in the afternoon and night.\n\n54:05 - Chinmay Pandya \nSo do you live at 2pm? At night or in the afternoon?\n\n54:08 - Biwas bhandari \nNo, no, in the afternoon. Yeah, yeah. From 2 to 5 in the afternoon.\n\n54:13 - Chinmay Pandya \nYeah, okay.\n\n54:13 - Biwas bhandari \nOkay, so I live at that time as well.\n\n54:18 - Chinmay Pandya \nI mean, I live from 9 to 1 in the morning and from 2 to 5 in the afternoon. So, I'll see you from 2 5 afternoon. You can come online then. We can collaborate. Okay, okay.\n\n54:28 - Chinmay Pandya \nOkay, bro.\n\n55:12 - Chinmay Pandya \nWhen did you start working on Lightning?\n\n55:15 - Biwas bhandari \nFirst I worked on it twice, using TypeScript. Then I switched to Python. And made 2-3 projects.\n\n55:25 - Biwas bhandari \nAnd that guy messaged.\n\n55:27 - Biwas bhandari \nDid you do any internship work? Not internship, I did both remote work. They were from Nepal, but they stayed in San Francisco. America.\n\n55:41 - Biwas bhandari \nThey gave me the job.\n\n55:43 - Biwas bhandari \nSo, I"}
02:07:11,385 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,386 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: . Then I switched to Python. And made 2-3 projects.\n\n55:25 - Biwas bhandari \nAnd that guy messaged.\n\n55:27 - Biwas bhandari \nDid you do any internship work? Not internship, I did both remote work. They were from Nepal, but they stayed in San Francisco. America.\n\n55:41 - Biwas bhandari \nThey gave me the job.\n\n55:43 - Biwas bhandari \nSo, I did it.\n\n55:45 - Biwas bhandari \nLang Graph.\n\n55:46 - Biwas bhandari \nI haven\'t used it much. I\'ve only used it in LangChain. Agent. Banana. Router. That\'s it. First time using Lang Graph.\n\n55:56 - Unidentified Speaker \nBut it\'s good. Yeah.\n\n56:00 - Chinmay Pandya \nWe\'ll figure it out.\n\n56:01 - Chinmay Pandya \nThere\'s no new code.\n\n56:03 - Chinmay Pandya \nIt\'s just LangChain. But the graph and nodes are different.\n\n56:10 - Chinmay Pandya \nok bro, let\'s meet tomorrow ok, today I am working on the collector now my quota is over so I will start again tomorrow morning if there is any quota, I will do it ok, I will try to figure out the collectors do you have the documentation link?\n\n56:38 - Biwas bhandari \nLangchan\'s Superverse I haven\'t used. I was only using MongoDB and MySQL. I\'ll send you a link.\n\n56:50 - Chinmay Pandya \nI\'ll send you the documentation link in the Discord chat.\n\n56:56 - Chinmay Pandya \nOkay. Let me know if you have any extra resources.\n\n57:00 - Biwas bhandari \nYeah.\n\n57:13 - Chinmay Pandya \nWhere did it go?\n\n57:23 - Biwas bhandari \nI sent it.\n\n57:24 - Chinmay Pandya \nThis was just a multi-agent. I was also looking at this.\n\n57:29 - Biwas bhandari \nBut it has a router.\n\n57:30 - Chinmay Pandya \nIt doesn\'t need a router. It has a supervisor in the code too.\n\n57:43 - Biwas bhandari \nusing supervisor, he was also using multi-agent collaboration using supervisor, he was using multi-agent collaboration actually in multi-agent, router is better we\'ll have to see I\'ll do it tonight, if there\'s any error I\'ll inform you, you can check it in\n\n58:05 - Chinmay Pandya \nthe morning If you figure out something or work on it, let me know. I\'m sleeping, when I wake up, you go offline, I\'ll see.\n\n58:27 - Biwas bhandari \nOkay, bye bye, have a good night.\n######################\nOutput:'}
02:07:11,386 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,389 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ". Then I switched to Python. And made 2-3 projects.\n\n55:25 - Biwas bhandari \nAnd that guy messaged.\n\n55:27 - Biwas bhandari \nDid you do any internship work? Not internship, I did both remote work. They were from Nepal, but they stayed in San Francisco. America.\n\n55:41 - Biwas bhandari \nThey gave me the job.\n\n55:43 - Biwas bhandari \nSo, I did it.\n\n55:45 - Biwas bhandari \nLang Graph.\n\n55:46 - Biwas bhandari \nI haven't used it much. I've only used it in LangChain. Agent. Banana. Router. That's it. First time using Lang Graph.\n\n55:56 - Unidentified Speaker \nBut it's good. Yeah.\n\n56:00 - Chinmay Pandya \nWe'll figure it out.\n\n56:01 - Chinmay Pandya \nThere's no new code.\n\n56:03 - Chinmay Pandya \nIt's just LangChain. But the graph and nodes are different.\n\n56:10 - Chinmay Pandya \nok bro, let's meet tomorrow ok, today I am working on the collector now my quota is over so I will start again tomorrow morning if there is any quota, I will do it ok, I will try to figure out the collectors do you have the documentation link?\n\n56:38 - Biwas bhandari \nLangchan's Superverse I haven't used. I was only using MongoDB and MySQL. I'll send you a link.\n\n56:50 - Chinmay Pandya \nI'll send you the documentation link in the Discord chat.\n\n56:56 - Chinmay Pandya \nOkay. Let me know if you have any extra resources.\n\n57:00 - Biwas bhandari \nYeah.\n\n57:13 - Chinmay Pandya \nWhere did it go?\n\n57:23 - Biwas bhandari \nI sent it.\n\n57:24 - Chinmay Pandya \nThis was just a multi-agent. I was also looking at this.\n\n57:29 - Biwas bhandari \nBut it has a router.\n\n57:30 - Chinmay Pandya \nIt doesn't need a router. It has a supervisor in the code too.\n\n57:43 - Biwas bhandari \nusing supervisor, he was also using multi-agent collaboration using supervisor, he was using multi-agent collaboration actually in multi-agent, router is better we'll have to see I'll do it tonight, if there's any error I'll inform you, you can check it in\n\n58:05 - Chinmay Pandya \nthe morning If you figure out something or work on it, let me know. I'm sleeping, when I wake up, you go offline, I'll see.\n\n58:27 - Biwas bhandari \nOkay, bye bye, have a good night."}
02:07:11,427 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,429 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: plan then, I\'ll leave Chinmay and D.Wes to discuss what you guys are going to try to do. Jonas is going to continue on the messages thing. I won\'t be on the project right now. I\'ll let you guys work.\n\n46:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAre you guys both on tomorrow?\n\n46:18 - Unidentified Speaker \nYeah, yep.\n\n46:21 - Unidentified Speaker \nOkay, cool.\n\n46:22 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so I think tomorrow, sometime around midday, we can check in all together and see how things are going and how we can delegate a little bit better.\n\n46:29 - Chinmay Pandya \nAlso, there\'s some issue with the check-in, the database check-in.\n\n46:39 - Biwas bhandari \nWhat\'s wrong with it?\n\n46:41 - Chinmay Pandya \nLike we have three check-ins, an update check-in, a create check-in, and get today\'s check-in, right?\n\n46:54 - Chinmay Pandya \nHello.\n\n46:55 - Unidentified Speaker \nYeah. Yeah.\n\n46:56 - Chinmay Pandya \nSo, uh, the code as it was written for create check-in, it will always, it should return the latest inserted node or the data, but it always returns the data as null.\n\n47:18 - Unidentified Speaker \nI see. So is that.\n\n47:21 - Chinmay Pandya \nNo, wait. I\'ll present my screen and show you.\n\n47:34 - Chinmay Pandya \nYeah.\n\n47:35 - Chinmay Pandya \nSo here.\n\n47:37 - Chinmay Pandya \nYou see this?\n\n47:39 - Unidentified Speaker \nYeah.\n\n47:40 - Chinmay Pandya \nThis is always not.\n\n47:44 - Chinmay Pandya \nYeah, so whenever you\'re trying to create a check-in, it will not return you the latest check-in which was created. And that\'s why the data is always null. And in the case of error, we pass in an object where data is null and error. So here, this was the original code.\n\n48:04 - Unidentified Speaker \nYeah.\n\n48:10 - Chinmay Pandya \nSo here we try to return something, but this will always be null. So this, it was causing error here. I think there\'s a problem with this function, this create function, which should be the latest inserted.\n\n48:24 - Conference Room (Jorge Lewis) - Speaker 1 \nDo you have experience with Superbase?\n\n48:31 - Chinmay Pandya \nI do not have with Superbase. But what I tried to do here is, because it was not inserting, I just ran the code to, for it to insert, then I called the two days check and it will fetch the most recent again.\n\n48:46 - Conference Room (Jorge Lewis) - Speaker 1 \nI\'ll send you, let me send you the documentation for superbase SDK. It\'s very simple. You\'ve worked with Postgres databases before, right? Yeah. Postgres, right?\n\n48:54 - Unidentified Speaker \nYeah.\n\n48:55 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so you should have no trouble understanding it, and then it\'s just a matter of looking at the documentation reference.\n\n49:01 - Unidentified Speaker \nOkay, yeah.\n\n49:02 - Chinmay Pandya \nAlso when you when you call get today\'s check-in, do you want only one single item to return or Don\'t just send link to one of them.\n\n49:11 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, that\'s the wrong one sends link to super base slash SSR Sorry, I didn\'t get Is it different yeah, it\'s slightly different I\'m talking about like just the basic API calls. Yeah, you were looking at the wrong ones. Like just these ones. Yeah, I just sent a link to one of them. It\'s not SuperBase.js we\'re using, even though that\'s the one that\'s still listed there. They\'re phasing it out and replacing it with SuperBase SSR. But the only difference between SuperBase.js and SuperBase SSR is how you create the client, not how you use the client. So just how a client is created and how authentication is performed is different. But how you make normal API calls, that\'s the same thing.\n\n50:20 - Unidentified Speaker \nOkay.\n\n50:21 - Chinmay Pandya \nBut the goal of the today\'s check-in function is to fetch one check-in or multiple check-ins?\n\n50:32 - Conference Room (Jorge Lewis) - Speaker 1 \nOne check-in. So, so every day there\'s one check-in object. And the idea is that every day the user checks in. So there\'s a new one that created every day for every user. Yeah.\n\n50:42 - Chinmay Pandya \nBecause the current code fetches multiple check-ins.\n\n50:48 - Conference Room (Jorge Lewis) - Speaker 1 \nNo, I think it does single.\n\n51:05 - Chinmay Pandya \nSo this is the today\'s check-in and it returns an array of anything.\n\n51:12 - Conference Room (Jorge Lewis) - Speaker 1 \nOh yeah, there should be single there.\n\n51:15 - Chinmay Pandya \nYeah, I tried adding single, but since I didn\'t know superface that well. Yeah, no, I\'ll go, I\'ll go.\n\n51:21 - Conference Room (Jorge Lewis) - Speaker 1 \nAsk your boss.\n\n51\n######################\nOutput:'}
02:07:11,430 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,432 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "plan then, I'll leave Chinmay and D.Wes to discuss what you guys are going to try to do. Jonas is going to continue on the messages thing. I won't be on the project right now. I'll let you guys work.\n\n46:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAre you guys both on tomorrow?\n\n46:18 - Unidentified Speaker \nYeah, yep.\n\n46:21 - Unidentified Speaker \nOkay, cool.\n\n46:22 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so I think tomorrow, sometime around midday, we can check in all together and see how things are going and how we can delegate a little bit better.\n\n46:29 - Chinmay Pandya \nAlso, there's some issue with the check-in, the database check-in.\n\n46:39 - Biwas bhandari \nWhat's wrong with it?\n\n46:41 - Chinmay Pandya \nLike we have three check-ins, an update check-in, a create check-in, and get today's check-in, right?\n\n46:54 - Chinmay Pandya \nHello.\n\n46:55 - Unidentified Speaker \nYeah. Yeah.\n\n46:56 - Chinmay Pandya \nSo, uh, the code as it was written for create check-in, it will always, it should return the latest inserted node or the data, but it always returns the data as null.\n\n47:18 - Unidentified Speaker \nI see. So is that.\n\n47:21 - Chinmay Pandya \nNo, wait. I'll present my screen and show you.\n\n47:34 - Chinmay Pandya \nYeah.\n\n47:35 - Chinmay Pandya \nSo here.\n\n47:37 - Chinmay Pandya \nYou see this?\n\n47:39 - Unidentified Speaker \nYeah.\n\n47:40 - Chinmay Pandya \nThis is always not.\n\n47:44 - Chinmay Pandya \nYeah, so whenever you're trying to create a check-in, it will not return you the latest check-in which was created. And that's why the data is always null. And in the case of error, we pass in an object where data is null and error. So here, this was the original code.\n\n48:04 - Unidentified Speaker \nYeah.\n\n48:10 - Chinmay Pandya \nSo here we try to return something, but this will always be null. So this, it was causing error here. I think there's a problem with this function, this create function, which should be the latest inserted.\n\n48:24 - Conference Room (Jorge Lewis) - Speaker 1 \nDo you have experience with Superbase?\n\n48:31 - Chinmay Pandya \nI do not have with Superbase. But what I tried to do here is, because it was not inserting, I just ran the code to, for it to insert, then I called the two days check and it will fetch the most recent again.\n\n48:46 - Conference Room (Jorge Lewis) - Speaker 1 \nI'll send you, let me send you the documentation for superbase SDK. It's very simple. You've worked with Postgres databases before, right? Yeah. Postgres, right?\n\n48:54 - Unidentified Speaker \nYeah.\n\n48:55 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so you should have no trouble understanding it, and then it's just a matter of looking at the documentation reference.\n\n49:01 - Unidentified Speaker \nOkay, yeah.\n\n49:02 - Chinmay Pandya \nAlso when you when you call get today's check-in, do you want only one single item to return or Don't just send link to one of them.\n\n49:11 - Conference Room (Jorge Lewis) - Speaker 2 \nYeah, that's the wrong one sends link to super base slash SSR Sorry, I didn't get Is it different yeah, it's slightly different I'm talking about like just the basic API calls. Yeah, you were looking at the wrong ones. Like just these ones. Yeah, I just sent a link to one of them. It's not SuperBase.js we're using, even though that's the one that's still listed there. They're phasing it out and replacing it with SuperBase SSR. But the only difference between SuperBase.js and SuperBase SSR is how you create the client, not how you use the client. So just how a client is created and how authentication is performed is different. But how you make normal API calls, that's the same thing.\n\n50:20 - Unidentified Speaker \nOkay.\n\n50:21 - Chinmay Pandya \nBut the goal of the today's check-in function is to fetch one check-in or multiple check-ins?\n\n50:32 - Conference Room (Jorge Lewis) - Speaker 1 \nOne check-in. So, so every day there's one check-in object. And the idea is that every day the user checks in. So there's a new one that created every day for every user. Yeah.\n\n50:42 - Chinmay Pandya \nBecause the current code fetches multiple check-ins.\n\n50:48 - Conference Room (Jorge Lewis) - Speaker 1 \nNo, I think it does single.\n\n51:05 - Chinmay Pandya \nSo this is the today's check-in and it returns an array of anything.\n\n51:12 - Conference Room (Jorge Lewis) - Speaker 1 \nOh yeah, there should be single there.\n\n51:15 - Chinmay Pandya \nYeah, I tried adding single, but since I didn't know superface that well. Yeah, no, I'll go, I'll go.\n\n51:21 - Conference Room (Jorge Lewis) - Speaker 1 \nAsk your boss.\n\n51"}
02:07:11,463 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,464 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Biwas / Jorge - Pair Programming \nTue, Aug 6, 2024\n\n0:01 - Biwas bhandari \nI want to be able to see your web environment on the screen.\n\n0:30 - Biwas bhandari \nCan you see everything? I think I can see now. Yeah, yeah, yeah. Okay, so...\n\n0:44 - Jorge Lewis \nYeah, I think that\'s it.\n\n0:59 - Jorge Lewis \nSo let me just run the app at first.\n\n1:46 - Biwas bhandari \nYeah.\n\n2:03 - Biwas bhandari \nNice, nice.\n\n2:05 - Biwas bhandari \nSo these are the posts that I\'ve made, yeah, that I\'ve faced. And this probably is not in this.\n\n2:18 - Jorge Lewis \nAll right, so I\'m following you now.\n\n2:25 - Jorge Lewis \nOK.\n\n2:34 - Biwas bhandari \nok yeah this is pretty much so let me first explain the code to you and this one is for authentication and the red is for recreating server field and password and this one is for fetching code which inputs plus and filtering it. For example, if the same Read.AI ID and title is in the repository, then it will not pass it to the evaluator of the relevant data.\n\n3:16 - Jorge Lewis \nYes. Can you try improving your mic? It\'s very tough to hear you. Do you not have any other headset at home?\n\n3:22 - Biwas bhandari \nLet me change it.\n\n3:28 - Jorge Lewis \nMaybe if you hold it to your mouse, it\'ll be better. I don\'t know.\n\n3:37 - Jorge Lewis \nCan you hear me now better?\n\n3:38 - Jorge Lewis \nYeah, now it\'s much better. I can hear you clearly.\n\n3:41 - Biwas bhandari \nOh.\n\n3:44 - Biwas bhandari \nYeah, that\'s it. And for the prompts, I\'m just passing the context from here.\n\n3:54 - Jorge Lewis \nYou can see.\n\n3:55 - Jorge Lewis \nYeah, OK.\n\n4:00 - Biwas bhandari \nThis one I just copied from the Python code.\n\n4:09 - Biwas bhandari \nSo...\n\n4:22 - Jorge Lewis \nOkay, so what you were working on was trying to add a button, right?\n\n4:27 - Biwas bhandari \nYeah. So I want to call, this one is the function that calls all the, at first it calls the, it fetches the post and it evaluates it and then tests it in the database. So this is the main function.\n\n4:44 - Jorge Lewis \nSo, okay, I see. So that function, by the way, should be called, it should be more than process posts. It\'s also fetching them. That name could be pretty misleading. If I see that function when I\'m calling it, it\'s not very clear that it\'s processing. I would imagine since the file that it\'s in, for example, is in evaluation, I would think that it\'s not very, it\'s not fetching the post, but it is.\n\n5:30 - Jorge Lewis \nOkay, so there\'s one concept of a spell kit and that\'s the server files which is, so okay, So we\'re not going to be able to do a lot of, it\'s not going to be very helpful if we do SvelteKit stuff right now because the most efficient way to do this is for you to go through the tutorials, the SvelteKit tutorials, which are great. And then once you do those tutorials, then we can do some programming because There\'s a very basic, well sorry not basic, but there\'s just an introductory concept where you have server files and then you have page files.\n\n6:33 - Biwas bhandari \nYeah, I know, I have read about it, I cannot import the server function in the content, so I think I basically need to create a route.\n\n6:45 - Jorge Lewis \nYeah, yeah, exactly. But this is actually not a server function. Server functions should be inside the server folder there in lib slash server. Yeah. So you can, you can just move your file folders.\n\n7:02 - Biwas bhandari \nI had to do that. First of all, I need to move all my folders inside.\n\n7:14 - Jorge Lewis \nAll right.\n\n7:16 - Jorge Lewis \nYeah, I mean, if they run on the server, you probably want them, well, yeah, they need to be in the folder.\n\n7:25 - Biwas bhandari \nOkay.\n\n8:19 - Jorge Lewis \nBye.\n\n8:42 - Biwas bhandari \nI should have found one.\n\n9:13 - Biwas bhandari \nthe Okay.\n\n11:06 - Biwas bhandari \nNow that insight is over.\n\n11:33 - Jorge Lewis \nHave you done the tutorial?\n\n11:37 - Biwas bhandari \nWas it failed yet?\n\n11:40 - Unidentified Speaker \nYeah.\n\n11:42 - Biwas bhandari \nNo. No.\n\n11:50 - Biwas bhandari \nHmm.\n\n12:08 - Biwas bhandari \nOkay.\n\n12:32 - Jorge Lewis \nBye.\n\n12:55 - Biwas bhandari \nOkay Your your gather characters out of the office just sitting but just standing there okay yeah so So there are a couple of things I need to include here in the content.\n\n13:59 - Biwas bhandari \nPeople.\n\n14:32 - Jorge Lewis \nOh, you haven\'t pulled. Oh no, bro\n######################\nOutput:'}
02:07:11,464 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,467 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Biwas / Jorge - Pair Programming \nTue, Aug 6, 2024\n\n0:01 - Biwas bhandari \nI want to be able to see your web environment on the screen.\n\n0:30 - Biwas bhandari \nCan you see everything? I think I can see now. Yeah, yeah, yeah. Okay, so...\n\n0:44 - Jorge Lewis \nYeah, I think that's it.\n\n0:59 - Jorge Lewis \nSo let me just run the app at first.\n\n1:46 - Biwas bhandari \nYeah.\n\n2:03 - Biwas bhandari \nNice, nice.\n\n2:05 - Biwas bhandari \nSo these are the posts that I've made, yeah, that I've faced. And this probably is not in this.\n\n2:18 - Jorge Lewis \nAll right, so I'm following you now.\n\n2:25 - Jorge Lewis \nOK.\n\n2:34 - Biwas bhandari \nok yeah this is pretty much so let me first explain the code to you and this one is for authentication and the red is for recreating server field and password and this one is for fetching code which inputs plus and filtering it. For example, if the same Read.AI ID and title is in the repository, then it will not pass it to the evaluator of the relevant data.\n\n3:16 - Jorge Lewis \nYes. Can you try improving your mic? It's very tough to hear you. Do you not have any other headset at home?\n\n3:22 - Biwas bhandari \nLet me change it.\n\n3:28 - Jorge Lewis \nMaybe if you hold it to your mouse, it'll be better. I don't know.\n\n3:37 - Jorge Lewis \nCan you hear me now better?\n\n3:38 - Jorge Lewis \nYeah, now it's much better. I can hear you clearly.\n\n3:41 - Biwas bhandari \nOh.\n\n3:44 - Biwas bhandari \nYeah, that's it. And for the prompts, I'm just passing the context from here.\n\n3:54 - Jorge Lewis \nYou can see.\n\n3:55 - Jorge Lewis \nYeah, OK.\n\n4:00 - Biwas bhandari \nThis one I just copied from the Python code.\n\n4:09 - Biwas bhandari \nSo...\n\n4:22 - Jorge Lewis \nOkay, so what you were working on was trying to add a button, right?\n\n4:27 - Biwas bhandari \nYeah. So I want to call, this one is the function that calls all the, at first it calls the, it fetches the post and it evaluates it and then tests it in the database. So this is the main function.\n\n4:44 - Jorge Lewis \nSo, okay, I see. So that function, by the way, should be called, it should be more than process posts. It's also fetching them. That name could be pretty misleading. If I see that function when I'm calling it, it's not very clear that it's processing. I would imagine since the file that it's in, for example, is in evaluation, I would think that it's not very, it's not fetching the post, but it is.\n\n5:30 - Jorge Lewis \nOkay, so there's one concept of a spell kit and that's the server files which is, so okay, So we're not going to be able to do a lot of, it's not going to be very helpful if we do SvelteKit stuff right now because the most efficient way to do this is for you to go through the tutorials, the SvelteKit tutorials, which are great. And then once you do those tutorials, then we can do some programming because There's a very basic, well sorry not basic, but there's just an introductory concept where you have server files and then you have page files.\n\n6:33 - Biwas bhandari \nYeah, I know, I have read about it, I cannot import the server function in the content, so I think I basically need to create a route.\n\n6:45 - Jorge Lewis \nYeah, yeah, exactly. But this is actually not a server function. Server functions should be inside the server folder there in lib slash server. Yeah. So you can, you can just move your file folders.\n\n7:02 - Biwas bhandari \nI had to do that. First of all, I need to move all my folders inside.\n\n7:14 - Jorge Lewis \nAll right.\n\n7:16 - Jorge Lewis \nYeah, I mean, if they run on the server, you probably want them, well, yeah, they need to be in the folder.\n\n7:25 - Biwas bhandari \nOkay.\n\n8:19 - Jorge Lewis \nBye.\n\n8:42 - Biwas bhandari \nI should have found one.\n\n9:13 - Biwas bhandari \nthe Okay.\n\n11:06 - Biwas bhandari \nNow that insight is over.\n\n11:33 - Jorge Lewis \nHave you done the tutorial?\n\n11:37 - Biwas bhandari \nWas it failed yet?\n\n11:40 - Unidentified Speaker \nYeah.\n\n11:42 - Biwas bhandari \nNo. No.\n\n11:50 - Biwas bhandari \nHmm.\n\n12:08 - Biwas bhandari \nOkay.\n\n12:32 - Jorge Lewis \nBye.\n\n12:55 - Biwas bhandari \nOkay Your your gather characters out of the office just sitting but just standing there okay yeah so So there are a couple of things I need to include here in the content.\n\n13:59 - Biwas bhandari \nPeople.\n\n14:32 - Jorge Lewis \nOh, you haven't pulled. Oh no, bro"}
02:07:11,478 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,479 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: then if we know if in our testing, we figure out, okay, this, this guy\'s pretty inaccurate when we try to like, test its limits in terms of like making more complicated answers, then we can introduce one. Does that work or do you think otherwise?\n\n41:47 - Chinmay Pandya \nYeah, I think we should try with a simpler model first.\n\n41:53 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so from all of these, what can we take from all of them? Which one do we like best?\n\n42:00 - Conference Room (Jorge Lewis) - Speaker 1 \nWell, not Jonas\'s, sorry, your one said a useful diagram, but not a graph, not the line graph.\n\n42:06 - Unidentified Speaker \nWe\'ll need to save this.\n\n42:11 - Unidentified Speaker \nBro, the text is too small.\n\n42:14 - Conference Room (Jorge Lewis) - Speaker 1 \nI\'ll save it later. So which one do you like best?\n\n42:24 - Chinmay Pandya \nMine has four nodes, and yours has three. So right now, I would like to test with three nodes, if it works.\n\n42:38 - Conference Room (Jorge Lewis) - Speaker 1 \nThese two are just, yeah, these are the same, right?\n\n42:42 - Conference Room (Jorge Lewis) - Speaker 2 \nExcept the line that goes between the coach and collector, but I don\'t- I don\'t think that\'s really relevant. Yeah, because both of them have a router, I don\'t think. BWAS.\n\n42:51 - Unidentified Speaker \nYeah, they\'re the same.\n\n42:54 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so BWAS, what do you think of this one, starting with this one then?\n\n43:18 - Biwas bhandari \nI work 10 kilometers and today I work 20 kilometers.\n\n43:22 - Unidentified Speaker \nYeah, yeah.\n\n43:24 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, one thing we need to consider is are things like when the user does things like that when he says 2 KM and then 5 KM like we need to make sure we have a system where it updates the database accurately because for example it might try to do it might update the database first with 2 KM and then it does another call with 5 KM but really it should be doing the second calls should be for 7\n\n43:50 - Chinmay Pandya \nso we need to make sure that\'s that\'s in place the database updated before every preceding check-in sorry like if the user checks in another five kilometers like you said if he checks in with another five kilometers so if we have the two kilometers updated and we can calculate that the entire day he already had two kilometers and then he went out and did five again yeah there\'s there\'s two options like one of them is just trust that the\n\n44:22 - Conference Room (Jorge Lewis) - Speaker 1 \nllm will see the conversation history, which in the past, through my experimentation, it was able to do that. It never failed. But the other option is to every database update is the sum. So it just adds them together. I think letting the LLM decide is better, because if it\'s the sum, we\'re relying a lot more on conditional, like hard-coded things than the LLM. The LLM will just know, OK, no info, let\'s update it.\n\n44:51 - Chinmay Pandya \nWe just need to tell LLM to recognize all of the activities of today. So he\'ll sum it up himself. Yeah.\n\n45:00 - Conference Room (Jorge Lewis) - Speaker 1 \nMaybe, maybe later down the road, if we noticed the, the collector is, is it sucks at trying to figure out like multiple data points and adding them together, we can make a small little graph down here to help add an extra LLM saying summarize or like extract the, the data points for this in this category.\n\n45:21 - Unidentified Speaker \nSomething like that.\n\n45:22 - Conference Room (Jorge Lewis) - Speaker 1 \nIt\'s the thing about the nice thing.\n\n45:24 - Unidentified Speaker \nSorry.\n\n45:25 - Chinmay Pandya \nI was thinking of a fourth node because if the collector has too many responsibilities, it might not work.\n\n45:32 - Unidentified Speaker \nYeah.\n\n45:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo, so we\'ll have to test around. Um, that\'s a nice thing about this graphs. It\'s really easy to test. You just change the prompts and add some edges. Yeah.\n\n45:40 - Chinmay Pandya \nWe just have to add a node and we have to just transfer the tools.\n\n45:46 - Unidentified Speaker \nYeah.\n\n45:46 - Chinmay Pandya \nWe have to transfer from coach, from collector to the support. Yeah.\n\n45:52 - Unidentified Speaker \nOkay, cool.\n\n45:54 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in terms of the plan then, I\'ll leave Chinmay and D.Wes to discuss what you guys are going to try to do. Jonas is going to continue on the messages thing. I won\'t be on the project right now. I\'ll let you guys work.\n\n46:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAre you guys both on tomorrow?\n\n46:18 - Unidentified Speaker \nYeah, yep.\n\n46:21 - Unidentified Speaker \nOkay, cool.\n\n46\n######################\nOutput:'}
02:07:11,480 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,482 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "then if we know if in our testing, we figure out, okay, this, this guy's pretty inaccurate when we try to like, test its limits in terms of like making more complicated answers, then we can introduce one. Does that work or do you think otherwise?\n\n41:47 - Chinmay Pandya \nYeah, I think we should try with a simpler model first.\n\n41:53 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so from all of these, what can we take from all of them? Which one do we like best?\n\n42:00 - Conference Room (Jorge Lewis) - Speaker 1 \nWell, not Jonas's, sorry, your one said a useful diagram, but not a graph, not the line graph.\n\n42:06 - Unidentified Speaker \nWe'll need to save this.\n\n42:11 - Unidentified Speaker \nBro, the text is too small.\n\n42:14 - Conference Room (Jorge Lewis) - Speaker 1 \nI'll save it later. So which one do you like best?\n\n42:24 - Chinmay Pandya \nMine has four nodes, and yours has three. So right now, I would like to test with three nodes, if it works.\n\n42:38 - Conference Room (Jorge Lewis) - Speaker 1 \nThese two are just, yeah, these are the same, right?\n\n42:42 - Conference Room (Jorge Lewis) - Speaker 2 \nExcept the line that goes between the coach and collector, but I don't- I don't think that's really relevant. Yeah, because both of them have a router, I don't think. BWAS.\n\n42:51 - Unidentified Speaker \nYeah, they're the same.\n\n42:54 - Conference Room (Jorge Lewis) - Speaker 1 \nOkay, so BWAS, what do you think of this one, starting with this one then?\n\n43:18 - Biwas bhandari \nI work 10 kilometers and today I work 20 kilometers.\n\n43:22 - Unidentified Speaker \nYeah, yeah.\n\n43:24 - Conference Room (Jorge Lewis) - Speaker 1 \nYeah, one thing we need to consider is are things like when the user does things like that when he says 2 KM and then 5 KM like we need to make sure we have a system where it updates the database accurately because for example it might try to do it might update the database first with 2 KM and then it does another call with 5 KM but really it should be doing the second calls should be for 7\n\n43:50 - Chinmay Pandya \nso we need to make sure that's that's in place the database updated before every preceding check-in sorry like if the user checks in another five kilometers like you said if he checks in with another five kilometers so if we have the two kilometers updated and we can calculate that the entire day he already had two kilometers and then he went out and did five again yeah there's there's two options like one of them is just trust that the\n\n44:22 - Conference Room (Jorge Lewis) - Speaker 1 \nllm will see the conversation history, which in the past, through my experimentation, it was able to do that. It never failed. But the other option is to every database update is the sum. So it just adds them together. I think letting the LLM decide is better, because if it's the sum, we're relying a lot more on conditional, like hard-coded things than the LLM. The LLM will just know, OK, no info, let's update it.\n\n44:51 - Chinmay Pandya \nWe just need to tell LLM to recognize all of the activities of today. So he'll sum it up himself. Yeah.\n\n45:00 - Conference Room (Jorge Lewis) - Speaker 1 \nMaybe, maybe later down the road, if we noticed the, the collector is, is it sucks at trying to figure out like multiple data points and adding them together, we can make a small little graph down here to help add an extra LLM saying summarize or like extract the, the data points for this in this category.\n\n45:21 - Unidentified Speaker \nSomething like that.\n\n45:22 - Conference Room (Jorge Lewis) - Speaker 1 \nIt's the thing about the nice thing.\n\n45:24 - Unidentified Speaker \nSorry.\n\n45:25 - Chinmay Pandya \nI was thinking of a fourth node because if the collector has too many responsibilities, it might not work.\n\n45:32 - Unidentified Speaker \nYeah.\n\n45:33 - Conference Room (Jorge Lewis) - Speaker 1 \nSo, so we'll have to test around. Um, that's a nice thing about this graphs. It's really easy to test. You just change the prompts and add some edges. Yeah.\n\n45:40 - Chinmay Pandya \nWe just have to add a node and we have to just transfer the tools.\n\n45:46 - Unidentified Speaker \nYeah.\n\n45:46 - Chinmay Pandya \nWe have to transfer from coach, from collector to the support. Yeah.\n\n45:52 - Unidentified Speaker \nOkay, cool.\n\n45:54 - Conference Room (Jorge Lewis) - Speaker 1 \nSo in terms of the plan then, I'll leave Chinmay and D.Wes to discuss what you guys are going to try to do. Jonas is going to continue on the messages thing. I won't be on the project right now. I'll let you guys work.\n\n46:15 - Conference Room (Jorge Lewis) - Speaker 1 \nAre you guys both on tomorrow?\n\n46:18 - Unidentified Speaker \nYeah, yep.\n\n46:21 - Unidentified Speaker \nOkay, cool.\n\n46"}
02:07:11,501 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,505 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ari \nHmm.\n\n12:08 - Biwas bhandari \nOkay.\n\n12:32 - Jorge Lewis \nBye.\n\n12:55 - Biwas bhandari \nOkay Your your gather characters out of the office just sitting but just standing there okay yeah so So there are a couple of things I need to include here in the content.\n\n13:59 - Biwas bhandari \nPeople.\n\n14:32 - Jorge Lewis \nOh, you haven\'t pulled. Oh no, bro, you gotta be pulling. I don\'t think you\'ve pulled yet.\n\n14:39 - Biwas bhandari \nNo, I haven\'t pulled yet.\n\n14:42 - Jorge Lewis \nYeah, yeah. You gotta always be pulling from alpha.\n\n14:48 - Jorge Lewis \nObviously, it depends on the project. If no one else is working on the project, it\'s obviously gonna be less likely, but it should be a habit that every day you\'re pulling, it should be on the back of your head always.\n\n15:08 - Biwas bhandari \nIssues of... No, I think that won\'t work.\n\n15:14 - Jorge Lewis \nYeah, no. Alright, so right now, we need to make a button that calls the function, right?\n\n15:21 - Biwas bhandari \nYeah, also, since I\'m calling it, it\'s only showing post and this one, but it\'s not showing here. Why is it relevant or not? Why do we need to show that?\n\n15:40 - Jorge Lewis \nI don\'t need that. I don\'t need why it\'s relevant or not.\n\n15:47 - Biwas bhandari \nOkay. And that\'s good.\n\n15:53 - Jorge Lewis \nLike for something like that, it\'s the same thing when you were working on the prompts, improving the prompts. You have to understand. So this is not specific for this project. I\'m trying to teach you this so that when you\'re working on the client\'s projects, it\'s going to be a big issue. If you\'re working on something that doesn\'t align with them, it\'s going to be a very big issue because for them, to them, that means that they\'re paying you money to work on something they don\'t need, they don\'t care about. And they\'re going to question your competence and your character. Why did you not ask me before? Is this important? Stuff like this, right?\n\n16:31 - Biwas bhandari \nThe relevance reason is not important to you, you are just fetching the data and putting it in the frontend.\n\n16:45 - Jorge Lewis \nYeah, right now, like for example, right now the current version, it doesn\'t have it. I don\'t need it right now. Because, yeah, just what I need right now is not that. And that\'s exactly the process it should be. You ask me in a chat, hey, I was thinking it would be useful if I had the reason why it was relevant or not, or the reason why it was relevant, then I would say yes or no. And we\'d be able to move from there rather than potentially spending time on that, right?\n\n17:14 - Biwas bhandari \nYeah. Okay.\n\n17:17 - Jorge Lewis \nCool. Oh yeah. So let\'s get this button in.\n\n17:24 - Unidentified Speaker \nYeah.\n\n17:24 - Jorge Lewis \nOkay. So open up the code and we\'ll go to... We\'ll figure it out. So which part were you struggling with? What have you tried so far and kind of where are you at?\n\n17:34 - Biwas bhandari \nSo yeah, for the bottom I have an alternative, right? If I just go to the search route, then it will automatically fetch it. I just told the sensitivity to make it.\n\n17:53 - Biwas bhandari \nLet me just show you.\n\n17:59 - Jorge Lewis \nSo there\'s a search route?\n\n18:02 - Biwas bhandari \nYeah. In the route, there is... Sorry. These two codes are written by XAPT.\n\n18:10 - Jorge Lewis \nIf I enter, then you can see here.\n\n18:24 - Biwas bhandari \nOkay, because if it\'s fetching the duplicate post, it\'s not saving in the database.\n\n18:30 - Jorge Lewis \nYeah. Okay, so...\n\n18:36 - Biwas bhandari \nYeah, if I go into the solver, it will automatically fetch all the functions.\n\n18:42 - Jorge Lewis \nYeah, so there\'s two ways we can do this. We can do it the really simple way and have it fetch on the load. So, what you\'re doing is fetching on load, right? Yeah. You\'ve added the functions on load. The alternative is adding it to an action. Are you familiar with actions?\n\n18:58 - Unidentified Speaker \nNo.\n\n18:59 - Jorge Lewis \nSo an action is a spelt kind of thing that allows us to call a server function in the front end. So I could show an example. If you go into, I don\'t know. I mean, yeah, so I guess there\'s this, there\'s nothing inside it, but for example, it might look like this. We have, What is it, search or just do, what should we call the end point that we\'re trying to...\n\n19:33 - Jorge Lewis \nOkay, fetch post and evaluate. So this is what it looks like,\n\n19:53 - Jorge Lewis \nHold up.\n\n20:05 - Jorge Lewis \nAll right, where\'s my GIF co-pilot?\n\n20:20 - Jorge Lewis \nOh, OK.\n\n20:36 - Jorge Lewis \nOkay\n######################\nOutput:'}
02:07:11,506 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,511 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "ari \nHmm.\n\n12:08 - Biwas bhandari \nOkay.\n\n12:32 - Jorge Lewis \nBye.\n\n12:55 - Biwas bhandari \nOkay Your your gather characters out of the office just sitting but just standing there okay yeah so So there are a couple of things I need to include here in the content.\n\n13:59 - Biwas bhandari \nPeople.\n\n14:32 - Jorge Lewis \nOh, you haven't pulled. Oh no, bro, you gotta be pulling. I don't think you've pulled yet.\n\n14:39 - Biwas bhandari \nNo, I haven't pulled yet.\n\n14:42 - Jorge Lewis \nYeah, yeah. You gotta always be pulling from alpha.\n\n14:48 - Jorge Lewis \nObviously, it depends on the project. If no one else is working on the project, it's obviously gonna be less likely, but it should be a habit that every day you're pulling, it should be on the back of your head always.\n\n15:08 - Biwas bhandari \nIssues of... No, I think that won't work.\n\n15:14 - Jorge Lewis \nYeah, no. Alright, so right now, we need to make a button that calls the function, right?\n\n15:21 - Biwas bhandari \nYeah, also, since I'm calling it, it's only showing post and this one, but it's not showing here. Why is it relevant or not? Why do we need to show that?\n\n15:40 - Jorge Lewis \nI don't need that. I don't need why it's relevant or not.\n\n15:47 - Biwas bhandari \nOkay. And that's good.\n\n15:53 - Jorge Lewis \nLike for something like that, it's the same thing when you were working on the prompts, improving the prompts. You have to understand. So this is not specific for this project. I'm trying to teach you this so that when you're working on the client's projects, it's going to be a big issue. If you're working on something that doesn't align with them, it's going to be a very big issue because for them, to them, that means that they're paying you money to work on something they don't need, they don't care about. And they're going to question your competence and your character. Why did you not ask me before? Is this important? Stuff like this, right?\n\n16:31 - Biwas bhandari \nThe relevance reason is not important to you, you are just fetching the data and putting it in the frontend.\n\n16:45 - Jorge Lewis \nYeah, right now, like for example, right now the current version, it doesn't have it. I don't need it right now. Because, yeah, just what I need right now is not that. And that's exactly the process it should be. You ask me in a chat, hey, I was thinking it would be useful if I had the reason why it was relevant or not, or the reason why it was relevant, then I would say yes or no. And we'd be able to move from there rather than potentially spending time on that, right?\n\n17:14 - Biwas bhandari \nYeah. Okay.\n\n17:17 - Jorge Lewis \nCool. Oh yeah. So let's get this button in.\n\n17:24 - Unidentified Speaker \nYeah.\n\n17:24 - Jorge Lewis \nOkay. So open up the code and we'll go to... We'll figure it out. So which part were you struggling with? What have you tried so far and kind of where are you at?\n\n17:34 - Biwas bhandari \nSo yeah, for the bottom I have an alternative, right? If I just go to the search route, then it will automatically fetch it. I just told the sensitivity to make it.\n\n17:53 - Biwas bhandari \nLet me just show you.\n\n17:59 - Jorge Lewis \nSo there's a search route?\n\n18:02 - Biwas bhandari \nYeah. In the route, there is... Sorry. These two codes are written by XAPT.\n\n18:10 - Jorge Lewis \nIf I enter, then you can see here.\n\n18:24 - Biwas bhandari \nOkay, because if it's fetching the duplicate post, it's not saving in the database.\n\n18:30 - Jorge Lewis \nYeah. Okay, so...\n\n18:36 - Biwas bhandari \nYeah, if I go into the solver, it will automatically fetch all the functions.\n\n18:42 - Jorge Lewis \nYeah, so there's two ways we can do this. We can do it the really simple way and have it fetch on the load. So, what you're doing is fetching on load, right? Yeah. You've added the functions on load. The alternative is adding it to an action. Are you familiar with actions?\n\n18:58 - Unidentified Speaker \nNo.\n\n18:59 - Jorge Lewis \nSo an action is a spelt kind of thing that allows us to call a server function in the front end. So I could show an example. If you go into, I don't know. I mean, yeah, so I guess there's this, there's nothing inside it, but for example, it might look like this. We have, What is it, search or just do, what should we call the end point that we're trying to...\n\n19:33 - Jorge Lewis \nOkay, fetch post and evaluate. So this is what it looks like,\n\n19:53 - Jorge Lewis \nHold up.\n\n20:05 - Jorge Lewis \nAll right, where's my GIF co-pilot?\n\n20:20 - Jorge Lewis \nOh, OK.\n\n20:36 - Jorge Lewis \nOkay"}
02:07:11,517 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,517 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,519 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: doesn\'t match. Oh, wait, no.\n\n26:11 - Biwas bhandari \nNo, it was just map before. Oh, yeah, this thing, yeah, yeah.\n\n26:16 - Jorge Lewis \nOkay, and then if there\'s a fetch error, but this can just always be, if there\'s only one function, like one super base call, we can call them exactly what they are.\n\n26:27 - Unidentified Speaker \nOkay.\n\n26:30 - Jorge Lewis \nBut yeah, so we can just.\n\n26:39 - Jorge Lewis \nOkay, I can\'t rename, I guess.\n\n26:47 - Jorge Lewis \nSo, okay, so we\'re checking, we\'re fetching the existing submissions, and then if there\'s an error, we can get them, throw a new error. We don\'t want to be throwing, I don\'t think we want to throw errors here.\n\n27:03 - Jorge Lewis \nI think this is a question I should ask Nazif, because error handling with, well, web dev in general, but especially stock kit, is something pretty hard to get right. So figuring out, asking Nazif how to do that properly might be a good idea. So actually, I\'m going to leave it here, and you can ask Nazif later.\n\n27:26 - Jorge Lewis \nDid you make the set function?\n\n27:32 - Jorge Lewis \nIs this built in or?\n\n27:34 - Biwas bhandari \nNo. Yeah, the third one is built in.\n\n27:39 - Jorge Lewis \nOh, what does it do?\n\n27:42 - Biwas bhandari \nIt will just set it like a cassette.\n\n27:47 - Jorge Lewis \nLike a what? Store it.\n\n27:51 - Jorge Lewis \nYour mic\'s pretty muffled again.\n\n27:58 - Biwas bhandari \nCan you hear now?\n\n27:59 - Biwas bhandari \nYeah, yeah.\n\n28:02 - Biwas bhandari \nYeah, this set will just store it like a cache.\n\n28:06 - Jorge Lewis \nSorry, your mic\'s again gone, it\'s too quiet.\n\n28:10 - Jorge Lewis \nHello?\n\n28:11 - Biwas bhandari \nThere we go, yeah, that\'s good.\n\n28:13 - Biwas bhandari \nYeah, the set, what this set does is it stores this in a cache.\n\n28:22 - Jorge Lewis \nIn a what?\n\n28:24 - Biwas bhandari \nCache, C-A-C-H-E, what do you call it? Oh, cache.\n\n28:28 - Unidentified Speaker \nYeah.\n\n28:29 - Jorge Lewis \nOh, I see. The big problem with that is that this is a server function, so we can\'t be using a cache on the server.\n\n28:47 - Jorge Lewis \nDo you understand how the architecture of a server client works?\n\n28:52 - Biwas bhandari \nYeah, mostly.\n\n28:57 - Jorge Lewis \nOkay, so using that, do you understand why we can\'t cache on the server?\n\n29:03 - Biwas bhandari \nLet me think.\n\n29:20 - Biwas bhandari \nNo, no idea.\n\n29:23 - Jorge Lewis \nSo the clients is the users. The server is not the users. The server belongs to all of the users. And in that way, it belongs to none of the users by themselves. So when we try to cache an individual user\'s or an individual client\'s results, that\'s a bad practice because we could technically... So the server is considered like a machine. It\'s just like a computer, right? We can store the user\'s results on there. But if we have 10,000 users storing the results on there, number one, is it going to have problems with scalability? Because caching is very expensive. But number two is it\'s a terrible practice because a server is made not to be used to store user stuff. You never want to store anything on the server. All you want to do on the server is call a function, produce an output, and return that output. That\'s always what a server is used for.\n\n30:22 - Jorge Lewis \nUsually when you want to do caching, you add a layer of caching. So for example, so you have these, you have the clients and then you have, let me just, you have a client, you have a server sometimes, and then you have the database in between. Oftentimes you have a, so for example, before when we were using, when we were using Python, we were using Reads. Reads is a tool that allows you to cache things. So your server calls on Reads for its cache and then uses that instead of, you know, this is kind of the structure that you want to be using if you want to use caches. There\'s obviously other solutions. You can cache it on the clients on using local storage or something, or you can cache it using database, but probably the most, the simplest option is usually the clients using local storage is my guess. But yeah, so usually we don\'t want to, we don\'t want to, store, cache things on the server. You don\'t want to save any user data on the server especially. That\'s kind of a... Because if I save anything on the server, it\'s very likely that it\'s not safe. That\'s first of all. And just a whole bunch of reasons why not to.\n\n31:34 - Biwas bhandari \nGot it. You can just add your command not to use it.\n\n31:38 - Jorge Lewis \nYeah, so what is this actually doing here? Getting the IDs?\n\n31:43 - Biwas bhandari\n######################\nOutput:'}
02:07:11,519 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,522 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "doesn't match. Oh, wait, no.\n\n26:11 - Biwas bhandari \nNo, it was just map before. Oh, yeah, this thing, yeah, yeah.\n\n26:16 - Jorge Lewis \nOkay, and then if there's a fetch error, but this can just always be, if there's only one function, like one super base call, we can call them exactly what they are.\n\n26:27 - Unidentified Speaker \nOkay.\n\n26:30 - Jorge Lewis \nBut yeah, so we can just.\n\n26:39 - Jorge Lewis \nOkay, I can't rename, I guess.\n\n26:47 - Jorge Lewis \nSo, okay, so we're checking, we're fetching the existing submissions, and then if there's an error, we can get them, throw a new error. We don't want to be throwing, I don't think we want to throw errors here.\n\n27:03 - Jorge Lewis \nI think this is a question I should ask Nazif, because error handling with, well, web dev in general, but especially stock kit, is something pretty hard to get right. So figuring out, asking Nazif how to do that properly might be a good idea. So actually, I'm going to leave it here, and you can ask Nazif later.\n\n27:26 - Jorge Lewis \nDid you make the set function?\n\n27:32 - Jorge Lewis \nIs this built in or?\n\n27:34 - Biwas bhandari \nNo. Yeah, the third one is built in.\n\n27:39 - Jorge Lewis \nOh, what does it do?\n\n27:42 - Biwas bhandari \nIt will just set it like a cassette.\n\n27:47 - Jorge Lewis \nLike a what? Store it.\n\n27:51 - Jorge Lewis \nYour mic's pretty muffled again.\n\n27:58 - Biwas bhandari \nCan you hear now?\n\n27:59 - Biwas bhandari \nYeah, yeah.\n\n28:02 - Biwas bhandari \nYeah, this set will just store it like a cache.\n\n28:06 - Jorge Lewis \nSorry, your mic's again gone, it's too quiet.\n\n28:10 - Jorge Lewis \nHello?\n\n28:11 - Biwas bhandari \nThere we go, yeah, that's good.\n\n28:13 - Biwas bhandari \nYeah, the set, what this set does is it stores this in a cache.\n\n28:22 - Jorge Lewis \nIn a what?\n\n28:24 - Biwas bhandari \nCache, C-A-C-H-E, what do you call it? Oh, cache.\n\n28:28 - Unidentified Speaker \nYeah.\n\n28:29 - Jorge Lewis \nOh, I see. The big problem with that is that this is a server function, so we can't be using a cache on the server.\n\n28:47 - Jorge Lewis \nDo you understand how the architecture of a server client works?\n\n28:52 - Biwas bhandari \nYeah, mostly.\n\n28:57 - Jorge Lewis \nOkay, so using that, do you understand why we can't cache on the server?\n\n29:03 - Biwas bhandari \nLet me think.\n\n29:20 - Biwas bhandari \nNo, no idea.\n\n29:23 - Jorge Lewis \nSo the clients is the users. The server is not the users. The server belongs to all of the users. And in that way, it belongs to none of the users by themselves. So when we try to cache an individual user's or an individual client's results, that's a bad practice because we could technically... So the server is considered like a machine. It's just like a computer, right? We can store the user's results on there. But if we have 10,000 users storing the results on there, number one, is it going to have problems with scalability? Because caching is very expensive. But number two is it's a terrible practice because a server is made not to be used to store user stuff. You never want to store anything on the server. All you want to do on the server is call a function, produce an output, and return that output. That's always what a server is used for.\n\n30:22 - Jorge Lewis \nUsually when you want to do caching, you add a layer of caching. So for example, so you have these, you have the clients and then you have, let me just, you have a client, you have a server sometimes, and then you have the database in between. Oftentimes you have a, so for example, before when we were using, when we were using Python, we were using Reads. Reads is a tool that allows you to cache things. So your server calls on Reads for its cache and then uses that instead of, you know, this is kind of the structure that you want to be using if you want to use caches. There's obviously other solutions. You can cache it on the clients on using local storage or something, or you can cache it using database, but probably the most, the simplest option is usually the clients using local storage is my guess. But yeah, so usually we don't want to, we don't want to, store, cache things on the server. You don't want to save any user data on the server especially. That's kind of a... Because if I save anything on the server, it's very likely that it's not safe. That's first of all. And just a whole bunch of reasons why not to.\n\n31:34 - Biwas bhandari \nGot it. You can just add your command not to use it.\n\n31:38 - Jorge Lewis \nYeah, so what is this actually doing here? Getting the IDs?\n\n31:43 - Biwas bhandari"}
02:07:11,523 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: it might look like this. We have, What is it, search or just do, what should we call the end point that we\'re trying to...\n\n19:33 - Jorge Lewis \nOkay, fetch post and evaluate. So this is what it looks like,\n\n19:53 - Jorge Lewis \nHold up.\n\n20:05 - Jorge Lewis \nAll right, where\'s my GIF co-pilot?\n\n20:20 - Jorge Lewis \nOh, OK.\n\n20:36 - Jorge Lewis \nOkay, so it takes in this, and inside here, so what we\'re doing is we\'re fetching. We don\'t return anything since the server function is calling on Superbase. So all we need to do is exactly what you did in the other function, which was calling this, the function, and let\'s just import it.\n\n21:02 - Jorge Lewis \nIt should be good. We don\'t need to return anything. In fact, since this is going to be a POST request... Oh no, this is a GET request. But we\'re not going to return anything. I guess we could. What does the fetch... Does it potentially return an F? The return is void.\n\n21:31 - Jorge Lewis \nSo it\'s not returning anything? Okay. So it\'s not returning anything.\n\n21:38 - Jorge Lewis \nYeah, so instead of, usually I don\'t wrap things and try and catch. That\'s kind of a terrible practice to be using. There\'s of course the right place and right time to use it, but that\'s what I did before and it\'s great when you want something to work, but when you\'re trying to, now that we\'re integrating it into the app, If it errors, we don\'t want nothing to happen. We need to know it erred so that we can fix it if it\'s needed. So instead of logging error, we do... Because the console log error would be... It\'s one way to do it. So we\'re fetching the subreddit post and this returns...\n\n22:19 - Jorge Lewis \nWhat if the Fetch subreddit, so okay, one thing I\'ve noticed already so far is you\'re missing to add the potentials. Like if, for example, let\'s go into Fetch subreddit posts. This here. By the way, you can follow me, by the way. If you go into live share, you can click follow.\n\n22:46 - Jorge Lewis \nOkay.\n\n22:47 - Jorge Lewis \nSo this function here returns a promise of a post, right? So you\'re returning here. The filtered post gets taken by this and filterExisting. So none of these actually have the ability to return null, meaning if there is an error, it will return undefined. We\'re not considering that at all. We don\'t give it the option to return none. This is exactly where we want to be checking if there\'s an error, so Okay, so if there\'s fetch error, then we\'re going to log it But then what happens okay, so you\'re using another try catch okay, but yeah, especially for so what I would recommend is Taking a look at some of the other code probably on adapt would be good, but taking a look at adapt and and seeing how we handle things like this. I\'ll go through now. I\'m no expert, so if I write something that isn\'t the most optimal, oh well. But at least it\'s not a try-catch function.\n\n23:52 - Jorge Lewis \nSo, okay, so we\'re getting the data from evaluator\'s mission, select.\n\n24:02 - Biwas bhandari \nOkay.\n\n24:03 - Biwas bhandari \nI\'m just fetching it from the superweb to see if the page post from Reddit ID is already there in the superweb. If it\'s there, it\'ll filter it out.\n\n24:23 - Jorge Lewis \nSo why are we selecting title here as well?\n\n24:26 - Biwas bhandari \nYeah, both are the same. I mean, I want to check if the Read.AI ID and title are there on my page. And sometimes there will be same title, and the reddit ID might be different. For example, if you post with a title, I need advice, and I will post with a title, I need advice. Both of our titles will be the same.\n\n24:48 - Jorge Lewis \nYeah, how did I do it?\n\n25:00 - Jorge Lewis \nSo, why are we not using the UUID?\n\n25:15 - Biwas bhandari \nbecause uuid is generated by superweb but what we are trying to compare is the post we face from Read.AI for example if you post from Read.AI it will give us reddit id title something like that it will not give\n\n25:33 - Jorge Lewis \nus uuid So the issue that I can see here, and I think it\'s good that you didn\'t actually do what I\'m about to suggest, is that the title and the Reddit ID, the Reddit ID isn\'t actually too unique. It\'s a five character long, I believe, ID, right?\n\n25:56 - Jorge Lewis \nSo by no means is that supposed to be unique. That\'s not the unique identifier in the program. So the case, so right here, can you explain? I actually don\'t know. We\'re checking that ID doesn\'t match. Oh, wait, no.\n\n26:11 - Biwas bhandari \nNo, it was just map before. Oh, yeah, this thing, yeah, yeah.\n\n26:16 - Jorge Lewis \nOkay, and then if there\'s a fetch error, but this can just always be, if there\'s only one function, like one super base call, we can call them exactly what they are.\n\n26:27 - Unidentified Speaker \nOkay.\n\n26:30 -\n######################\nOutput:'}
02:07:11,523 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,526 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "it might look like this. We have, What is it, search or just do, what should we call the end point that we're trying to...\n\n19:33 - Jorge Lewis \nOkay, fetch post and evaluate. So this is what it looks like,\n\n19:53 - Jorge Lewis \nHold up.\n\n20:05 - Jorge Lewis \nAll right, where's my GIF co-pilot?\n\n20:20 - Jorge Lewis \nOh, OK.\n\n20:36 - Jorge Lewis \nOkay, so it takes in this, and inside here, so what we're doing is we're fetching. We don't return anything since the server function is calling on Superbase. So all we need to do is exactly what you did in the other function, which was calling this, the function, and let's just import it.\n\n21:02 - Jorge Lewis \nIt should be good. We don't need to return anything. In fact, since this is going to be a POST request... Oh no, this is a GET request. But we're not going to return anything. I guess we could. What does the fetch... Does it potentially return an F? The return is void.\n\n21:31 - Jorge Lewis \nSo it's not returning anything? Okay. So it's not returning anything.\n\n21:38 - Jorge Lewis \nYeah, so instead of, usually I don't wrap things and try and catch. That's kind of a terrible practice to be using. There's of course the right place and right time to use it, but that's what I did before and it's great when you want something to work, but when you're trying to, now that we're integrating it into the app, If it errors, we don't want nothing to happen. We need to know it erred so that we can fix it if it's needed. So instead of logging error, we do... Because the console log error would be... It's one way to do it. So we're fetching the subreddit post and this returns...\n\n22:19 - Jorge Lewis \nWhat if the Fetch subreddit, so okay, one thing I've noticed already so far is you're missing to add the potentials. Like if, for example, let's go into Fetch subreddit posts. This here. By the way, you can follow me, by the way. If you go into live share, you can click follow.\n\n22:46 - Jorge Lewis \nOkay.\n\n22:47 - Jorge Lewis \nSo this function here returns a promise of a post, right? So you're returning here. The filtered post gets taken by this and filterExisting. So none of these actually have the ability to return null, meaning if there is an error, it will return undefined. We're not considering that at all. We don't give it the option to return none. This is exactly where we want to be checking if there's an error, so Okay, so if there's fetch error, then we're going to log it But then what happens okay, so you're using another try catch okay, but yeah, especially for so what I would recommend is Taking a look at some of the other code probably on adapt would be good, but taking a look at adapt and and seeing how we handle things like this. I'll go through now. I'm no expert, so if I write something that isn't the most optimal, oh well. But at least it's not a try-catch function.\n\n23:52 - Jorge Lewis \nSo, okay, so we're getting the data from evaluator's mission, select.\n\n24:02 - Biwas bhandari \nOkay.\n\n24:03 - Biwas bhandari \nI'm just fetching it from the superweb to see if the page post from Reddit ID is already there in the superweb. If it's there, it'll filter it out.\n\n24:23 - Jorge Lewis \nSo why are we selecting title here as well?\n\n24:26 - Biwas bhandari \nYeah, both are the same. I mean, I want to check if the Read.AI ID and title are there on my page. And sometimes there will be same title, and the reddit ID might be different. For example, if you post with a title, I need advice, and I will post with a title, I need advice. Both of our titles will be the same.\n\n24:48 - Jorge Lewis \nYeah, how did I do it?\n\n25:00 - Jorge Lewis \nSo, why are we not using the UUID?\n\n25:15 - Biwas bhandari \nbecause uuid is generated by superweb but what we are trying to compare is the post we face from Read.AI for example if you post from Read.AI it will give us reddit id title something like that it will not give\n\n25:33 - Jorge Lewis \nus uuid So the issue that I can see here, and I think it's good that you didn't actually do what I'm about to suggest, is that the title and the Reddit ID, the Reddit ID isn't actually too unique. It's a five character long, I believe, ID, right?\n\n25:56 - Jorge Lewis \nSo by no means is that supposed to be unique. That's not the unique identifier in the program. So the case, so right here, can you explain? I actually don't know. We're checking that ID doesn't match. Oh, wait, no.\n\n26:11 - Biwas bhandari \nNo, it was just map before. Oh, yeah, this thing, yeah, yeah.\n\n26:16 - Jorge Lewis \nOkay, and then if there's a fetch error, but this can just always be, if there's only one function, like one super base call, we can call them exactly what they are.\n\n26:27 - Unidentified Speaker \nOkay.\n\n26:30 -"}
02:07:11,536 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,538 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: the server especially. That\'s kind of a... Because if I save anything on the server, it\'s very likely that it\'s not safe. That\'s first of all. And just a whole bunch of reasons why not to.\n\n31:34 - Biwas bhandari \nGot it. You can just add your command not to use it.\n\n31:38 - Jorge Lewis \nYeah, so what is this actually doing here? Getting the IDs?\n\n31:43 - Biwas bhandari \nYeah. Mapping the IDs.\n\n31:48 - Jorge Lewis \nSo we can just do that, right?\n\n32:08 - Jorge Lewis \nWhat\'s the function? Is it includes?\n\n32:14 - Jorge Lewis \nSo we\'re checking the existing Read.AI IDs. Yeah, okay. So the problem with this, by the way, is like I said, the Read.AI ID isn\'t unique. So the issue with that is that maybe there\'s a post with the same ID. It\'s very rare since they\'re pretty, like, they\'re not impossible to get the same, but they\'re also very, like, they look very different. So it\'s something that we need to consider for the longterm, but for now it\'s fine, right?\n\n32:44 - Jorge Lewis \nSo we\'ll leave that for now. Obviously, we shouldn\'t be fetching every time is the first thing, but yeah, so we can figure it out later.\n\n32:55 - Jorge Lewis \nSo existing, I guess we\'re getting the IDs. We\'re checking if...\n\n33:12 - Jorge Lewis \nOkay.\n\n33:19 - Jorge Lewis \nOkay, you\'re checking both.\n\n33:21 - Jorge Lewis \nYeah.\n\n33:22 - Jorge Lewis \nOkay. Yeah, I mean, fair enough.\n\n33:25 - Jorge Lewis \nAlthough, yeah, I mean, I wonder if there\'s ever a time where, because like, the Read.AI ID, that was random, the title, people make them themselves. So I\'m wondering if, like, if I\'m a person with an idea, On the subreddits, often I see that people posting very similar titles. So I wonder if we might lose something.\n\n33:48 - Biwas bhandari \nYeah, I encountered one. It was fetching two with the same ID.\n\n33:59 - Jorge Lewis \nBut like different posts or like different people?\n\n34:03 - Biwas bhandari \nNo, I didn\'t check that, but I just console logged the title and two of them were the same.\n\n34:11 - Jorge Lewis \nYeah, so people cross post, they post on different subreddits, so that would make sense. So what we could do is do check for title and user.\n\n34:25 - Biwas bhandari \nOr even, I think.\n\n34:26 - Biwas bhandari \nWe can filter it with username.\n\n34:29 - Jorge Lewis \nYeah, yeah, if you check for username, we don\'t need the same, we don\'t need one user twice. That\'s a good point, so. So we can do.\n\n34:40 - Biwas bhandari \nYeah, I should have done that before.\n\n34:45 - Jorge Lewis \nYeah, no, it\'s fine. That\'s what we learned. So that\'s why it\'s good that we\'re doing this like super fast because then you learn this. If you made this system perfectly, you wouldn\'t, like it\'s impossible to kind of predict that you would make this mistake. So it\'s just great to make things fast. Okay, so we return new posts. If there\'s no new posts, so this could just be empty. Okay.\n\n35:10 - Jorge Lewis \nYeah, it\'ll just be empty if there\'s no. Oh, yeah.\n\n35:17 - Biwas bhandari \nIf all the posts are duplicated, it will not pass anything.\n\n35:21 - Jorge Lewis \nSo I mean, if it errors, if this superbase call errors, we\'ll be console logging, and then we\'ll throw this error. But I want to just not throw that error for now.\n\n35:32 - Jorge Lewis \nSo now we\'re getting an error saying that this might be null, data submissions. So one common thing that we do when we\'re, directly after we call a super base call, we do if error to check if the error is right, but also and if the data is not null. So this way. We know that there is some data that we return. Because if it\'s empty, well... Yeah, because it shouldn\'t be... It\'s possibly null. Why is it saying... Is this...\n\n36:31 - Jorge Lewis \nIs your IDE commenting that out as well? Like, erroring this?\n\n36:36 - Jorge Lewis \nYeah.\n\n36:36 - Jorge Lewis \nYeah, but I\'m checking right here, no?\n\n36:40 - Biwas bhandari \nI think we just need to...\n\n36:43 - Jorge Lewis \nIf error... Oh wait, no, sorry, whoops, this should be or.\n\n36:47 - Biwas bhandari \nNo, we can just... I had a question mark here.\n\n36:49 - Jorge Lewis \nI don\'t know, we try not to use question marks. That\'s... Question marks... What question mark does is it just... That it\'s not null, but if this was saying it can be null, that\'s a totally different thing. What\'s the or operator in TypeScript?\n\n37:09 - Biwas bhandari \nIs it just or?\n\n37:13 - Jorge Lewis \nIt\'s right?\n\n37:14 - Unidentified Speaker \nYeah.\n\n37:17 - Jorge Lewis \nFor me, it\'s like\n######################\nOutput:'}
02:07:11,538 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,541 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "the server especially. That's kind of a... Because if I save anything on the server, it's very likely that it's not safe. That's first of all. And just a whole bunch of reasons why not to.\n\n31:34 - Biwas bhandari \nGot it. You can just add your command not to use it.\n\n31:38 - Jorge Lewis \nYeah, so what is this actually doing here? Getting the IDs?\n\n31:43 - Biwas bhandari \nYeah. Mapping the IDs.\n\n31:48 - Jorge Lewis \nSo we can just do that, right?\n\n32:08 - Jorge Lewis \nWhat's the function? Is it includes?\n\n32:14 - Jorge Lewis \nSo we're checking the existing Read.AI IDs. Yeah, okay. So the problem with this, by the way, is like I said, the Read.AI ID isn't unique. So the issue with that is that maybe there's a post with the same ID. It's very rare since they're pretty, like, they're not impossible to get the same, but they're also very, like, they look very different. So it's something that we need to consider for the longterm, but for now it's fine, right?\n\n32:44 - Jorge Lewis \nSo we'll leave that for now. Obviously, we shouldn't be fetching every time is the first thing, but yeah, so we can figure it out later.\n\n32:55 - Jorge Lewis \nSo existing, I guess we're getting the IDs. We're checking if...\n\n33:12 - Jorge Lewis \nOkay.\n\n33:19 - Jorge Lewis \nOkay, you're checking both.\n\n33:21 - Jorge Lewis \nYeah.\n\n33:22 - Jorge Lewis \nOkay. Yeah, I mean, fair enough.\n\n33:25 - Jorge Lewis \nAlthough, yeah, I mean, I wonder if there's ever a time where, because like, the Read.AI ID, that was random, the title, people make them themselves. So I'm wondering if, like, if I'm a person with an idea, On the subreddits, often I see that people posting very similar titles. So I wonder if we might lose something.\n\n33:48 - Biwas bhandari \nYeah, I encountered one. It was fetching two with the same ID.\n\n33:59 - Jorge Lewis \nBut like different posts or like different people?\n\n34:03 - Biwas bhandari \nNo, I didn't check that, but I just console logged the title and two of them were the same.\n\n34:11 - Jorge Lewis \nYeah, so people cross post, they post on different subreddits, so that would make sense. So what we could do is do check for title and user.\n\n34:25 - Biwas bhandari \nOr even, I think.\n\n34:26 - Biwas bhandari \nWe can filter it with username.\n\n34:29 - Jorge Lewis \nYeah, yeah, if you check for username, we don't need the same, we don't need one user twice. That's a good point, so. So we can do.\n\n34:40 - Biwas bhandari \nYeah, I should have done that before.\n\n34:45 - Jorge Lewis \nYeah, no, it's fine. That's what we learned. So that's why it's good that we're doing this like super fast because then you learn this. If you made this system perfectly, you wouldn't, like it's impossible to kind of predict that you would make this mistake. So it's just great to make things fast. Okay, so we return new posts. If there's no new posts, so this could just be empty. Okay.\n\n35:10 - Jorge Lewis \nYeah, it'll just be empty if there's no. Oh, yeah.\n\n35:17 - Biwas bhandari \nIf all the posts are duplicated, it will not pass anything.\n\n35:21 - Jorge Lewis \nSo I mean, if it errors, if this superbase call errors, we'll be console logging, and then we'll throw this error. But I want to just not throw that error for now.\n\n35:32 - Jorge Lewis \nSo now we're getting an error saying that this might be null, data submissions. So one common thing that we do when we're, directly after we call a super base call, we do if error to check if the error is right, but also and if the data is not null. So this way. We know that there is some data that we return. Because if it's empty, well... Yeah, because it shouldn't be... It's possibly null. Why is it saying... Is this...\n\n36:31 - Jorge Lewis \nIs your IDE commenting that out as well? Like, erroring this?\n\n36:36 - Jorge Lewis \nYeah.\n\n36:36 - Jorge Lewis \nYeah, but I'm checking right here, no?\n\n36:40 - Biwas bhandari \nI think we just need to...\n\n36:43 - Jorge Lewis \nIf error... Oh wait, no, sorry, whoops, this should be or.\n\n36:47 - Biwas bhandari \nNo, we can just... I had a question mark here.\n\n36:49 - Jorge Lewis \nI don't know, we try not to use question marks. That's... Question marks... What question mark does is it just... That it's not null, but if this was saying it can be null, that's a totally different thing. What's the or operator in TypeScript?\n\n37:09 - Biwas bhandari \nIs it just or?\n\n37:13 - Jorge Lewis \nIt's right?\n\n37:14 - Unidentified Speaker \nYeah.\n\n37:17 - Jorge Lewis \nFor me, it's like"}
02:07:11,555 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,556 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: not to use question marks. That\'s... Question marks... What question mark does is it just... That it\'s not null, but if this was saying it can be null, that\'s a totally different thing. What\'s the or operator in TypeScript?\n\n37:09 - Biwas bhandari \nIs it just or?\n\n37:13 - Jorge Lewis \nIt\'s right?\n\n37:14 - Unidentified Speaker \nYeah.\n\n37:17 - Jorge Lewis \nFor me, it\'s like different colors, these two. It looks really annoying.\n\n37:25 - Jorge Lewis \nOkay, but now it\'s still airing. I don\'t know. Look, if I do this, that should stop airing. Well, no, without your thing.\n\n37:32 - Biwas bhandari \nI want to learn this. Why is it... Okay, let\'s try...\n\n37:37 - Jorge Lewis \nOkay, so...\n\n37:53 - Jorge Lewis \nBro, I see exactly why so we\'re checking if it\'s not if it\'s null if it\'s null Then we\'re going to do nothing. We still go through with this. So Right here. We should be doing We should be returning an empty list. Oh That way we stop going through this function Okay Okay, so yes, that was why. See, if I said, okay, let me just do this here, I would have forgotten that we should be doing this proper error checking.\n\n38:31 - Jorge Lewis \nOh, yeah.\n\n38:33 - Jorge Lewis \nAnd sometimes you want to move fast, but sometimes it\'s better to write good code. There\'s a balance.\n\n38:45 - Jorge Lewis \nI do the same. Sometimes I will add a question mark even though I should be error checking.\n\n38:52 - Jorge Lewis \nOkay, so this is returning the new post, so we\'ll go back to where it\'s been called, which was, where was it being called?\n\n39:00 - Jorge Lewis \nYeah, here.\n\n39:02 - Biwas bhandari \nHere?\n\n39:05 - Jorge Lewis \nHere.\n\n39:08 - Jorge Lewis \nLet me just close all the tabs, because I\'m lost. Do we have the, I start always from the page.spelt, and then the server file that\'s calling it. Then we can go down here. So this is the main function that we\'re running. We\'re fetching this. If anything happens and it errors, it\'s just going to return an empty list. So I think, actually, this one, we fixed the other function, not this one. So yeah, there\'s a lot of try-catch. Oh, man. No, no, no. No more try-catches. I hereby ban you to try and catch.\n\n39:44 - Jorge Lewis \nYeah, okay. So, okay. You\'re, you\'re doing it.\n\n39:46 - Biwas bhandari \nOh, what is it? Bad practice. Yeah.\n\n39:51 - Jorge Lewis \nSo, so what was the, okay. So for the try and catch, what do you, what do you think you\'re going to catch? Like, uh, what\'s the thought process? What are you worried that my error that we\'re trying to catch?\n\n40:02 - Biwas bhandari \nUm, sometimes we can just, uh, uh, I mean, uh, wrong username and password. So it will just generate another.\n\n40:15 - Jorge Lewis \nLet\'s go step by step. So over time, at the very start, if you\'re a very beginner, try and catch this faster. But at my level, when you understand how to do error checking, it\'s very fast. I\'m not good. Nazif can do this probably in a second. It\'s going to take me at least a minute or two.\n\n40:35 - Jorge Lewis \nSo for fetch functions, if there\'s no response, it\'ll be a null, right? I think. Or no, it\'ll be an empty response. It\'ll give this as something. So if there\'s, if it\'s not okay, is this correct by the way? I don\'t know the best practice, like for, if we\'re checking if it\'s okay. I know there\'s.\n\n41:04 - Jorge Lewis \nCause I think there\'s, there\'s a lot of ways to check if the response did well. Let me, I\'m asking co-pilot. Let\'s see. Yeah, it should be fine. Okay, so we\'re just checking if it\'s not okay. Error. Parse the...\n\n41:25 - Jorge Lewis \nYep.\n\n41:28 - Jorge Lewis \nNew... Whoa. This is data, data, data.\n\n41:34 - Biwas bhandari \nIs there...\n\n41:36 - Biwas bhandari \nNo, we can just change this.\n\n41:46 - Jorge Lewis \nSo I think an easier way of doing this, or a cleaner way of doing this is, now don\'t throw any heat, but that. Nope, not that.\n\n42:00 - Unidentified Speaker \nOkay.\n\n42:02 - Jorge Lewis \nWait, it\'s saying not okay.\n\n42:07 - Jorge Lewis \nWhat is this post data object that I\'m, this one here? Where is it? Sorry?\n\n42:15 - Biwas bhandari \nThat\'s the type for post.\n\n42:17 - Biwas bhandari \nYep. Did you make it yourself?\n\n42:19 - Jorge Lewis \nYeah.\n\n42:20 - Jorge Lewis \nIs it exactly the same as when you return?\n\n42:25 - Biwas bhandari \nYeah. I first check the response and make it. Okay.\n\n42:30 - Jorge Lewis\n######################\nOutput:'}
02:07:11,556 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,559 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "not to use question marks. That's... Question marks... What question mark does is it just... That it's not null, but if this was saying it can be null, that's a totally different thing. What's the or operator in TypeScript?\n\n37:09 - Biwas bhandari \nIs it just or?\n\n37:13 - Jorge Lewis \nIt's right?\n\n37:14 - Unidentified Speaker \nYeah.\n\n37:17 - Jorge Lewis \nFor me, it's like different colors, these two. It looks really annoying.\n\n37:25 - Jorge Lewis \nOkay, but now it's still airing. I don't know. Look, if I do this, that should stop airing. Well, no, without your thing.\n\n37:32 - Biwas bhandari \nI want to learn this. Why is it... Okay, let's try...\n\n37:37 - Jorge Lewis \nOkay, so...\n\n37:53 - Jorge Lewis \nBro, I see exactly why so we're checking if it's not if it's null if it's null Then we're going to do nothing. We still go through with this. So Right here. We should be doing We should be returning an empty list. Oh That way we stop going through this function Okay Okay, so yes, that was why. See, if I said, okay, let me just do this here, I would have forgotten that we should be doing this proper error checking.\n\n38:31 - Jorge Lewis \nOh, yeah.\n\n38:33 - Jorge Lewis \nAnd sometimes you want to move fast, but sometimes it's better to write good code. There's a balance.\n\n38:45 - Jorge Lewis \nI do the same. Sometimes I will add a question mark even though I should be error checking.\n\n38:52 - Jorge Lewis \nOkay, so this is returning the new post, so we'll go back to where it's been called, which was, where was it being called?\n\n39:00 - Jorge Lewis \nYeah, here.\n\n39:02 - Biwas bhandari \nHere?\n\n39:05 - Jorge Lewis \nHere.\n\n39:08 - Jorge Lewis \nLet me just close all the tabs, because I'm lost. Do we have the, I start always from the page.spelt, and then the server file that's calling it. Then we can go down here. So this is the main function that we're running. We're fetching this. If anything happens and it errors, it's just going to return an empty list. So I think, actually, this one, we fixed the other function, not this one. So yeah, there's a lot of try-catch. Oh, man. No, no, no. No more try-catches. I hereby ban you to try and catch.\n\n39:44 - Jorge Lewis \nYeah, okay. So, okay. You're, you're doing it.\n\n39:46 - Biwas bhandari \nOh, what is it? Bad practice. Yeah.\n\n39:51 - Jorge Lewis \nSo, so what was the, okay. So for the try and catch, what do you, what do you think you're going to catch? Like, uh, what's the thought process? What are you worried that my error that we're trying to catch?\n\n40:02 - Biwas bhandari \nUm, sometimes we can just, uh, uh, I mean, uh, wrong username and password. So it will just generate another.\n\n40:15 - Jorge Lewis \nLet's go step by step. So over time, at the very start, if you're a very beginner, try and catch this faster. But at my level, when you understand how to do error checking, it's very fast. I'm not good. Nazif can do this probably in a second. It's going to take me at least a minute or two.\n\n40:35 - Jorge Lewis \nSo for fetch functions, if there's no response, it'll be a null, right? I think. Or no, it'll be an empty response. It'll give this as something. So if there's, if it's not okay, is this correct by the way? I don't know the best practice, like for, if we're checking if it's okay. I know there's.\n\n41:04 - Jorge Lewis \nCause I think there's, there's a lot of ways to check if the response did well. Let me, I'm asking co-pilot. Let's see. Yeah, it should be fine. Okay, so we're just checking if it's not okay. Error. Parse the...\n\n41:25 - Jorge Lewis \nYep.\n\n41:28 - Jorge Lewis \nNew... Whoa. This is data, data, data.\n\n41:34 - Biwas bhandari \nIs there...\n\n41:36 - Biwas bhandari \nNo, we can just change this.\n\n41:46 - Jorge Lewis \nSo I think an easier way of doing this, or a cleaner way of doing this is, now don't throw any heat, but that. Nope, not that.\n\n42:00 - Unidentified Speaker \nOkay.\n\n42:02 - Jorge Lewis \nWait, it's saying not okay.\n\n42:07 - Jorge Lewis \nWhat is this post data object that I'm, this one here? Where is it? Sorry?\n\n42:15 - Biwas bhandari \nThat's the type for post.\n\n42:17 - Biwas bhandari \nYep. Did you make it yourself?\n\n42:19 - Jorge Lewis \nYeah.\n\n42:20 - Jorge Lewis \nIs it exactly the same as when you return?\n\n42:25 - Biwas bhandari \nYeah. I first check the response and make it. Okay.\n\n42:30 - Jorge Lewis"}
02:07:11,585 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,587 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: one here? Where is it? Sorry?\n\n42:15 - Biwas bhandari \nThat\'s the type for post.\n\n42:17 - Biwas bhandari \nYep. Did you make it yourself?\n\n42:19 - Jorge Lewis \nYeah.\n\n42:20 - Jorge Lewis \nIs it exactly the same as when you return?\n\n42:25 - Biwas bhandari \nYeah. I first check the response and make it. Okay.\n\n42:30 - Jorge Lewis \nSo, so if it, like if it\'s, if it\'s exactly the same, then we can do, we can return this data as posts as a list of posts, I believe. Um, Oh, wait, no, this is JSON, so we can do it. So I\'m trying to, so the benefit of TypeScript is typing, getting the types. So that\'s what I\'m trying to do here because, I mean, in the end here, you are getting the type as a list of posts. But I\'m trying to figure out if there\'s a better way to do it. Usually, this is something that we should be learning in general, kind of learning how to do types.\n\n43:24 - Jorge Lewis \nFor example, Nazif, he\'s the most experienced web developer on our team. If he can look at our code and say, ew, then we need to improve it. That\'s always what I think of Of course, if I\'m working on a project that\'s not going to exist tomorrow, then it doesn\'t matter, but the idea is that you learn it so that when you make a very fast project, it should be natural.\n\n43:50 - Jorge Lewis \nSo if, should this actually be, if it\'s exactly the same, we can cast this here. Can we not, or?\n\n43:59 - Jorge Lewis \nI wanna see, actually, let\'s, I just wanna see. So I wanna, I want to see what is actually, what that looks like, Can I, can you run that?\n\n44:29 - Jorge Lewis \nOh, wait, I don\'t think we\'ve set up the, I don\'t know if it\'ll actually run yet. Let\'s, let\'s, okay, let\'s, let\'s come back here. Okay, we\'ll come back here to fix all the types and make this code cleaner, but for now we\'ll finish connecting it up. Okay, so we\'re, we\'re calling, fetch, although we don\'t need a return fetch since fetch is a void, so we\'re not returning anything here actually. We actually don\'t even need to store it as a variable. Why are we storing void, right? Okay, so let\'s continue down this chain. So actually, I think this should work. We need to call it now. So we go into a page file and Here, let\'s find a button to attach. Let me run it locally as well, so I don\'t have to. Actually, I can see your screen. So I\'m going to ask you to just swap to the web view every now and then.\n\n45:24 - Jorge Lewis \nSo we\'re here. Where can I add the button? Let\'s add the button inside Data Table. Because if you look at the web view right now, on Chrome.\n\n45:42 - Jorge Lewis \nlike if you look at the web on like the web the front end yeah like like on your browser okay well now you can\'t see it anymore but what how it is is okay let me oh I didn\'t finish cleaning up the code previously I left a try-catch somewhere Okay, let\'s fix the try-catches.\n\n46:14 - Biwas bhandari \nCome back to me.\n\n46:42 - Jorge Lewis \nYou there?\n\n46:50 - Biwas bhandari \nYou there?\n\n47:01 - Jorge Lewis \nHello, hello?\n\n47:04 - Biwas bhandari \nYeah, hello?\n\n47:06 - Biwas bhandari \nYou there?\n\n47:08 - Biwas bhandari \nYeah.\n\n47:09 - Biwas bhandari \nOkay, cool.\n\n47:16 - Jorge Lewis \nSo, oh yeah, so what I was doing, I just finished removing the try catch, because I forgot to remove the catch part. So now I should an error, I don\'t think so.\n\n47:54 - Biwas bhandari \nDid it call it?\n\n48:00 - Jorge Lewis \nOkay, nice. Okay, so if you see the filter using ID or something, we wanna add the button on the right of that.\n\n48:10 - Jorge Lewis \nYeah, I wanna add it on the right of that. So inside the code, what is that? Okay, here, I found the component. So this is the component that is Oh, you stopped following me.\n\n48:26 - Unidentified Speaker \nOkay.\n\n48:26 - Jorge Lewis \nYeah. So this here is the input component. So this is a flex. Let\'s make it a flex row and then add it here. So we can add a button, Shadestand button with an on click.\n\n48:39 - Biwas bhandari \nOh, you are using Shadestand.\n\n48:43 - Biwas bhandari \nI\'m using what?\n\n48:45 - Jorge Lewis \nShadestand.\n\n48:47 - Jorge Lewis \nYeah, yeah, yeah. This is all Shadestand here.\n\n48:53 - Jorge Lewis \nAnd then inside here, what do we call it?\n\n49:01 - Unidentified Speaker \nDon\'t spam.\n\n49:06 - Jorge Lewis \nI don\'t want to get my Read.AI account banned for spam. So here we\'re going to call the function for fetchPost\n######################\nOutput:'}
02:07:11,587 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,589 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "one here? Where is it? Sorry?\n\n42:15 - Biwas bhandari \nThat's the type for post.\n\n42:17 - Biwas bhandari \nYep. Did you make it yourself?\n\n42:19 - Jorge Lewis \nYeah.\n\n42:20 - Jorge Lewis \nIs it exactly the same as when you return?\n\n42:25 - Biwas bhandari \nYeah. I first check the response and make it. Okay.\n\n42:30 - Jorge Lewis \nSo, so if it, like if it's, if it's exactly the same, then we can do, we can return this data as posts as a list of posts, I believe. Um, Oh, wait, no, this is JSON, so we can do it. So I'm trying to, so the benefit of TypeScript is typing, getting the types. So that's what I'm trying to do here because, I mean, in the end here, you are getting the type as a list of posts. But I'm trying to figure out if there's a better way to do it. Usually, this is something that we should be learning in general, kind of learning how to do types.\n\n43:24 - Jorge Lewis \nFor example, Nazif, he's the most experienced web developer on our team. If he can look at our code and say, ew, then we need to improve it. That's always what I think of Of course, if I'm working on a project that's not going to exist tomorrow, then it doesn't matter, but the idea is that you learn it so that when you make a very fast project, it should be natural.\n\n43:50 - Jorge Lewis \nSo if, should this actually be, if it's exactly the same, we can cast this here. Can we not, or?\n\n43:59 - Jorge Lewis \nI wanna see, actually, let's, I just wanna see. So I wanna, I want to see what is actually, what that looks like, Can I, can you run that?\n\n44:29 - Jorge Lewis \nOh, wait, I don't think we've set up the, I don't know if it'll actually run yet. Let's, let's, okay, let's, let's come back here. Okay, we'll come back here to fix all the types and make this code cleaner, but for now we'll finish connecting it up. Okay, so we're, we're calling, fetch, although we don't need a return fetch since fetch is a void, so we're not returning anything here actually. We actually don't even need to store it as a variable. Why are we storing void, right? Okay, so let's continue down this chain. So actually, I think this should work. We need to call it now. So we go into a page file and Here, let's find a button to attach. Let me run it locally as well, so I don't have to. Actually, I can see your screen. So I'm going to ask you to just swap to the web view every now and then.\n\n45:24 - Jorge Lewis \nSo we're here. Where can I add the button? Let's add the button inside Data Table. Because if you look at the web view right now, on Chrome.\n\n45:42 - Jorge Lewis \nlike if you look at the web on like the web the front end yeah like like on your browser okay well now you can't see it anymore but what how it is is okay let me oh I didn't finish cleaning up the code previously I left a try-catch somewhere Okay, let's fix the try-catches.\n\n46:14 - Biwas bhandari \nCome back to me.\n\n46:42 - Jorge Lewis \nYou there?\n\n46:50 - Biwas bhandari \nYou there?\n\n47:01 - Jorge Lewis \nHello, hello?\n\n47:04 - Biwas bhandari \nYeah, hello?\n\n47:06 - Biwas bhandari \nYou there?\n\n47:08 - Biwas bhandari \nYeah.\n\n47:09 - Biwas bhandari \nOkay, cool.\n\n47:16 - Jorge Lewis \nSo, oh yeah, so what I was doing, I just finished removing the try catch, because I forgot to remove the catch part. So now I should an error, I don't think so.\n\n47:54 - Biwas bhandari \nDid it call it?\n\n48:00 - Jorge Lewis \nOkay, nice. Okay, so if you see the filter using ID or something, we wanna add the button on the right of that.\n\n48:10 - Jorge Lewis \nYeah, I wanna add it on the right of that. So inside the code, what is that? Okay, here, I found the component. So this is the component that is Oh, you stopped following me.\n\n48:26 - Unidentified Speaker \nOkay.\n\n48:26 - Jorge Lewis \nYeah. So this here is the input component. So this is a flex. Let's make it a flex row and then add it here. So we can add a button, Shadestand button with an on click.\n\n48:39 - Biwas bhandari \nOh, you are using Shadestand.\n\n48:43 - Biwas bhandari \nI'm using what?\n\n48:45 - Jorge Lewis \nShadestand.\n\n48:47 - Jorge Lewis \nYeah, yeah, yeah. This is all Shadestand here.\n\n48:53 - Jorge Lewis \nAnd then inside here, what do we call it?\n\n49:01 - Unidentified Speaker \nDon't spam.\n\n49:06 - Jorge Lewis \nI don't want to get my Read.AI account banned for spam. So here we're going to call the function for fetchPost"}
02:07:11,628 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,629 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: using what?\n\n48:45 - Jorge Lewis \nShadestand.\n\n48:47 - Jorge Lewis \nYeah, yeah, yeah. This is all Shadestand here.\n\n48:53 - Jorge Lewis \nAnd then inside here, what do we call it?\n\n49:01 - Unidentified Speaker \nDon\'t spam.\n\n49:06 - Jorge Lewis \nI don\'t want to get my Read.AI account banned for spam. So here we\'re going to call the function for fetchPostAndEvaluate. So we create that up here. We\'ll do, yeah, okay, thank you very much. Ha ha, Copilot.\n\n49:31 - Jorge Lewis \nBut this is actually wrong, so see, that\'s why Copilot can\'t save you. It maybe saves you a lot of time, but this should actually, like, if you don\'t understand any of the code, then you\'ll be totally lost. This should be fetch, post, and evaluate. So this is the endpoint that we\'re trying to access through the page server file right here, so this one. And you do that by doing question mark slash to reach this end point here. Post, sure. I mean, we\'re not returning anything, so post works. I think it makes it more simple, actually.\n\n50:05 - Jorge Lewis \nAnd then string of filter value, we don\'t need to pass it anything. So what if we don\'t pass it anything? Can I just not pass it? All right. I think that works.\n\n50:18 - Jorge Lewis \nWe can just log the data, sure. I added a console log for me. Thank you. Okay, so now it should work, I think. Let\'s try it.\n\n50:26 - Biwas bhandari \nLet\'s give it a go.\n\n50:43 - Jorge Lewis \nOkay, so it did call it properly. So let\'s check out the object.\n\n50:49 - Biwas bhandari \nI think we need to remove that. Sorry? Giving us this error. It\'s OK.\n\n51:19 - Jorge Lewis \nform actions expects form encoded data okay so what do we do is we\'re going to google it go ahead all right this is all you I\'ll guide you with my experience but I want to see how you solve this this bug so we have a bug that we\'ve never seen before pretend pretend like i\'ve never seen it and now you\'re going to tackle it I think I just need to now if it will But you have hot reload on, you don\'t have to refresh the page.\n\n52:08 - Biwas bhandari \nOkay.\n\n52:09 - Jorge Lewis \nAll right, so my tip here is you have no clue what this is saying, what the error is saying. The error tells you the problem, but you have no clue what it\'s telling you. So what do you do? You Google. Or you try GPT? I would use probably Google.\n\n52:30 - Jorge Lewis \nThe annoying thing with Spellkit is that there\'s not a lot of resources on it, and it\'s a really new framework, so try GPT isn\'t as good with Spellkit as it is something like React.\n\n52:44 - Jorge Lewis \nYou\'re using Tmux or?\n\n52:50 - Jorge Lewis \nAre you able to copy and paste from the terminal?\n\n52:52 - Biwas bhandari \nOkay, yeah.\n\n53:07 - Jorge Lewis \nOh, I see the issue. I think.\n\n53:10 - Biwas bhandari \nYeah.\n\n53:13 - Jorge Lewis \nWait, but... Yeah, I mean...\n\n53:20 - Jorge Lewis \nOkay, I\'m gonna fix the issue to check if I understand it. Okay, can you run it again? I think I fixed it.\n\n53:29 - Biwas bhandari \nDon\'t look at the code.\n\n53:40 - Jorge Lewis \nDid it not work?\n\n53:44 - Jorge Lewis \nIt shouldn\'t even be, why is it erroring now?\n\n53:50 - Jorge Lewis \nHave you refreshed the page?\n\n53:56 - Biwas bhandari \nNo.\n\n54:21 - Jorge Lewis \nOh, is it saying? Yeah, what the heck?\n\n54:36 - Biwas bhandari \nYeah, it\'s lagging.\n\n54:43 - Biwas bhandari \nAlright, I\'m gonna go get a coffee, I\'ll be right back.\n\n54:48 - Jorge Lewis \nYou can continue working on this for now.\n\n54:54 - Jorge Lewis \nBy the way, I can see, I know the error now, but I\'ll leave you to solve it, you got this. If you want a hint, it\'s related to how the...\n\n55:07 - Jorge Lewis \nIt\'s related to, it\'s not SpokeKit specific, it\'s post versus get requests. Like what\'s the difference and how do they work? So that\'s their tip.\n\n55:36 - Biwas bhandari \nlaptop is lagging what? What?\n\n56:05 - Biwas bhandari \nYeah, hello?\n\n57:20 - Biwas bhandari \nYeah.\n\n58:11 - Jorge Lewis \nHave you found it?\n\n58:14 - Biwas bhandari \nNo idea.\n\n58:15 - Jorge Lewis \nAll right, so it\'s not actually, it\'s a very expected bug, like it\'s not unexpected. So how I would go about this problem is I would read the error. So let\'s go back to the error.\n\n58:33 - Jorge Lewis \nOkay.\n\n58:36 - Jorge Lewis \nSo the error says, Svelte kit form actions Okay, yeah. I think I got it. But...\n\n59:32 - Jorge Lewis\n######################\nOutput:'}
02:07:11,629 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,632 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "using what?\n\n48:45 - Jorge Lewis \nShadestand.\n\n48:47 - Jorge Lewis \nYeah, yeah, yeah. This is all Shadestand here.\n\n48:53 - Jorge Lewis \nAnd then inside here, what do we call it?\n\n49:01 - Unidentified Speaker \nDon't spam.\n\n49:06 - Jorge Lewis \nI don't want to get my Read.AI account banned for spam. So here we're going to call the function for fetchPostAndEvaluate. So we create that up here. We'll do, yeah, okay, thank you very much. Ha ha, Copilot.\n\n49:31 - Jorge Lewis \nBut this is actually wrong, so see, that's why Copilot can't save you. It maybe saves you a lot of time, but this should actually, like, if you don't understand any of the code, then you'll be totally lost. This should be fetch, post, and evaluate. So this is the endpoint that we're trying to access through the page server file right here, so this one. And you do that by doing question mark slash to reach this end point here. Post, sure. I mean, we're not returning anything, so post works. I think it makes it more simple, actually.\n\n50:05 - Jorge Lewis \nAnd then string of filter value, we don't need to pass it anything. So what if we don't pass it anything? Can I just not pass it? All right. I think that works.\n\n50:18 - Jorge Lewis \nWe can just log the data, sure. I added a console log for me. Thank you. Okay, so now it should work, I think. Let's try it.\n\n50:26 - Biwas bhandari \nLet's give it a go.\n\n50:43 - Jorge Lewis \nOkay, so it did call it properly. So let's check out the object.\n\n50:49 - Biwas bhandari \nI think we need to remove that. Sorry? Giving us this error. It's OK.\n\n51:19 - Jorge Lewis \nform actions expects form encoded data okay so what do we do is we're going to google it go ahead all right this is all you I'll guide you with my experience but I want to see how you solve this this bug so we have a bug that we've never seen before pretend pretend like i've never seen it and now you're going to tackle it I think I just need to now if it will But you have hot reload on, you don't have to refresh the page.\n\n52:08 - Biwas bhandari \nOkay.\n\n52:09 - Jorge Lewis \nAll right, so my tip here is you have no clue what this is saying, what the error is saying. The error tells you the problem, but you have no clue what it's telling you. So what do you do? You Google. Or you try GPT? I would use probably Google.\n\n52:30 - Jorge Lewis \nThe annoying thing with Spellkit is that there's not a lot of resources on it, and it's a really new framework, so try GPT isn't as good with Spellkit as it is something like React.\n\n52:44 - Jorge Lewis \nYou're using Tmux or?\n\n52:50 - Jorge Lewis \nAre you able to copy and paste from the terminal?\n\n52:52 - Biwas bhandari \nOkay, yeah.\n\n53:07 - Jorge Lewis \nOh, I see the issue. I think.\n\n53:10 - Biwas bhandari \nYeah.\n\n53:13 - Jorge Lewis \nWait, but... Yeah, I mean...\n\n53:20 - Jorge Lewis \nOkay, I'm gonna fix the issue to check if I understand it. Okay, can you run it again? I think I fixed it.\n\n53:29 - Biwas bhandari \nDon't look at the code.\n\n53:40 - Jorge Lewis \nDid it not work?\n\n53:44 - Jorge Lewis \nIt shouldn't even be, why is it erroring now?\n\n53:50 - Jorge Lewis \nHave you refreshed the page?\n\n53:56 - Biwas bhandari \nNo.\n\n54:21 - Jorge Lewis \nOh, is it saying? Yeah, what the heck?\n\n54:36 - Biwas bhandari \nYeah, it's lagging.\n\n54:43 - Biwas bhandari \nAlright, I'm gonna go get a coffee, I'll be right back.\n\n54:48 - Jorge Lewis \nYou can continue working on this for now.\n\n54:54 - Jorge Lewis \nBy the way, I can see, I know the error now, but I'll leave you to solve it, you got this. If you want a hint, it's related to how the...\n\n55:07 - Jorge Lewis \nIt's related to, it's not SpokeKit specific, it's post versus get requests. Like what's the difference and how do they work? So that's their tip.\n\n55:36 - Biwas bhandari \nlaptop is lagging what? What?\n\n56:05 - Biwas bhandari \nYeah, hello?\n\n57:20 - Biwas bhandari \nYeah.\n\n58:11 - Jorge Lewis \nHave you found it?\n\n58:14 - Biwas bhandari \nNo idea.\n\n58:15 - Jorge Lewis \nAll right, so it's not actually, it's a very expected bug, like it's not unexpected. So how I would go about this problem is I would read the error. So let's go back to the error.\n\n58:33 - Jorge Lewis \nOkay.\n\n58:36 - Jorge Lewis \nSo the error says, Svelte kit form actions Okay, yeah. I think I got it. But...\n\n59:32 - Jorge Lewis"}
02:07:11,669 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,670 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: idea.\n\n58:15 - Jorge Lewis \nAll right, so it\'s not actually, it\'s a very expected bug, like it\'s not unexpected. So how I would go about this problem is I would read the error. So let\'s go back to the error.\n\n58:33 - Jorge Lewis \nOkay.\n\n58:36 - Jorge Lewis \nSo the error says, Svelte kit form actions Okay, yeah. I think I got it. But...\n\n59:32 - Jorge Lewis \nSo it\'s going to be very hard for you to solve this.\n\n59:44 - Jorge Lewis \nif you don\'t understand to a basic how, the basics of how posts and get requests work, and kind of how those work. So what we\'re saying is a header is kind of to define how the, kind of defines the rest of the function, I guess you could say.\n\n1:00:13 - Jorge Lewis \nprovides additional, like it tells the server or whatever we\'re interacting with about the request that we\'re making. So in this case, the content type we\'re telling it is we\'re passing you this type of content.\n\n1:00:30 - Jorge Lewis \nBut we\'re in a post request, so we\'re telling it, so beforehand, by the way, so this is actually supposed to be JSON. We\'re usually passing it JSON, but the reason So we\'re telling it, OK, the content type we\'re going to pass you is JSON. But we\'re not passing it at anything, because I deleted the body request, the body of it. We told it, hey, we\'re going to pass you JSON, but we\'re not returning any JSON.\n\n1:00:59 - Jorge Lewis \nSo there\'s either we can just give it empty data, and that works. Or I believe there\'s a content type that\'s kind of empty.\n\n1:01:10 - Jorge Lewis \nLet me see. So the option is, we don\'t need to pass it any data. We don\'t need to pass the function anything. So either we can pass it something empty, or we could figure out if there\'s a content type that says empty. But I don\'t think there is. So what we\'ll do is we\'ll pass it an empty JSON.\n\n1:01:38 - Jorge Lewis \nUm, and now it should work. Oh yeah.\n\n1:01:44 - Jorge Lewis \nActually, there might be an error, but not with the actual, uh, request.\n\n1:01:53 - Unidentified Speaker \nOkay.\n\n1:01:56 - Jorge Lewis \nHave you, have you clicked it again?\n\n1:02:00 - Biwas bhandari \nYeah.\n\n1:02:00 - Jorge Lewis \nI was from the error was like 26 minutes, three 26.\n\n1:02:08 - Biwas bhandari \nYeah, now it\'s 27 already.\n\n1:02:14 - Jorge Lewis \nSo click the fetch post, yeah?\n\n1:02:18 - Jorge Lewis \nIs that the error? That\'s the old error.\n\n1:02:21 - Biwas bhandari \nIs it being clicked or not?\n\n1:02:27 - Biwas bhandari \nWhy isn\'t it not being clicked?\n\n1:02:30 - Jorge Lewis \nThat maybe means there\'s no error.\n\n1:02:36 - Jorge Lewis \nOr nothing\'s happening, or what?\n\n1:02:43 - Jorge Lewis \nOh my, your laptop is just...\n\n1:02:50 - Jorge Lewis \nOkay, but yeah, the get request is... The post request is getting sent. Let\'s retry.\n\n1:03:00 - Unidentified Speaker \nYou there?\n\n1:03:26 - Jorge Lewis \nSorry, what\'s it doing?\n\n1:03:35 - Jorge Lewis \nIt sounds like your laptop\'s having a heart attack.\n\n1:03:49 - Biwas bhandari \nYou alive?\n\n1:03:50 - Jorge Lewis \nYeah, your laptop sounds like it\'s dying.\n\n1:04:29 - Jorge Lewis \nYou alive?\n\n1:04:39 - Jorge Lewis \nBro, your microphone sounds like it\'s dead.\n\n1:04:45 - Jorge Lewis \nHello?\n\n1:04:47 - Biwas bhandari \nYeah?\n\n1:04:58 - Jorge Lewis \nIt\'s also frozen or? 99.\n\n1:04:59 - Biwas bhandari \nRestart your laptop. Yeah, the laptop is.\n\n1:06:53 - Jorge Lewis \nI get the skirt when I want I get the skirt when I want Don\'t tell your mother you\'re wrong, mother.\n\n1:07:11 - Jorge Lewis \nMother, she\'s got it all wrong. She got my threatened all over. She got my threatened all over. When I\'m in your town, press down, hit me up. When I\'m in your town, press down, hit me up. Only if you down, then you slurp the deer. At the work, girl, I\'ll be back for the rear. Hate when I creep, and your song will wake me up. Fake like I\'m sleepin\' on down while I be up. Monkey on my back, and I\'ll walk a hundred miles. Get with the nigga, feel safe when he smile. Love the confusion, the vibe, and the Back in my mouth, back in my mouth, yo.\n\n1:07:58 - Jorge Lewis \nYo.\n######################\nOutput:'}
02:07:11,670 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,673 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "idea.\n\n58:15 - Jorge Lewis \nAll right, so it's not actually, it's a very expected bug, like it's not unexpected. So how I would go about this problem is I would read the error. So let's go back to the error.\n\n58:33 - Jorge Lewis \nOkay.\n\n58:36 - Jorge Lewis \nSo the error says, Svelte kit form actions Okay, yeah. I think I got it. But...\n\n59:32 - Jorge Lewis \nSo it's going to be very hard for you to solve this.\n\n59:44 - Jorge Lewis \nif you don't understand to a basic how, the basics of how posts and get requests work, and kind of how those work. So what we're saying is a header is kind of to define how the, kind of defines the rest of the function, I guess you could say.\n\n1:00:13 - Jorge Lewis \nprovides additional, like it tells the server or whatever we're interacting with about the request that we're making. So in this case, the content type we're telling it is we're passing you this type of content.\n\n1:00:30 - Jorge Lewis \nBut we're in a post request, so we're telling it, so beforehand, by the way, so this is actually supposed to be JSON. We're usually passing it JSON, but the reason So we're telling it, OK, the content type we're going to pass you is JSON. But we're not passing it at anything, because I deleted the body request, the body of it. We told it, hey, we're going to pass you JSON, but we're not returning any JSON.\n\n1:00:59 - Jorge Lewis \nSo there's either we can just give it empty data, and that works. Or I believe there's a content type that's kind of empty.\n\n1:01:10 - Jorge Lewis \nLet me see. So the option is, we don't need to pass it any data. We don't need to pass the function anything. So either we can pass it something empty, or we could figure out if there's a content type that says empty. But I don't think there is. So what we'll do is we'll pass it an empty JSON.\n\n1:01:38 - Jorge Lewis \nUm, and now it should work. Oh yeah.\n\n1:01:44 - Jorge Lewis \nActually, there might be an error, but not with the actual, uh, request.\n\n1:01:53 - Unidentified Speaker \nOkay.\n\n1:01:56 - Jorge Lewis \nHave you, have you clicked it again?\n\n1:02:00 - Biwas bhandari \nYeah.\n\n1:02:00 - Jorge Lewis \nI was from the error was like 26 minutes, three 26.\n\n1:02:08 - Biwas bhandari \nYeah, now it's 27 already.\n\n1:02:14 - Jorge Lewis \nSo click the fetch post, yeah?\n\n1:02:18 - Jorge Lewis \nIs that the error? That's the old error.\n\n1:02:21 - Biwas bhandari \nIs it being clicked or not?\n\n1:02:27 - Biwas bhandari \nWhy isn't it not being clicked?\n\n1:02:30 - Jorge Lewis \nThat maybe means there's no error.\n\n1:02:36 - Jorge Lewis \nOr nothing's happening, or what?\n\n1:02:43 - Jorge Lewis \nOh my, your laptop is just...\n\n1:02:50 - Jorge Lewis \nOkay, but yeah, the get request is... The post request is getting sent. Let's retry.\n\n1:03:00 - Unidentified Speaker \nYou there?\n\n1:03:26 - Jorge Lewis \nSorry, what's it doing?\n\n1:03:35 - Jorge Lewis \nIt sounds like your laptop's having a heart attack.\n\n1:03:49 - Biwas bhandari \nYou alive?\n\n1:03:50 - Jorge Lewis \nYeah, your laptop sounds like it's dying.\n\n1:04:29 - Jorge Lewis \nYou alive?\n\n1:04:39 - Jorge Lewis \nBro, your microphone sounds like it's dead.\n\n1:04:45 - Jorge Lewis \nHello?\n\n1:04:47 - Biwas bhandari \nYeah?\n\n1:04:58 - Jorge Lewis \nIt's also frozen or? 99.\n\n1:04:59 - Biwas bhandari \nRestart your laptop. Yeah, the laptop is.\n\n1:06:53 - Jorge Lewis \nI get the skirt when I want I get the skirt when I want Don't tell your mother you're wrong, mother.\n\n1:07:11 - Jorge Lewis \nMother, she's got it all wrong. She got my threatened all over. She got my threatened all over. When I'm in your town, press down, hit me up. When I'm in your town, press down, hit me up. Only if you down, then you slurp the deer. At the work, girl, I'll be back for the rear. Hate when I creep, and your song will wake me up. Fake like I'm sleepin' on down while I be up. Monkey on my back, and I'll walk a hundred miles. Get with the nigga, feel safe when he smile. Love the confusion, the vibe, and the Back in my mouth, back in my mouth, yo.\n\n1:07:58 - Jorge Lewis \nYo."}
02:07:11,681 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,682 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Get with the nigga, feel safe when he smile. Love the confusion, the vibe, and the Back in my mouth, back in my mouth, yo.\n\n1:07:58 - Jorge Lewis \nYo.\n######################\nOutput:'}
02:07:11,683 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,685 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'Get with the nigga, feel safe when he smile. Love the confusion, the vibe, and the Back in my mouth, back in my mouth, yo.\n\n1:07:58 - Jorge Lewis \nYo.'}
02:07:11,750 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,752 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'re unhelpfully putting out narratives that, you know, you can improve productivity by 70% with AI. Yes, if you want to use builder.ai and you say, give me a clone of Instagram or give me a clone of Facebook, yeah, it\'s an established pattern. As soon as you want to do something innovative, I\'m sorry, you can\'t just go to software, hey, make this thing. It might come one day. I was watching an article last night saying that there\'s a multi-agent coding solution which has a test bot, a reviewer bot, coder bot, and they\'re giving each other\'s feedback. And it keeps on getting, the coder will keep on getting it wrong and keeps on getting feedback until it gets it right. And so that\'s quite clever.\n\n5:34 - Jorge Lewis \nWas it called Devon?\n\n5:36 - Cuan Mulligan \nCould have been, yeah.\n\n5:38 - Cuan Mulligan \nDevon\'s very impressive.\n\n5:40 - Cuan Mulligan \nBut again, a lot of these things are happy path, right? So that\'s why I was asking you guys, what are you seeing? And yes, obviously you don\'t have the inefficiencies of large organizations, But I do wonder whether there is a conversation to say, like, how do we manage expectations? Like, could we use AI to manage expectations saying, hey, you know, not that it\'s of any value whatsoever if you know what you\'re talking about, but to say, hey, there was 7,000 lines of code written today. There was 15 check-ins. There was five issues. There\'s even something similar to that. We know something\'s happening. I don\'t put in particular, that doesn\'t mean the needle has shifted, but it does mean activity has happened. So that would be hygiene. I think the evolution beyond that is to say, I was reading a good article about the difference between a roadmap, a product roadmap, and a flight plan. Flight plan has to change the dynamics in the weather and stuff like this. And you have the ultimate goal, but your path there is evolutionary, and it responds to dynamic changes and stuff. So I built myself an hour if we did our first startup years ago, about 15 ago, which was building an AI project manager. We got gazumped by JIRA and Azure DevOps and stuff like that because we just couldn\'t because we had to use our underlying database and people wouldn\'t let go of Jira and DevOps because they were so integral to the solution. But people said, well, can you give us the bot? We really like that. So there\'s a lot of thinking that we\'ve done. And again, another experiment to figure out is after we built this is, could we build an AI project manager to lighten your load from an account management point of view? I think there\'s some really interesting stuff we could do there. But that\'s another phase. So on this in particular, you asked some really interesting questions yesterday. And some of them makes total sense. And some of them felt that we weren\'t aligned, or I don\'t understand how the coding requires that sort of information. I think I had a preconceived idea of it working a different way. So can you sort of give me an update of where we are with stuff and how close we are to getting it in the next release so I can play with stuff?\n\n7:57 - Jorge Lewis \nYeah, how about I run you down and where the architectures are right now so you get an idea of what it\'s doing behind the scenes.\n\n8:07 - Cuan Mulligan \nJust give me two seconds. I want to see if Arif and JP are around. They might like to hear this.\n\n8:34 - Cuan Mulligan \nI\'ll just give them this meeting link. If they can join, they can join. Um, okay, cool.\n\n8:44 - Jorge Lewis \nI\'m trying to try to post the, I had a drawing. Let me find it there.\n\n9:11 - Jorge Lewis \nOr I think of, yeah. Okay, so can you open up that PDF you sent? It should have been an image, but yeah.\n\n9:27 - Jorge Lewis \nLet me just screenshot and send it. Where did you put it?\n\n9:32 - Cuan Mulligan \nBecause I just got read...\n\n9:38 - Cuan Mulligan \nI\'m hearing beeps but I\'m not entirely sure where this is.\n\n9:41 - Jorge Lewis \nIt\'s in the dap channel.\n\n9:45 - Cuan Mulligan \nIn this? Or in... No, it\'s in adapt. Sorry, it\'s in that. Okay, fine.\n\n9:54 - Cuan Mulligan \nIs it?\n\n9:57 - Cuan Mulligan \nYes, supervisor, entry coach, entity, supervisor, select next, speaker, tool, coach. What\'s that drawing platform that you use?\n\n10:08 - Jorge Lewis \nThe one that you share?\n\n10:10 - Unidentified Speaker \nExcalibur.\n\n10:13 - Cuan Mulligan \nYeah, that would probably be better in there because it\'s typing some of the text.\n\n10:18 - Jorge Lewis \nYeah, sometimes when I\'m really in the brain, like the whiteboard, I need the drawing.\n\n10:23 - Cuan Mulligan \nYeah, I get that. But okay, let\'s not start with the architecture because that\'s an implied thing that you need. Hey, JP.\n\n10:33 - Cuan Mulligan \nGood morning.\n\n10:34 - Cuan Mulligan \nHey, so where are we with the actual feature set going backwards from the customer, from us? When do you think I\'ll\n######################\nOutput:'}
02:07:11,752 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,755 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'re unhelpfully putting out narratives that, you know, you can improve productivity by 70% with AI. Yes, if you want to use builder.ai and you say, give me a clone of Instagram or give me a clone of Facebook, yeah, it's an established pattern. As soon as you want to do something innovative, I'm sorry, you can't just go to software, hey, make this thing. It might come one day. I was watching an article last night saying that there's a multi-agent coding solution which has a test bot, a reviewer bot, coder bot, and they're giving each other's feedback. And it keeps on getting, the coder will keep on getting it wrong and keeps on getting feedback until it gets it right. And so that's quite clever.\n\n5:34 - Jorge Lewis \nWas it called Devon?\n\n5:36 - Cuan Mulligan \nCould have been, yeah.\n\n5:38 - Cuan Mulligan \nDevon's very impressive.\n\n5:40 - Cuan Mulligan \nBut again, a lot of these things are happy path, right? So that's why I was asking you guys, what are you seeing? And yes, obviously you don't have the inefficiencies of large organizations, But I do wonder whether there is a conversation to say, like, how do we manage expectations? Like, could we use AI to manage expectations saying, hey, you know, not that it's of any value whatsoever if you know what you're talking about, but to say, hey, there was 7,000 lines of code written today. There was 15 check-ins. There was five issues. There's even something similar to that. We know something's happening. I don't put in particular, that doesn't mean the needle has shifted, but it does mean activity has happened. So that would be hygiene. I think the evolution beyond that is to say, I was reading a good article about the difference between a roadmap, a product roadmap, and a flight plan. Flight plan has to change the dynamics in the weather and stuff like this. And you have the ultimate goal, but your path there is evolutionary, and it responds to dynamic changes and stuff. So I built myself an hour if we did our first startup years ago, about 15 ago, which was building an AI project manager. We got gazumped by JIRA and Azure DevOps and stuff like that because we just couldn't because we had to use our underlying database and people wouldn't let go of Jira and DevOps because they were so integral to the solution. But people said, well, can you give us the bot? We really like that. So there's a lot of thinking that we've done. And again, another experiment to figure out is after we built this is, could we build an AI project manager to lighten your load from an account management point of view? I think there's some really interesting stuff we could do there. But that's another phase. So on this in particular, you asked some really interesting questions yesterday. And some of them makes total sense. And some of them felt that we weren't aligned, or I don't understand how the coding requires that sort of information. I think I had a preconceived idea of it working a different way. So can you sort of give me an update of where we are with stuff and how close we are to getting it in the next release so I can play with stuff?\n\n7:57 - Jorge Lewis \nYeah, how about I run you down and where the architectures are right now so you get an idea of what it's doing behind the scenes.\n\n8:07 - Cuan Mulligan \nJust give me two seconds. I want to see if Arif and JP are around. They might like to hear this.\n\n8:34 - Cuan Mulligan \nI'll just give them this meeting link. If they can join, they can join. Um, okay, cool.\n\n8:44 - Jorge Lewis \nI'm trying to try to post the, I had a drawing. Let me find it there.\n\n9:11 - Jorge Lewis \nOr I think of, yeah. Okay, so can you open up that PDF you sent? It should have been an image, but yeah.\n\n9:27 - Jorge Lewis \nLet me just screenshot and send it. Where did you put it?\n\n9:32 - Cuan Mulligan \nBecause I just got read...\n\n9:38 - Cuan Mulligan \nI'm hearing beeps but I'm not entirely sure where this is.\n\n9:41 - Jorge Lewis \nIt's in the dap channel.\n\n9:45 - Cuan Mulligan \nIn this? Or in... No, it's in adapt. Sorry, it's in that. Okay, fine.\n\n9:54 - Cuan Mulligan \nIs it?\n\n9:57 - Cuan Mulligan \nYes, supervisor, entry coach, entity, supervisor, select next, speaker, tool, coach. What's that drawing platform that you use?\n\n10:08 - Jorge Lewis \nThe one that you share?\n\n10:10 - Unidentified Speaker \nExcalibur.\n\n10:13 - Cuan Mulligan \nYeah, that would probably be better in there because it's typing some of the text.\n\n10:18 - Jorge Lewis \nYeah, sometimes when I'm really in the brain, like the whiteboard, I need the drawing.\n\n10:23 - Cuan Mulligan \nYeah, I get that. But okay, let's not start with the architecture because that's an implied thing that you need. Hey, JP.\n\n10:33 - Cuan Mulligan \nGood morning.\n\n10:34 - Cuan Mulligan \nHey, so where are we with the actual feature set going backwards from the customer, from us? When do you think I'll"}
02:07:11,782 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,783 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,785 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: in the brain, like the whiteboard, I need the drawing.\n\n10:23 - Cuan Mulligan \nYeah, I get that. But okay, let\'s not start with the architecture because that\'s an implied thing that you need. Hey, JP.\n\n10:33 - Cuan Mulligan \nGood morning.\n\n10:34 - Cuan Mulligan \nHey, so where are we with the actual feature set going backwards from the customer, from us? When do you think I\'ll be able to play with it? We talked about a potential demo today. Is that feasible?\n\n10:48 - Jorge Lewis \nSo what I\'m doing currently right now is trying to, so from Friday when we had the demo, what we had was the check-in bot specifically. So behind the scenes, they\'re split up into different modules. They all have the same persona, so they act like the same person. But behind the scenes, they\'re each specialized to do one thing. And in our case, I was working on the check-in bot. The check-in bot is comprised of the coach, data analyst, and the supervisor.\n\n11:20 - Jorge Lewis \nSo the supervisor, his job is to gather the data, then he sends it to the coach to provide coaching on the data that\'s given from the user, and then he can get further analysis from the data analyst if he wants or not. And then it goes back to the supervisor to repeat the loop. So that\'s the check-in thing, and that\'s what I was working on.\n\n11:38 - Cuan Mulligan \nSo this is a multi-agent system?\n\n11:41 - Jorge Lewis \nYeah, it\'s evolved into that. I don\'t know if we\'re going to call it... It is a multi-agent system, but I don\'t know if we\'re going to call that because an agent is often, it can be defined as someone like with a persona. So we don\'t know yet. Behind the scene, it is very similar.\n\n11:58 - Unidentified Speaker \nOkay.\n\n12:00 - Cuan Mulligan \nSo a multi-agent system to the customer or the user would have an experience of working with three different people. But under the hood, what we\'re saying is it\'s one unified person experience, but there will be sub bots, sub agents, let\'s say, call them sub agents that are working together to achieve a particular outcome. And so you\'re niching up the capability into really thin slices so they can become experts in that one thing.\n\n12:25 - Jorge Lewis \nExactly. Yeah. And the reason so by Friday, what I had was I had one bot that had the capabilities to retrieve data from the database, get data from the database, and then provide some some coaching. But the performance wasn\'t that good. The one guy couldn\'t do it all. So we went into this route of delegating.\n\n12:44 - Cuan Mulligan \nWhen you say performance, that\'s got multiple interpretations in terms of speed, in terms of accuracy, in terms of experience.\n\n12:53 - Jorge Lewis \nOkay, so speed is actually a very annoying thing because right now it\'s currently quite slow, but for the performance I was referring to was just the quality of Alpine didn\'t think it would be able to become I feel like if we modified the prompt, it wouldn\'t be able to, it\'s not flexible because we tell it to change one aspect. Let\'s say for your coaching, do this, do more of this. Then having it integrated within the entire bot, it\'s not a good idea because by separating them, we get to independently improve one of the modules. It would mess up the function calling quite a bit because function calling is surprisingly pretty difficult for language models. So separating that is usually the best idea. It gives us the most scalability in terms of capabilities and quality.\n\n13:43 - Cuan Mulligan \nOkay. So for me, there\'s a milestone I\'m looking for, which is to have a version of the bot that we can interact with, pull in data from a profile, and then changing the foundational prompt so that that bot can change its responses to certain scenarios. Because that, I think, is going to give us more learning in terms of all the different types of edge cases of how people engage with it. So that was what I thought we\'d have on Friday, and then it was talked about potentially today. So when do you think we can actually play with that?\n\n14:25 - Jorge Lewis \nLet me keep going into the progress we\'ve made so far, and then we can wrap that. So from Friday, that\'s what we had, the single bot trying to do everything. And then over the weekend, I worked on it. And by that point, we had the UI completed, but the reactivity was terrible. You\'d have to refresh the page every new message just because of the way the backend was connected. Over the weekend, we fixed the reactivity, and I implemented the multi-agent architecture.\n\n14:50 - Cuan Mulligan \nSo just some feedback, by the way, especially to myself and Arif, because we are quite technical, giving us that level of granularity, saying, hey, listen, we\'ve got this bit done, but the reactivity was really, really shit. That\'s fine. We would then understand that that\'s a realistic issue and a glass ceiling you\'ve hit, and then say, hey, while functionally it hasn\'t improved, we\'ve re-architected it to sort out the reactivity blocker. That\'s huge progress for us. Even though it\'s not getting us to the ultimate goal that we thought we\'d get on the Friday, but we can understand that level of reality with dealing with software. It goes backwards and forwards and left and right\n######################\nOutput:'}
02:07:11,785 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,788 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "in the brain, like the whiteboard, I need the drawing.\n\n10:23 - Cuan Mulligan \nYeah, I get that. But okay, let's not start with the architecture because that's an implied thing that you need. Hey, JP.\n\n10:33 - Cuan Mulligan \nGood morning.\n\n10:34 - Cuan Mulligan \nHey, so where are we with the actual feature set going backwards from the customer, from us? When do you think I'll be able to play with it? We talked about a potential demo today. Is that feasible?\n\n10:48 - Jorge Lewis \nSo what I'm doing currently right now is trying to, so from Friday when we had the demo, what we had was the check-in bot specifically. So behind the scenes, they're split up into different modules. They all have the same persona, so they act like the same person. But behind the scenes, they're each specialized to do one thing. And in our case, I was working on the check-in bot. The check-in bot is comprised of the coach, data analyst, and the supervisor.\n\n11:20 - Jorge Lewis \nSo the supervisor, his job is to gather the data, then he sends it to the coach to provide coaching on the data that's given from the user, and then he can get further analysis from the data analyst if he wants or not. And then it goes back to the supervisor to repeat the loop. So that's the check-in thing, and that's what I was working on.\n\n11:38 - Cuan Mulligan \nSo this is a multi-agent system?\n\n11:41 - Jorge Lewis \nYeah, it's evolved into that. I don't know if we're going to call it... It is a multi-agent system, but I don't know if we're going to call that because an agent is often, it can be defined as someone like with a persona. So we don't know yet. Behind the scene, it is very similar.\n\n11:58 - Unidentified Speaker \nOkay.\n\n12:00 - Cuan Mulligan \nSo a multi-agent system to the customer or the user would have an experience of working with three different people. But under the hood, what we're saying is it's one unified person experience, but there will be sub bots, sub agents, let's say, call them sub agents that are working together to achieve a particular outcome. And so you're niching up the capability into really thin slices so they can become experts in that one thing.\n\n12:25 - Jorge Lewis \nExactly. Yeah. And the reason so by Friday, what I had was I had one bot that had the capabilities to retrieve data from the database, get data from the database, and then provide some some coaching. But the performance wasn't that good. The one guy couldn't do it all. So we went into this route of delegating.\n\n12:44 - Cuan Mulligan \nWhen you say performance, that's got multiple interpretations in terms of speed, in terms of accuracy, in terms of experience.\n\n12:53 - Jorge Lewis \nOkay, so speed is actually a very annoying thing because right now it's currently quite slow, but for the performance I was referring to was just the quality of Alpine didn't think it would be able to become I feel like if we modified the prompt, it wouldn't be able to, it's not flexible because we tell it to change one aspect. Let's say for your coaching, do this, do more of this. Then having it integrated within the entire bot, it's not a good idea because by separating them, we get to independently improve one of the modules. It would mess up the function calling quite a bit because function calling is surprisingly pretty difficult for language models. So separating that is usually the best idea. It gives us the most scalability in terms of capabilities and quality.\n\n13:43 - Cuan Mulligan \nOkay. So for me, there's a milestone I'm looking for, which is to have a version of the bot that we can interact with, pull in data from a profile, and then changing the foundational prompt so that that bot can change its responses to certain scenarios. Because that, I think, is going to give us more learning in terms of all the different types of edge cases of how people engage with it. So that was what I thought we'd have on Friday, and then it was talked about potentially today. So when do you think we can actually play with that?\n\n14:25 - Jorge Lewis \nLet me keep going into the progress we've made so far, and then we can wrap that. So from Friday, that's what we had, the single bot trying to do everything. And then over the weekend, I worked on it. And by that point, we had the UI completed, but the reactivity was terrible. You'd have to refresh the page every new message just because of the way the backend was connected. Over the weekend, we fixed the reactivity, and I implemented the multi-agent architecture.\n\n14:50 - Cuan Mulligan \nSo just some feedback, by the way, especially to myself and Arif, because we are quite technical, giving us that level of granularity, saying, hey, listen, we've got this bit done, but the reactivity was really, really shit. That's fine. We would then understand that that's a realistic issue and a glass ceiling you've hit, and then say, hey, while functionally it hasn't improved, we've re-architected it to sort out the reactivity blocker. That's huge progress for us. Even though it's not getting us to the ultimate goal that we thought we'd get on the Friday, but we can understand that level of reality with dealing with software. It goes backwards and forwards and left and right"}
02:07:11,790 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: comms management & adapt demo \nTue, Jun 11, 2024\n\n0:00 - Jorge Lewis \nCan you hear me?\n\n0:01 - Unidentified Speaker \nCool.\n\n0:01 - Cuan Mulligan \nYeah.\n\n0:03 - Cuan Mulligan \nCool. So let\'s tease apart what\'s going on. So where are we? Obviously, there\'s the self-inflicted pressure in terms of we had expectations and hitting that. Is that where you or is there something in how I am or we\'re engaging with you that\'s putting more pressure on you guys or?\n\n0:21 - Jorge Lewis \nSo there\'s definitely the self-inflicting part, which is we want to impress. That\'s on us. The solution to that one is just start sharing our dev chats to you. And that way, we have no pressure. It\'s just you\'re getting the full behind the scenes. But then there\'s also, I mean, if that solution solves the other issue, which is that you\'re constantly asking for updates, then that\'s a perfect solution. But if it still doesn\'t, you require more like daily explanations in terms of what\'s going on. And then it does feel like, it feels like you\'re expecting deliverables every day.\n\n0:58 - Cuan Mulligan \nSo definitely not expecting deliverables every day.\n\n1:04 - Cuan Mulligan \nI\'ve been doing product delivery for 25 years, so I know that\'s unrealistic and it\'s not useful.\n\n1:11 - Cuan Mulligan \nI think when, for example, if I said to you, I\'m going to give you 10 pounds on Friday, And then on Wednesday, I know that that\'s not going to happen. Me telling you straight away and saying, listen, sorry, that\'s not going to happen. Here\'s why. Here\'s what we\'re going to do about it. And here\'s when you\'re going to get it. That\'s what I mean by managing expectations. So as soon as you understand that something can\'t be done, it\'s setting those expectations of, hey, And let\'s be candid about it. This isn\'t going to happen. Here\'s why. I get software changes. But this is when you are going to get it. And this is what our confidence is. Yes, obviously, things can slip again. We get that. But at the moment, from my point of view, there\'s a huge amount of trust on my side that I\'m assuming you guys are working. I\'m not seeing stuff that I can play with. I feel from my side, I\'ve tried to lean in and say, OK, Let\'s get this sort of visual contract of saying, I want to be able to do this. When can I get this thing? And that was supposed to be last Friday. And listen, I get stuff happens, and it\'s technology. It\'s never 100%.\n\n2:28 - Jorge Lewis \nI think you\'re hitting on a really big point that\'s a part of this, where we don\'t acknowledge that you understand that software has delays. And we\'re trying to probably make up for it or compensate for it with just delays. So knowing that you truly do understand how software development is, then it does give us a lot more freedom to just say, yeah, this is what went wrong.\n\n2:59 - Cuan Mulligan \nI think that\'s more real. I\'m not saying it\'s particularly any more pleasant, but it\'s more real. And I think it understands, you know, hey, we thought this plugin was going to work. It doesn\'t work at all. And we\'ve lost a day. It\'s not great, but shit happens. And we get that.\n\n3:18 - Jorge Lewis \nAnd it\'s better that you know that rather than us just saying, oh, sorry, it\'s going to be a day later.\n\n3:23 - Cuan Mulligan \nYeah, because it\'s just like, Were you on the beach? Did you get hung over? Like, there\'s no, there\'s like, we don\'t know. Right. And obviously I\'m speaking with JP and ARIF every day. And they\'re like going, Hey, cause when you tell me there\'s a demo on Friday, I\'m obviously relaying that boat to the other ADAPT founders, but also to ARIF and JP, because they want to know how it\'s going and what my point of view is and what you guys are doing before they put their money into it. And, You know, I mean, listen, I think we both recognize that you guys are not a 400 person company. And that\'s one of the reasons why we like you guys, because we like your personality, we like your drive. And that\'s why we\'d be interested in sort of partnering with you, because I think we can significantly add value to you guys and help you elevate your game. I think there\'s a three-year window to do something really, really interesting together before AI changes the landscape altogether and scares the shit out of everybody. But I think there\'s a short-term window to do something really interesting and impactful in the world with this tech. I just think we\'re fighting a tide of expectations. I was just on a webinar earlier on with ServiceNow, and they\'re unhelpfully putting out narratives that, you know, you can improve productivity by 70% with AI. Yes, if you want to use builder.ai and you say, give me a clone of Instagram or give me a clone of Facebook, yeah, it\'s an established pattern. As soon as you want to do something innovative, I\'m sorry, you can\'t just go to software, hey, make this thing. It might come one day. I was watching an article last night saying\n######################\nOutput:'}
02:07:11,790 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,795 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "comms management & adapt demo \nTue, Jun 11, 2024\n\n0:00 - Jorge Lewis \nCan you hear me?\n\n0:01 - Unidentified Speaker \nCool.\n\n0:01 - Cuan Mulligan \nYeah.\n\n0:03 - Cuan Mulligan \nCool. So let's tease apart what's going on. So where are we? Obviously, there's the self-inflicted pressure in terms of we had expectations and hitting that. Is that where you or is there something in how I am or we're engaging with you that's putting more pressure on you guys or?\n\n0:21 - Jorge Lewis \nSo there's definitely the self-inflicting part, which is we want to impress. That's on us. The solution to that one is just start sharing our dev chats to you. And that way, we have no pressure. It's just you're getting the full behind the scenes. But then there's also, I mean, if that solution solves the other issue, which is that you're constantly asking for updates, then that's a perfect solution. But if it still doesn't, you require more like daily explanations in terms of what's going on. And then it does feel like, it feels like you're expecting deliverables every day.\n\n0:58 - Cuan Mulligan \nSo definitely not expecting deliverables every day.\n\n1:04 - Cuan Mulligan \nI've been doing product delivery for 25 years, so I know that's unrealistic and it's not useful.\n\n1:11 - Cuan Mulligan \nI think when, for example, if I said to you, I'm going to give you 10 pounds on Friday, And then on Wednesday, I know that that's not going to happen. Me telling you straight away and saying, listen, sorry, that's not going to happen. Here's why. Here's what we're going to do about it. And here's when you're going to get it. That's what I mean by managing expectations. So as soon as you understand that something can't be done, it's setting those expectations of, hey, And let's be candid about it. This isn't going to happen. Here's why. I get software changes. But this is when you are going to get it. And this is what our confidence is. Yes, obviously, things can slip again. We get that. But at the moment, from my point of view, there's a huge amount of trust on my side that I'm assuming you guys are working. I'm not seeing stuff that I can play with. I feel from my side, I've tried to lean in and say, OK, Let's get this sort of visual contract of saying, I want to be able to do this. When can I get this thing? And that was supposed to be last Friday. And listen, I get stuff happens, and it's technology. It's never 100%.\n\n2:28 - Jorge Lewis \nI think you're hitting on a really big point that's a part of this, where we don't acknowledge that you understand that software has delays. And we're trying to probably make up for it or compensate for it with just delays. So knowing that you truly do understand how software development is, then it does give us a lot more freedom to just say, yeah, this is what went wrong.\n\n2:59 - Cuan Mulligan \nI think that's more real. I'm not saying it's particularly any more pleasant, but it's more real. And I think it understands, you know, hey, we thought this plugin was going to work. It doesn't work at all. And we've lost a day. It's not great, but shit happens. And we get that.\n\n3:18 - Jorge Lewis \nAnd it's better that you know that rather than us just saying, oh, sorry, it's going to be a day later.\n\n3:23 - Cuan Mulligan \nYeah, because it's just like, Were you on the beach? Did you get hung over? Like, there's no, there's like, we don't know. Right. And obviously I'm speaking with JP and ARIF every day. And they're like going, Hey, cause when you tell me there's a demo on Friday, I'm obviously relaying that boat to the other ADAPT founders, but also to ARIF and JP, because they want to know how it's going and what my point of view is and what you guys are doing before they put their money into it. And, You know, I mean, listen, I think we both recognize that you guys are not a 400 person company. And that's one of the reasons why we like you guys, because we like your personality, we like your drive. And that's why we'd be interested in sort of partnering with you, because I think we can significantly add value to you guys and help you elevate your game. I think there's a three-year window to do something really, really interesting together before AI changes the landscape altogether and scares the shit out of everybody. But I think there's a short-term window to do something really interesting and impactful in the world with this tech. I just think we're fighting a tide of expectations. I was just on a webinar earlier on with ServiceNow, and they're unhelpfully putting out narratives that, you know, you can improve productivity by 70% with AI. Yes, if you want to use builder.ai and you say, give me a clone of Instagram or give me a clone of Facebook, yeah, it's an established pattern. As soon as you want to do something innovative, I'm sorry, you can't just go to software, hey, make this thing. It might come one day. I was watching an article last night saying"}
02:07:11,796 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,798 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: fine. We would then understand that that\'s a realistic issue and a glass ceiling you\'ve hit, and then say, hey, while functionally it hasn\'t improved, we\'ve re-architected it to sort out the reactivity blocker. That\'s huge progress for us. Even though it\'s not getting us to the ultimate goal that we thought we\'d get on the Friday, but we can understand that level of reality with dealing with software. It goes backwards and forwards and left and right. So having that transparency, I think, is really, really useful. JP, what about you? I know you\'re a clever guy, but I don\'t know whether that level of feedback is something that you\'d want or not.\n\n15:38 - Jonathan Phillips \nI pick up little bits, and I learn as I go.\n\n15:47 - Jorge Lewis \nOver the weekend, we improved the reactivity and then I improved the bot system. By yesterday, I had finished what I was happy with in terms of architecture. Today, my plan was to fix the prompts to make them more aware of their environment. So pretty much tell them, hey, you\'re part of the system. You shouldn\'t have your own persona. You\'re part of this guy, right? All these things, and just improving the prompts here and there.\n\n16:12 - Jorge Lewis \nBy the way, to kind of give you some more context regarding prompting, there\'s one type of prompt, which is for the persona. And then there\'s another one that\'s for functionality. The functionality one is behind the scenes. The persona one is going to be editable by you guys. But I\'m trying to figure out a way if we can make even the ones behind the scenes editable for you guys so you can iterate those ones as well.\n\n16:34 - Cuan Mulligan \nI think that would be certainly from an Intelli agent one for JP. I feel that\'s probably where you\'re going to need to go because we can\'t specify the functionality to the end degree. So having an interface that we can modify the functionality while also the style of the personality, I think having those two levers would be super useful.\n\n16:58 - Unidentified Speaker \nYeah.\n\n16:59 - Cuan Mulligan \nOn the sort of the agents and having sub-agents, is there a sense that If the supervisor buzz goes left, even if you want to go right, you must listen to them. Is there a hierarchy of opinion, for want of a better word, in the bus? Otherwise, how are they going to stop? I think you called it a circle jerk. How do they not just get into a really nasty cycle of saying nice things to each other?\n\n17:27 - Jorge Lewis \nSo in the one for Adapt, there\'s not much hierarchy. The flow is usually very simple. So it\'s going to be gather the data, coach on the data. To coach on the data, he can pull more insights from a data analyst or not. But for something like for JP\'s one where it\'s sometimes have a circle jerk, just you have to allocate who has priority and who doesn\'t. But on top of that, the supervisor in Adapt\'s case is also the check-in manager, but his main role isn\'t to manage the conversation. His main role is to get data and then pass it on to the coach to provide coaching. So we could further add another layer on top, which is just a pure supervisor just saying, this is how the conversation should look like, If it looks like there\'s a power struggle, do this or this.\n\n18:20 - Jorge Lewis \nSo if we go into the graph.\n\n18:28 - Jorge Lewis \nI shall send it. Can I send images here?\n\n18:32 - Cuan Mulligan \nI should.\n\n18:39 - Jorge Lewis \nHow do I?\n\n18:43 - Jorge Lewis \nOh, let me let me screen show you this.\n\n18:51 - Jorge Lewis \nCan you guys see it? Yep. So at the top here, we have the supervisor, but this is also- Can AI rewrite the writing?\n\n19:07 - Jorge Lewis \nWe can. Let\'s see. Thank you. Thank you. See, I did try doing it in Excalibur, but sometimes I need the drawing of the whiteboard. Let\'s see. I know there\'s AI features.\n\n19:26 - Jorge Lewis \nNo. Oh, wireframe to code.\n\n19:30 - Jorge Lewis \nAnyways, supervisor is going to start us off. So if the user says, let\'s check in, the supervisor starts off. The supervisor and the coach both have a tool to select the next speaker. This is to pass the baton to the next person.\n\n19:50 - Cuan Mulligan \nIs that the next sub-agent?\n\n19:54 - Cuan Mulligan \nThe this one or we say speaker is that the person that the sub agent bot that\'s engaging with the customer person.\n\n20:01 - Jorge Lewis \nThis, this, this is a tool. So tools are, are just for the language models to call and for us to manage behind the scenes, like to allocate who should speak next. Right. So the blue ones are tools. They\'re not real people. This one\'s also supposedly a tool, the entry. So let\'s just go step by step. So the first one is he can select, all right, we\'ve got some user data. Let\'s select the coach to speak next. So we\'ll start the coach off. This node here is just to introduce the coach to the scenario, saying, hey, we have this new data. Let\'s coach on it. And then we start into it. The coach can then select the next speaker, which could be the data guy or\n######################\nOutput:'}
02:07:11,798 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,802 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "fine. We would then understand that that's a realistic issue and a glass ceiling you've hit, and then say, hey, while functionally it hasn't improved, we've re-architected it to sort out the reactivity blocker. That's huge progress for us. Even though it's not getting us to the ultimate goal that we thought we'd get on the Friday, but we can understand that level of reality with dealing with software. It goes backwards and forwards and left and right. So having that transparency, I think, is really, really useful. JP, what about you? I know you're a clever guy, but I don't know whether that level of feedback is something that you'd want or not.\n\n15:38 - Jonathan Phillips \nI pick up little bits, and I learn as I go.\n\n15:47 - Jorge Lewis \nOver the weekend, we improved the reactivity and then I improved the bot system. By yesterday, I had finished what I was happy with in terms of architecture. Today, my plan was to fix the prompts to make them more aware of their environment. So pretty much tell them, hey, you're part of the system. You shouldn't have your own persona. You're part of this guy, right? All these things, and just improving the prompts here and there.\n\n16:12 - Jorge Lewis \nBy the way, to kind of give you some more context regarding prompting, there's one type of prompt, which is for the persona. And then there's another one that's for functionality. The functionality one is behind the scenes. The persona one is going to be editable by you guys. But I'm trying to figure out a way if we can make even the ones behind the scenes editable for you guys so you can iterate those ones as well.\n\n16:34 - Cuan Mulligan \nI think that would be certainly from an Intelli agent one for JP. I feel that's probably where you're going to need to go because we can't specify the functionality to the end degree. So having an interface that we can modify the functionality while also the style of the personality, I think having those two levers would be super useful.\n\n16:58 - Unidentified Speaker \nYeah.\n\n16:59 - Cuan Mulligan \nOn the sort of the agents and having sub-agents, is there a sense that If the supervisor buzz goes left, even if you want to go right, you must listen to them. Is there a hierarchy of opinion, for want of a better word, in the bus? Otherwise, how are they going to stop? I think you called it a circle jerk. How do they not just get into a really nasty cycle of saying nice things to each other?\n\n17:27 - Jorge Lewis \nSo in the one for Adapt, there's not much hierarchy. The flow is usually very simple. So it's going to be gather the data, coach on the data. To coach on the data, he can pull more insights from a data analyst or not. But for something like for JP's one where it's sometimes have a circle jerk, just you have to allocate who has priority and who doesn't. But on top of that, the supervisor in Adapt's case is also the check-in manager, but his main role isn't to manage the conversation. His main role is to get data and then pass it on to the coach to provide coaching. So we could further add another layer on top, which is just a pure supervisor just saying, this is how the conversation should look like, If it looks like there's a power struggle, do this or this.\n\n18:20 - Jorge Lewis \nSo if we go into the graph.\n\n18:28 - Jorge Lewis \nI shall send it. Can I send images here?\n\n18:32 - Cuan Mulligan \nI should.\n\n18:39 - Jorge Lewis \nHow do I?\n\n18:43 - Jorge Lewis \nOh, let me let me screen show you this.\n\n18:51 - Jorge Lewis \nCan you guys see it? Yep. So at the top here, we have the supervisor, but this is also- Can AI rewrite the writing?\n\n19:07 - Jorge Lewis \nWe can. Let's see. Thank you. Thank you. See, I did try doing it in Excalibur, but sometimes I need the drawing of the whiteboard. Let's see. I know there's AI features.\n\n19:26 - Jorge Lewis \nNo. Oh, wireframe to code.\n\n19:30 - Jorge Lewis \nAnyways, supervisor is going to start us off. So if the user says, let's check in, the supervisor starts off. The supervisor and the coach both have a tool to select the next speaker. This is to pass the baton to the next person.\n\n19:50 - Cuan Mulligan \nIs that the next sub-agent?\n\n19:54 - Cuan Mulligan \nThe this one or we say speaker is that the person that the sub agent bot that's engaging with the customer person.\n\n20:01 - Jorge Lewis \nThis, this, this is a tool. So tools are, are just for the language models to call and for us to manage behind the scenes, like to allocate who should speak next. Right. So the blue ones are tools. They're not real people. This one's also supposedly a tool, the entry. So let's just go step by step. So the first one is he can select, all right, we've got some user data. Let's select the coach to speak next. So we'll start the coach off. This node here is just to introduce the coach to the scenario, saying, hey, we have this new data. Let's coach on it. And then we start into it. The coach can then select the next speaker, which could be the data guy or"}
02:07:11,802 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,804 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: the entry. So let\'s just go step by step. So the first one is he can select, all right, we\'ve got some user data. Let\'s select the coach to speak next. So we\'ll start the coach off. This node here is just to introduce the coach to the scenario, saying, hey, we have this new data. Let\'s coach on it. And then we start into it. The coach can then select the next speaker, which could be the data guy or go back to the supervisor.\n\n20:44 - Jorge Lewis \nSo this entry node is also just telling the data guy the context of the conversation so far. The solid lines, by the way, are non-conditional. So anytime the conversation is at the data guy for one message, he gives a response, and it\'ll go directly back to the coach. The dotted lines are conditionals, depending on some factors. And then after the coach maybe makes some coaching, he hands it back to the supervisor, and we usually repeat.\n\n21:15 - Cuan Mulligan \nI\'m just going to hide my camera because I\'m going to start eating and I don\'t think any of you need to see it.\n\n21:20 - Jorge Lewis \nI mean, I wouldn\'t mind.\n\n21:23 - Jorge Lewis \nYes. So that does that make sense? Albeit the beautiful handwriting.\n\n21:29 - Cuan Mulligan \nYeah. I mean, it does. But I suppose the real challenge is in the nuance of testing it.\n\n21:38 - Cuan Mulligan \nBecause it all looks fine on paper.\n\n21:42 - Jorge Lewis \nWhen do you think we can actually start to like So let\'s so Jonas has been working on the front end side of things So this so this is you guys can still see my screen, right? Yeah. Yeah. So for example, I could select my chat and See, we had an issue this morning. I was working. I spent way too long trying to fix this issue. We\'re sending to the same messages, but, um, so yeah, we have the conversation going now, but I need to push the changes that I made today.\n\n22:13 - Cuan Mulligan \nCould you, could you explain this? I think it\'s really useful context for us. So that we can understand, for example, if you\'re doing normal software engineering and you say you pass in two variables, like two numbers, and the addition of the number is the function of the module, 1 plus should be equal to 2. It always will be. Obviously, LLMs and this sort of work is a bit more fragile in that way. It\'s not as canonical or categorical. Can you explain to us why it started producing double responses and how did you fix it? I think this will just go a long way for us to start understanding the realities of software engineering in this way, that it\'s not quite the same as building a website.\n\n22:55 - Jorge Lewis \nThis was actually not the language model. It was something related to the code, our code.\n\n23:02 - Cuan Mulligan \nOK. So the language model was giving you a single response, but for some reason you were displaying it twice?\n\n23:08 - Jorge Lewis \nUh, yeah, no, well, this, this is my, our side. So the right side is us. So this is me saying I\'m 24 years old.\n\n23:17 - Cuan Mulligan \nOkay. So the UI is doubling what you said.\n\n23:22 - Jorge Lewis \nNot even the UI. Behind the scenes as well, it was making two of the same messages. So for some reason, the bot would respond with one nice message. Perfect. But then the R side would keep putting two. And I finally fixed it. If this doesn\'t duplicate, I\'ve done it. And it didn\'t duplicate.\n\n23:42 - Jorge Lewis \nYes, so I think as soon as I push, I need to ask Jonas, because as soon as I push or merge my changes into the alpha branch, it\'ll be deployed. But I don\'t know if it\'ll work as is. So I need to check with Jonas on that one. But there\'s also, I don\'t know how good it looks at the moment, but let\'s take a look.\n\n24:01 - Jorge Lewis \nThere\'s the admin link somewhere. Let me find it.\n\n24:08 - Jorge Lewis \nWe\'ve separated the chat interface, or we\'ve made them into two separate projects so that, I mean, it doesn\'t make a difference on the user side, but for us, it makes it a lot easier to work with.\n\n24:20 - Cuan Mulligan \nNext task.\n\n24:26 - Jorge Lewis \nWhat should we do?\n\n24:44 - Cuan Mulligan \nEggs and bacon, Kevin? Eggs, bacon, avocado, six eggs. Six pieces of bacon and half an avocado.\n\n24:54 - Jorge Lewis \nSounds like...\n\n24:57 - Cuan Mulligan \nI can\'t find the link.\n\n25:02 - Cuan Mulligan \nIt is interesting, though, that compared to using chocolate-covered, cream-filled eclairs or profiteroles, You can\'t quite eat the same number of eggs.\n\n25:17 - Unidentified Speaker \nIt\'s amazing.\n\n25:23 - Jorge Lewis \nSo yes, the admin page looks like this now. So you can review the responses. So this is the top dropdown is for you to select which user you want to go through. So let\'s just say mine.\n\n25:35 - Jorge Lewis \nLet\'s say this response wasn\'t that good. You can click on it and you can select if it was a good or a bad response\n######################\nOutput:'}
02:07:11,804 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,807 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "the entry. So let's just go step by step. So the first one is he can select, all right, we've got some user data. Let's select the coach to speak next. So we'll start the coach off. This node here is just to introduce the coach to the scenario, saying, hey, we have this new data. Let's coach on it. And then we start into it. The coach can then select the next speaker, which could be the data guy or go back to the supervisor.\n\n20:44 - Jorge Lewis \nSo this entry node is also just telling the data guy the context of the conversation so far. The solid lines, by the way, are non-conditional. So anytime the conversation is at the data guy for one message, he gives a response, and it'll go directly back to the coach. The dotted lines are conditionals, depending on some factors. And then after the coach maybe makes some coaching, he hands it back to the supervisor, and we usually repeat.\n\n21:15 - Cuan Mulligan \nI'm just going to hide my camera because I'm going to start eating and I don't think any of you need to see it.\n\n21:20 - Jorge Lewis \nI mean, I wouldn't mind.\n\n21:23 - Jorge Lewis \nYes. So that does that make sense? Albeit the beautiful handwriting.\n\n21:29 - Cuan Mulligan \nYeah. I mean, it does. But I suppose the real challenge is in the nuance of testing it.\n\n21:38 - Cuan Mulligan \nBecause it all looks fine on paper.\n\n21:42 - Jorge Lewis \nWhen do you think we can actually start to like So let's so Jonas has been working on the front end side of things So this so this is you guys can still see my screen, right? Yeah. Yeah. So for example, I could select my chat and See, we had an issue this morning. I was working. I spent way too long trying to fix this issue. We're sending to the same messages, but, um, so yeah, we have the conversation going now, but I need to push the changes that I made today.\n\n22:13 - Cuan Mulligan \nCould you, could you explain this? I think it's really useful context for us. So that we can understand, for example, if you're doing normal software engineering and you say you pass in two variables, like two numbers, and the addition of the number is the function of the module, 1 plus should be equal to 2. It always will be. Obviously, LLMs and this sort of work is a bit more fragile in that way. It's not as canonical or categorical. Can you explain to us why it started producing double responses and how did you fix it? I think this will just go a long way for us to start understanding the realities of software engineering in this way, that it's not quite the same as building a website.\n\n22:55 - Jorge Lewis \nThis was actually not the language model. It was something related to the code, our code.\n\n23:02 - Cuan Mulligan \nOK. So the language model was giving you a single response, but for some reason you were displaying it twice?\n\n23:08 - Jorge Lewis \nUh, yeah, no, well, this, this is my, our side. So the right side is us. So this is me saying I'm 24 years old.\n\n23:17 - Cuan Mulligan \nOkay. So the UI is doubling what you said.\n\n23:22 - Jorge Lewis \nNot even the UI. Behind the scenes as well, it was making two of the same messages. So for some reason, the bot would respond with one nice message. Perfect. But then the R side would keep putting two. And I finally fixed it. If this doesn't duplicate, I've done it. And it didn't duplicate.\n\n23:42 - Jorge Lewis \nYes, so I think as soon as I push, I need to ask Jonas, because as soon as I push or merge my changes into the alpha branch, it'll be deployed. But I don't know if it'll work as is. So I need to check with Jonas on that one. But there's also, I don't know how good it looks at the moment, but let's take a look.\n\n24:01 - Jorge Lewis \nThere's the admin link somewhere. Let me find it.\n\n24:08 - Jorge Lewis \nWe've separated the chat interface, or we've made them into two separate projects so that, I mean, it doesn't make a difference on the user side, but for us, it makes it a lot easier to work with.\n\n24:20 - Cuan Mulligan \nNext task.\n\n24:26 - Jorge Lewis \nWhat should we do?\n\n24:44 - Cuan Mulligan \nEggs and bacon, Kevin? Eggs, bacon, avocado, six eggs. Six pieces of bacon and half an avocado.\n\n24:54 - Jorge Lewis \nSounds like...\n\n24:57 - Cuan Mulligan \nI can't find the link.\n\n25:02 - Cuan Mulligan \nIt is interesting, though, that compared to using chocolate-covered, cream-filled eclairs or profiteroles, You can't quite eat the same number of eggs.\n\n25:17 - Unidentified Speaker \nIt's amazing.\n\n25:23 - Jorge Lewis \nSo yes, the admin page looks like this now. So you can review the responses. So this is the top dropdown is for you to select which user you want to go through. So let's just say mine.\n\n25:35 - Jorge Lewis \nLet's say this response wasn't that good. You can click on it and you can select if it was a good or a bad response"}
02:07:11,830 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,832 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: eggs.\n\n25:17 - Unidentified Speaker \nIt\'s amazing.\n\n25:23 - Jorge Lewis \nSo yes, the admin page looks like this now. So you can review the responses. So this is the top dropdown is for you to select which user you want to go through. So let\'s just say mine.\n\n25:35 - Jorge Lewis \nLet\'s say this response wasn\'t that good. You can click on it and you can select if it was a good or a bad response. If it was good, it takes us to this page where it\'s just the form. So this was the response we deemed as impressive. What was good about it? Where should the conversation... I think this part, I think we were supposed to ask you, but we didn\'t. Should a good, impressive response have a following field here?\n\n26:01 - Cuan Mulligan \nLet me ask JP and Ira from this, actually. So the reason why I came up with this idea was not just the response, but where do you want the conversation to go after that response? Is there a particular direction you need to take it away from where you think you\'re going at the moment?\n\n26:18 - Cuan Mulligan \nFor example, let\'s say someone says, oh, I didn\'t do my walk because my kid went to hospital. And they said, oh, I\'m really concerned to hear about that. That\'s a good response. But where do you actually go next? Do you go back to the previous point? Or would you say, actually, given this is a highly sensitive topic, do you actually now want to say, shall we pause this check-in and come back to you tomorrow?\n\n26:46 - Cuan Mulligan \nIt\'s that sort of stuff. That was the point of the follow-on. So you\'ve got the immediate response, which is good, which could include a follow-on. But if it doesn\'t explicitly have one, the follow-on was, as a person, this is where I would go next.\n\n27:01 - Arif Harbott \nYeah, OK. That makes sense.\n\n27:03 - Arif Harbott \nYeah, it\'s probably.\n\n27:07 - Cuan Mulligan \nUp to the user you pose the question. Yeah, I think you\'re right. Are you okay to carry on today? Or do you want to just pick this up again tomorrow with the clear ahead? Yeah Because I\'d imagine doing a marketing thing there\'s particular Sort of non-logical next steps that jp goes. Uh, if I saw that I\'d want to go left or I\'m like, oh fuck I would have gone, right?\n\n27:29 - Jonathan Phillips \nYeah, that\'s the communication of your expertise completely that that\'s it\'s imperative that we direct them so that they don\'t decide what to do themselves, so to speak.\n\n27:47 - Jorge Lewis \nLanguage models are very, what they do is predict the next set of text. They\'re very bad at skipping a step and going from the results to Like, if they\'re given the endpoint, it\'s very hard for them to try to reach it through messages. They usually just go straight to that point. So we\'d have to, we should gather the data right here, we should gather the data, and we\'d later end up finding a way to make it in a way that the language model would enjoy using.\n\n28:19 - Cuan Mulligan \nIs it possible, for example, let\'s say you\'re running a workshop, And that workshop could be broken down into, have you ever heard of a business model canvas workshop?\n\n28:31 - Jorge Lewis \nCanvas workshop for the business model.\n\n28:34 - Cuan Mulligan \nYes, a business model canvas is like a 12 box diagram of different steps. And there\'s a particular, there\'s an effective way that you travel through those steps. And so is there a way that we can create those steps that they must be finished. And then the steps must happen in that order, but the journey to go from step one to two is what\'s organic, but you have to get to two before you can start talking about three. Yeah.\n\n29:05 - Jorge Lewis \nYeah. That\'s actually something similar to what we\'re doing for, for these sub modules. Cool.\n\n29:16 - Jorge Lewis \nSo this function here is to select the next speaker within the check-in cycle. So I\'ve given it the standard check-in cycle looks like, The supervisor, he requests user tracking data, the coach gets it from the supervisor, the data analyst gets user from the tracking data, and then tries to provide useful insights. The coach uses this to create some coaching, and it\'s back to the supervisor. So giving it an example of the orders that we want is usually enough for it to understand how things go. And then sometimes, depending on how well we prompt and the examples we give it, it\'ll be able to do it pretty well, in between, I mean. Going from one to another, it does a good job.\n\n29:56 - Cuan Mulligan \nThose sort of five points, I\'m sorry, I think from an IntelliAsian point of view, being able to see those and add to them or change the order of them, I think is going to be imperative.\n\n30:07 - Jonathan Phillips \nSorry, excuse my ignorance, where are they sitting, those five points, as far as, it\'s in the code, obviously, at the moment, but where, as far as a user interface, is it part of a hard-coded prompt or is it something that\'s modifiable?\n\n30:25 - Jorge Lewis \nSo it\'s modifiable. We can bring it to the front end and bring it here. But this is\n######################\nOutput:'}
02:07:11,832 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,835 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "eggs.\n\n25:17 - Unidentified Speaker \nIt's amazing.\n\n25:23 - Jorge Lewis \nSo yes, the admin page looks like this now. So you can review the responses. So this is the top dropdown is for you to select which user you want to go through. So let's just say mine.\n\n25:35 - Jorge Lewis \nLet's say this response wasn't that good. You can click on it and you can select if it was a good or a bad response. If it was good, it takes us to this page where it's just the form. So this was the response we deemed as impressive. What was good about it? Where should the conversation... I think this part, I think we were supposed to ask you, but we didn't. Should a good, impressive response have a following field here?\n\n26:01 - Cuan Mulligan \nLet me ask JP and Ira from this, actually. So the reason why I came up with this idea was not just the response, but where do you want the conversation to go after that response? Is there a particular direction you need to take it away from where you think you're going at the moment?\n\n26:18 - Cuan Mulligan \nFor example, let's say someone says, oh, I didn't do my walk because my kid went to hospital. And they said, oh, I'm really concerned to hear about that. That's a good response. But where do you actually go next? Do you go back to the previous point? Or would you say, actually, given this is a highly sensitive topic, do you actually now want to say, shall we pause this check-in and come back to you tomorrow?\n\n26:46 - Cuan Mulligan \nIt's that sort of stuff. That was the point of the follow-on. So you've got the immediate response, which is good, which could include a follow-on. But if it doesn't explicitly have one, the follow-on was, as a person, this is where I would go next.\n\n27:01 - Arif Harbott \nYeah, OK. That makes sense.\n\n27:03 - Arif Harbott \nYeah, it's probably.\n\n27:07 - Cuan Mulligan \nUp to the user you pose the question. Yeah, I think you're right. Are you okay to carry on today? Or do you want to just pick this up again tomorrow with the clear ahead? Yeah Because I'd imagine doing a marketing thing there's particular Sort of non-logical next steps that jp goes. Uh, if I saw that I'd want to go left or I'm like, oh fuck I would have gone, right?\n\n27:29 - Jonathan Phillips \nYeah, that's the communication of your expertise completely that that's it's imperative that we direct them so that they don't decide what to do themselves, so to speak.\n\n27:47 - Jorge Lewis \nLanguage models are very, what they do is predict the next set of text. They're very bad at skipping a step and going from the results to Like, if they're given the endpoint, it's very hard for them to try to reach it through messages. They usually just go straight to that point. So we'd have to, we should gather the data right here, we should gather the data, and we'd later end up finding a way to make it in a way that the language model would enjoy using.\n\n28:19 - Cuan Mulligan \nIs it possible, for example, let's say you're running a workshop, And that workshop could be broken down into, have you ever heard of a business model canvas workshop?\n\n28:31 - Jorge Lewis \nCanvas workshop for the business model.\n\n28:34 - Cuan Mulligan \nYes, a business model canvas is like a 12 box diagram of different steps. And there's a particular, there's an effective way that you travel through those steps. And so is there a way that we can create those steps that they must be finished. And then the steps must happen in that order, but the journey to go from step one to two is what's organic, but you have to get to two before you can start talking about three. Yeah.\n\n29:05 - Jorge Lewis \nYeah. That's actually something similar to what we're doing for, for these sub modules. Cool.\n\n29:16 - Jorge Lewis \nSo this function here is to select the next speaker within the check-in cycle. So I've given it the standard check-in cycle looks like, The supervisor, he requests user tracking data, the coach gets it from the supervisor, the data analyst gets user from the tracking data, and then tries to provide useful insights. The coach uses this to create some coaching, and it's back to the supervisor. So giving it an example of the orders that we want is usually enough for it to understand how things go. And then sometimes, depending on how well we prompt and the examples we give it, it'll be able to do it pretty well, in between, I mean. Going from one to another, it does a good job.\n\n29:56 - Cuan Mulligan \nThose sort of five points, I'm sorry, I think from an IntelliAsian point of view, being able to see those and add to them or change the order of them, I think is going to be imperative.\n\n30:07 - Jonathan Phillips \nSorry, excuse my ignorance, where are they sitting, those five points, as far as, it's in the code, obviously, at the moment, but where, as far as a user interface, is it part of a hard-coded prompt or is it something that's modifiable?\n\n30:25 - Jorge Lewis \nSo it's modifiable. We can bring it to the front end and bring it here. But this is"}
02:07:11,884 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,885 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: is going to be imperative.\n\n30:07 - Jonathan Phillips \nSorry, excuse my ignorance, where are they sitting, those five points, as far as, it\'s in the code, obviously, at the moment, but where, as far as a user interface, is it part of a hard-coded prompt or is it something that\'s modifiable?\n\n30:25 - Jorge Lewis \nSo it\'s modifiable. We can bring it to the front end and bring it here. But this is a simple one where there\'s no variables. But something more complicated like this one where we have variables like a profile ID. Or actually, let me go. Yeah.\n\n30:53 - Cuan Mulligan \nI want all of these aspects of a prompt to be in an admin screen that we can tweak and modify.\n\n30:59 - Jorge Lewis \nYeah, so we need to figure out the best way to do that because it\'s obviously possible. Just what\'s the best way? I\'m thinking the best way is just to use So you can see here, we give it a variable. This is a variable here, userInfo. And at the bottom, we give it as the actual value.\n\n31:22 - Cuan Mulligan \nSorry, I can\'t see your screen anymore. Is it just me? No, I\'ve lost it as well.\n\n31:27 - Jorge Lewis \nOh, for just now or the whole time?\n\n31:30 - Cuan Mulligan \nNo, just now. Just now.\n\n31:34 - Jorge Lewis \nLet me know.\n\n31:38 - Jonathan Phillips \nYeah, we\'re back.\n\n31:42 - Jorge Lewis \nOK, so this part here, so this is a prompt for creating an agent. So we\'re passing it the user info, which is things like name, those things, right? It\'s given as a variable using the curly brackets. And then we set the value down here in the code. So we could, on the front end for that, make the curly brackets as a keyword for variable. And we need to tell you guys to not change those. That\'s the simplest way I can think of as of now. Later down the line, to make it more intuitive, we can make a drop, like an insert variable type of thing. But I don\'t think there\'s a need. We can use double curly braces if that\'s more intuitive and obvious.\n\n32:20 - Cuan Mulligan \nI would just create a CRUD screen with those fields in it that we can edit. And then at runtime, you pull that down.\n\n32:39 - Cuan Mulligan \nI think the risk of going into code and changing something accidental is way bigger. So anything that\'s changing stuff, I would want to control the experience just to be safe.\n\n32:55 - Jorge Lewis \nYes, the only one of the problem for the crud table you\'d be so we would assign the variables, right? On the UI. But the value would have to be assigned later down the road.\n\n33:11 - Cuan Mulligan \nOnce you spin it up, that will pull down the latest value, and then we\'d have to have some form of... If you changed it, it would have to refresh. Let\'s say you changed the personality variable. It would have to then take that new personality, so maybe there\'s a restart, a reboot, refresh, whatever. There has to be a way of pushing that change into the bot context so that it takes that new context into consideration going forward.\n\n33:43 - Jorge Lewis \nYeah, the concern is that so user, so let\'s say if we were to just drag this into a front end, we have the left side of the screen can be the prompts with the right side just being the variables. We can\'t assign the value in the admin page. It has to be done behind the scenes. So it has to follow a certain key. For example, the key would be user info.\n\n34:12 - Cuan Mulligan \nI don\'t think we need to fix it now, anyway.\n\n34:14 - Cuan Mulligan \nYeah, we can go into that.\n\n34:16 - Cuan Mulligan \nSo when will this be deployed? Because it looks, you know, it\'s great to see this. It looks like it\'s actually, there\'s a whole load of stuff that\'s happened. When can we start to play?\n\n34:26 - Jorge Lewis \nI mean, I could try pushing right now, if you guys want to see if that will work or not. Actually, never mind, we have a problem with Vercel. They\'ve changed their pricing or their integration with GitHub. Only Jonas, oh, wait, no. Let me give it a go. Only one person from the accounts can now merge into Alpha. Let\'s find out.\n\n35:07 - Jorge Lewis \nBut I mean, yeah, I think Jonas is off for today. But if he\'s able to respond to my message, I can get it done myself.\n\n35:18 - Jorge Lewis \nYeah, it doesn\'t let me.\n\n35:22 - Cuan Mulligan \nHow come he\'s away today? Sorry, I didn\'t know.\n\n35:25 - Jorge Lewis \nSorry. Jonas, I think he\'s just off for dinner with his girlfriend\'s family.\n\n35:36 - Cuan Mulligan \nOkay, so if you can get a copy of it and let us know when you can push so we can test it because...\n\n35:42 - Jorge Lewis \nHe\'s off for my day. His day starts at the normal time. I start late.\n\n35:49 - Jorge Lewis \nI can get him back on.\n\n35:54 - Jorge Lewis \nBut if this doesn\'t have any issues, like with the actual connecting with\n######################\nOutput:'}
02:07:11,885 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,888 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "is going to be imperative.\n\n30:07 - Jonathan Phillips \nSorry, excuse my ignorance, where are they sitting, those five points, as far as, it's in the code, obviously, at the moment, but where, as far as a user interface, is it part of a hard-coded prompt or is it something that's modifiable?\n\n30:25 - Jorge Lewis \nSo it's modifiable. We can bring it to the front end and bring it here. But this is a simple one where there's no variables. But something more complicated like this one where we have variables like a profile ID. Or actually, let me go. Yeah.\n\n30:53 - Cuan Mulligan \nI want all of these aspects of a prompt to be in an admin screen that we can tweak and modify.\n\n30:59 - Jorge Lewis \nYeah, so we need to figure out the best way to do that because it's obviously possible. Just what's the best way? I'm thinking the best way is just to use So you can see here, we give it a variable. This is a variable here, userInfo. And at the bottom, we give it as the actual value.\n\n31:22 - Cuan Mulligan \nSorry, I can't see your screen anymore. Is it just me? No, I've lost it as well.\n\n31:27 - Jorge Lewis \nOh, for just now or the whole time?\n\n31:30 - Cuan Mulligan \nNo, just now. Just now.\n\n31:34 - Jorge Lewis \nLet me know.\n\n31:38 - Jonathan Phillips \nYeah, we're back.\n\n31:42 - Jorge Lewis \nOK, so this part here, so this is a prompt for creating an agent. So we're passing it the user info, which is things like name, those things, right? It's given as a variable using the curly brackets. And then we set the value down here in the code. So we could, on the front end for that, make the curly brackets as a keyword for variable. And we need to tell you guys to not change those. That's the simplest way I can think of as of now. Later down the line, to make it more intuitive, we can make a drop, like an insert variable type of thing. But I don't think there's a need. We can use double curly braces if that's more intuitive and obvious.\n\n32:20 - Cuan Mulligan \nI would just create a CRUD screen with those fields in it that we can edit. And then at runtime, you pull that down.\n\n32:39 - Cuan Mulligan \nI think the risk of going into code and changing something accidental is way bigger. So anything that's changing stuff, I would want to control the experience just to be safe.\n\n32:55 - Jorge Lewis \nYes, the only one of the problem for the crud table you'd be so we would assign the variables, right? On the UI. But the value would have to be assigned later down the road.\n\n33:11 - Cuan Mulligan \nOnce you spin it up, that will pull down the latest value, and then we'd have to have some form of... If you changed it, it would have to refresh. Let's say you changed the personality variable. It would have to then take that new personality, so maybe there's a restart, a reboot, refresh, whatever. There has to be a way of pushing that change into the bot context so that it takes that new context into consideration going forward.\n\n33:43 - Jorge Lewis \nYeah, the concern is that so user, so let's say if we were to just drag this into a front end, we have the left side of the screen can be the prompts with the right side just being the variables. We can't assign the value in the admin page. It has to be done behind the scenes. So it has to follow a certain key. For example, the key would be user info.\n\n34:12 - Cuan Mulligan \nI don't think we need to fix it now, anyway.\n\n34:14 - Cuan Mulligan \nYeah, we can go into that.\n\n34:16 - Cuan Mulligan \nSo when will this be deployed? Because it looks, you know, it's great to see this. It looks like it's actually, there's a whole load of stuff that's happened. When can we start to play?\n\n34:26 - Jorge Lewis \nI mean, I could try pushing right now, if you guys want to see if that will work or not. Actually, never mind, we have a problem with Vercel. They've changed their pricing or their integration with GitHub. Only Jonas, oh, wait, no. Let me give it a go. Only one person from the accounts can now merge into Alpha. Let's find out.\n\n35:07 - Jorge Lewis \nBut I mean, yeah, I think Jonas is off for today. But if he's able to respond to my message, I can get it done myself.\n\n35:18 - Jorge Lewis \nYeah, it doesn't let me.\n\n35:22 - Cuan Mulligan \nHow come he's away today? Sorry, I didn't know.\n\n35:25 - Jorge Lewis \nSorry. Jonas, I think he's just off for dinner with his girlfriend's family.\n\n35:36 - Cuan Mulligan \nOkay, so if you can get a copy of it and let us know when you can push so we can test it because...\n\n35:42 - Jorge Lewis \nHe's off for my day. His day starts at the normal time. I start late.\n\n35:49 - Jorge Lewis \nI can get him back on.\n\n35:54 - Jorge Lewis \nBut if this doesn't have any issues, like with the actual connecting with"}
02:07:11,919 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:11,920 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'s family.\n\n35:36 - Cuan Mulligan \nOkay, so if you can get a copy of it and let us know when you can push so we can test it because...\n\n35:42 - Jorge Lewis \nHe\'s off for my day. His day starts at the normal time. I start late.\n\n35:49 - Jorge Lewis \nI can get him back on.\n\n35:54 - Jorge Lewis \nBut if this doesn\'t have any issues, like with the actual connecting with the front end when it\'s merged, then it should be...\n\n36:03 - Jorge Lewis \n10 but it takes as long as Jonas can respond.\n\n36:12 - Jorge Lewis \nSo we\'ve looked at the good response. Let\'s take a look at the bad one. Similar thing.\n\n36:18 - Jorge Lewis \nThe system prompts.\n\n36:23 - Jorge Lewis \nSo now we\'ve separated the prompts into different aspects to give you guys some more room to work with. And this will later be the whole list of prompts that we\'re seeing that aren\'t added, like the system prompt for agents and things like this. So we\'ll add that later down the road. As of now, you can start playing with these. Yeah.\n\n36:51 - Jorge Lewis \nSo does that include everything you guys were wondering, or have we missed anything?\n\n36:59 - Cuan Mulligan \nI mean, yeah, we need to figure out what we can do. And yeah, if you can send over the latest URLs that we need to play with, and then we can start playing with stuff and giving feedback, that\'d be great.\n\n37:13 - Jorge Lewis \nOkay, sounds good. And then just to solve the issue of the daily progress is we\'ll start moving a lot of our tech chats into your guys\' chats, or maybe we\'ll make a separate channel for us to put the tech-specific stuff, and we\'ll start just chatting there. Sound good?\n\n37:30 - Jorge Lewis \nYeah.\n\n37:32 - Jorge Lewis \nCool. I\'ll send the links right now, and then I\'ll let you know when they\'re playable.\n\n37:41 - Jonathan Phillips \nJust just let you know as well the payment went through today so it should be in your account now Sounds good.\n\n37:48 - Jorge Lewis \nThanks so much I hope you could I\'ve hope you\'ve been able to see how we\'re able to apply some of the coins a lot of cool and stuff to To the most yeah that we\'re using well behind the scenes. We\'re using line graph. It\'s a pretty pretty new framework for for just LLMs. It uses a graph structure, which makes it super modular and flexible. I love it so far. It was different to what we were previously using, which was another framework by Microsoft Autogen, which was a lot more abstracted and less easy to work with. So this one hopefully gives us a lot more just grit and speed. Excellent.\n\n38:26 - Cuan Mulligan \nCool you.\n\n38:27 - Cuan Mulligan \nThanks guys so much for your time. Thanks a lot. Bye-bye.\n######################\nOutput:'}
02:07:11,921 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:11,923 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'s family.\n\n35:36 - Cuan Mulligan \nOkay, so if you can get a copy of it and let us know when you can push so we can test it because...\n\n35:42 - Jorge Lewis \nHe's off for my day. His day starts at the normal time. I start late.\n\n35:49 - Jorge Lewis \nI can get him back on.\n\n35:54 - Jorge Lewis \nBut if this doesn't have any issues, like with the actual connecting with the front end when it's merged, then it should be...\n\n36:03 - Jorge Lewis \n10 but it takes as long as Jonas can respond.\n\n36:12 - Jorge Lewis \nSo we've looked at the good response. Let's take a look at the bad one. Similar thing.\n\n36:18 - Jorge Lewis \nThe system prompts.\n\n36:23 - Jorge Lewis \nSo now we've separated the prompts into different aspects to give you guys some more room to work with. And this will later be the whole list of prompts that we're seeing that aren't added, like the system prompt for agents and things like this. So we'll add that later down the road. As of now, you can start playing with these. Yeah.\n\n36:51 - Jorge Lewis \nSo does that include everything you guys were wondering, or have we missed anything?\n\n36:59 - Cuan Mulligan \nI mean, yeah, we need to figure out what we can do. And yeah, if you can send over the latest URLs that we need to play with, and then we can start playing with stuff and giving feedback, that'd be great.\n\n37:13 - Jorge Lewis \nOkay, sounds good. And then just to solve the issue of the daily progress is we'll start moving a lot of our tech chats into your guys' chats, or maybe we'll make a separate channel for us to put the tech-specific stuff, and we'll start just chatting there. Sound good?\n\n37:30 - Jorge Lewis \nYeah.\n\n37:32 - Jorge Lewis \nCool. I'll send the links right now, and then I'll let you know when they're playable.\n\n37:41 - Jonathan Phillips \nJust just let you know as well the payment went through today so it should be in your account now Sounds good.\n\n37:48 - Jorge Lewis \nThanks so much I hope you could I've hope you've been able to see how we're able to apply some of the coins a lot of cool and stuff to To the most yeah that we're using well behind the scenes. We're using line graph. It's a pretty pretty new framework for for just LLMs. It uses a graph structure, which makes it super modular and flexible. I love it so far. It was different to what we were previously using, which was another framework by Microsoft Autogen, which was a lot more abstracted and less easy to work with. So this one hopefully gives us a lot more just grit and speed. Excellent.\n\n38:26 - Cuan Mulligan \nCool you.\n\n38:27 - Cuan Mulligan \nThanks guys so much for your time. Thanks a lot. Bye-bye."}
02:07:12,334 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:12,336 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: graph working like the check-in the chatting and Onboarding, yeah, the last onboarding I know a little bit.\n\n5:46 - Jorge Lewis \nOkay.\n\n5:49 - Jorge Lewis \nYeah, pretty much same. Okay, so pretty much, do you understand the vision of ADAPT, the goal?\n\n5:58 - Hasnain sayyed \nYeah, so it\'s kind of 10 weeks framework. It will ask the goal of the user, like whether he wants to lose the weight or what\'s the motivation he wants within these 10 weeks. And during that, it will get the similar exercises. It will get the data, like the daily check-ins. And based on that, a performance review will be given to the user.\n\n6:26 - Unidentified Speaker \nYeah.\n\n6:27 - Jorge Lewis \nSo that\'s the main part of the app. Sorry, that\'s the start of the app.\n\n6:38 - Jorge Lewis \nThe main part of the app, though, is after that, where we understand his goal and why he\'s trying to achieve it, and then we\'re going to help him do that. Because understanding his goal and helping him understand his goal is good, but now the main point of the app is to help him achieve it. All the features you can see on the page one. We have the reminders and nudges, the daily check-ins, the day-to-day mentoring, and the milestones. So these are the four main systems that are going to be used throughout the core app. So reminders and nudges, okay. Actually, this is a, follow me over.\n\n7:25 - Jorge Lewis \nOkay, here, here. So this is the mentor.\n\n7:30 - Jorge Lewis \nMentor has three things to do.\n\n7:37 - Jorge Lewis \nHold up.\n\n7:46 - Jorge Lewis \nOkay, I\'ll explain it like this. The core app has a mentor. The main agent that the user will be interacting with is the mentor. Sometimes when there\'s a dip in performance and the mentor gets notified by perhaps an analyst agent saying, hey, the user has been lacking on this. And then the mentor will say, okay, user, do you want to start a coaching session? And that\'s the coach\'s job. The coach\'s job is to go really in detail about why is the user lacking and not making progress towards their goals. What is stopping them? Do they have to update their goal? Do they have to agree on a new system, like some new practices they should do. Anyways, the mentor, his job is just facilitating everyday conversation. One of the main things that you guys were working on before was a daily check-in, right? So this is when you know about the day-to-day mentoring. All this is really is just the Everything other than the daily check-in, I think. It\'s kind of giving the mentor the ability to help the user and coach the user with simple things. So this will be mostly using data sources related to health, fitness, sleep, all those things so that he can provide advice. So I think this is mostly a very simple chatbot, the mentor. And then he has tools which can make him do a daily check-in.\n\n9:16 - Jorge Lewis \nAlthough this LMS feature, by the way, so initially Kuhn wanted to have an LMS, a learning management system. He wanted to, it was like kind of pretty separate to this whole app so that the, there\'s an LMS, the user watches a video every day and the mentor can ask the user, Hey, have you watched the video? Uh, but I don\'t know where Kuhn is on that right now. I think he\'s changed his mind a little bit since now this is becoming like a, the term he uses is a, um, is a health vault, I think, or health bank, something like that.\n\n9:50 - Jorge Lewis \nAre you familiar with the term? He just made it up, but he\'s been using that word a bit in the chat.\n\n10:01 - Hasnain sayyed \nWhich word?\n\n10:03 - Jorge Lewis \nHealth bank, I think.\n\n10:08 - Hasnain sayyed \nNo, I haven\'t heard that.\n\n10:09 - Jorge Lewis \nAll right.\n\n10:13 - Hasnain sayyed \nBut I know this LMS content like it will be recommending video based on the user past history.\n\n10:22 - Jorge Lewis \nNot recommending but just so there\'s there\'s one video every day for the user so the user picks a course I think there\'s gonna be multiple courses and they pick a course every day there\'s a new video that they have to watch. But I don\'t know if that\'s the case anymore. I don\'t know if Kuon has changed it or how he\'s been regarding that. We\'ll have to get updated on that.\n\n10:46 - Jorge Lewis \nThe rest of the system, reminders, milestones, these two are just very simple. What the mentor can do is remind the user.\n\n11:01 - Jorge Lewis \nthrough notifications, saying, for example, hey, your bedtime is in three hours, you shouldn\'t drink coffee, for example.\n\n11:12 - Jorge Lewis \nAnd the milestones are pretty much a way to motivate the user. So it\'s the mentor, when the user checks in, the user says, hey, the mentor can ask during the daily check-in, Have you done your walk today? And the user says, yes, I walked 10 kilometers. And the milestone should be kind of automatic, saying there\'s just a condition for each milestone. So for example, one milestone can be user walked 1,000 kilometers, for example, over\n######################\nOutput:'}
02:07:12,336 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:12,339 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "graph working like the check-in the chatting and Onboarding, yeah, the last onboarding I know a little bit.\n\n5:46 - Jorge Lewis \nOkay.\n\n5:49 - Jorge Lewis \nYeah, pretty much same. Okay, so pretty much, do you understand the vision of ADAPT, the goal?\n\n5:58 - Hasnain sayyed \nYeah, so it's kind of 10 weeks framework. It will ask the goal of the user, like whether he wants to lose the weight or what's the motivation he wants within these 10 weeks. And during that, it will get the similar exercises. It will get the data, like the daily check-ins. And based on that, a performance review will be given to the user.\n\n6:26 - Unidentified Speaker \nYeah.\n\n6:27 - Jorge Lewis \nSo that's the main part of the app. Sorry, that's the start of the app.\n\n6:38 - Jorge Lewis \nThe main part of the app, though, is after that, where we understand his goal and why he's trying to achieve it, and then we're going to help him do that. Because understanding his goal and helping him understand his goal is good, but now the main point of the app is to help him achieve it. All the features you can see on the page one. We have the reminders and nudges, the daily check-ins, the day-to-day mentoring, and the milestones. So these are the four main systems that are going to be used throughout the core app. So reminders and nudges, okay. Actually, this is a, follow me over.\n\n7:25 - Jorge Lewis \nOkay, here, here. So this is the mentor.\n\n7:30 - Jorge Lewis \nMentor has three things to do.\n\n7:37 - Jorge Lewis \nHold up.\n\n7:46 - Jorge Lewis \nOkay, I'll explain it like this. The core app has a mentor. The main agent that the user will be interacting with is the mentor. Sometimes when there's a dip in performance and the mentor gets notified by perhaps an analyst agent saying, hey, the user has been lacking on this. And then the mentor will say, okay, user, do you want to start a coaching session? And that's the coach's job. The coach's job is to go really in detail about why is the user lacking and not making progress towards their goals. What is stopping them? Do they have to update their goal? Do they have to agree on a new system, like some new practices they should do. Anyways, the mentor, his job is just facilitating everyday conversation. One of the main things that you guys were working on before was a daily check-in, right? So this is when you know about the day-to-day mentoring. All this is really is just the Everything other than the daily check-in, I think. It's kind of giving the mentor the ability to help the user and coach the user with simple things. So this will be mostly using data sources related to health, fitness, sleep, all those things so that he can provide advice. So I think this is mostly a very simple chatbot, the mentor. And then he has tools which can make him do a daily check-in.\n\n9:16 - Jorge Lewis \nAlthough this LMS feature, by the way, so initially Kuhn wanted to have an LMS, a learning management system. He wanted to, it was like kind of pretty separate to this whole app so that the, there's an LMS, the user watches a video every day and the mentor can ask the user, Hey, have you watched the video? Uh, but I don't know where Kuhn is on that right now. I think he's changed his mind a little bit since now this is becoming like a, the term he uses is a, um, is a health vault, I think, or health bank, something like that.\n\n9:50 - Jorge Lewis \nAre you familiar with the term? He just made it up, but he's been using that word a bit in the chat.\n\n10:01 - Hasnain sayyed \nWhich word?\n\n10:03 - Jorge Lewis \nHealth bank, I think.\n\n10:08 - Hasnain sayyed \nNo, I haven't heard that.\n\n10:09 - Jorge Lewis \nAll right.\n\n10:13 - Hasnain sayyed \nBut I know this LMS content like it will be recommending video based on the user past history.\n\n10:22 - Jorge Lewis \nNot recommending but just so there's there's one video every day for the user so the user picks a course I think there's gonna be multiple courses and they pick a course every day there's a new video that they have to watch. But I don't know if that's the case anymore. I don't know if Kuon has changed it or how he's been regarding that. We'll have to get updated on that.\n\n10:46 - Jorge Lewis \nThe rest of the system, reminders, milestones, these two are just very simple. What the mentor can do is remind the user.\n\n11:01 - Jorge Lewis \nthrough notifications, saying, for example, hey, your bedtime is in three hours, you shouldn't drink coffee, for example.\n\n11:12 - Jorge Lewis \nAnd the milestones are pretty much a way to motivate the user. So it's the mentor, when the user checks in, the user says, hey, the mentor can ask during the daily check-in, Have you done your walk today? And the user says, yes, I walked 10 kilometers. And the milestone should be kind of automatic, saying there's just a condition for each milestone. So for example, one milestone can be user walked 1,000 kilometers, for example, over"}
02:07:12,390 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:12,393 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: nain sayyed \nGot it.\n\n47:21 - Jorge Lewis \nSo for example, the objective, when it\'s default, could literally be nothing. We just tell the bot who it is and what it\'s doing, and we let it, like, kind of just, you know, we tell it, pretend you\'re a person that\'s trying to achieve this goal, and you\'re chatting, you\'re trying to improve your life with a chatbot, with a life coach here. So this is their profile information that they set, okay. So this, I guess this can be default as well. We can just set, maybe we pre-fill all of these with the default information and then so that Kuen can make a lot of new users fast. And if he wants to change it, then he can.\n\n48:07 - Jorge Lewis \nAnd maybe, this is just an idea, no clue, temperature.\n\n48:26 - Jorge Lewis \nI\'m like that.\n\n48:32 - Hasnain sayyed \nBut yes, we have to create a new column. Yes, for every user for the temperature if you want.\n\n48:42 - Jorge Lewis \nThat will be dynamic for each create.\n\n48:49 - Jorge Lewis \nSo is it is it all good or? Yeah, yeah.\n\n48:58 - Jorge Lewis \nOh, cool. Let\'s go, let\'s go into, uh, working on that.\n\n49:04 - Hasnain sayyed \nGot it. So which part, uh, should we start the first, uh, the UI, AI work?\n\n49:14 - Jorge Lewis \nUm, so the UI, we\'ll leave it to a front end. Have you worked with spells?\n\n49:22 - Hasnain sayyed \nUh, no, actually I am proficient in react next. Yeah.\n\n49:34 - Jorge Lewis \nYeah, we\'ll run that for now. We can worry about the backend. All of this here can be done just by creating new, we can set all this data with just doing it in Superbase. So these here, so actually this profile information is sets, this is already from, that\'s already in the table. This is new, and this is new.\n\n49:58 - Jorge Lewis \nHmm.\n\n49:59 - Jorge Lewis \nRight. I\'m sure. Correct.\n\n50:02 - Hasnain sayyed \nSo these are all new ones, but, uh, if you create the temperature, uh, uh, additional point of here, so it will affect the real user or else we have to, uh, set like, uh, if, uh, the condition, like if I did a synthetic user, then it will be, uh, getting from the database or else, uh, the default temperature of all the real user will be like that.\n\n50:27 - Jorge Lewis \nYeah, I think so, yeah. So, in the call, in the function that does... I think it\'s just called run, actually. In that function, we can take in a parameter saying synthetic or not, and then anywhere in the code we can access that variable.\n\n50:48 - Hasnain sayyed \nOkay, so...\n\n50:48 - Jorge Lewis \nSo, I\'ll leave it up to you.\n\n50:55 - Hasnain sayyed \nthe basic thing here if I am just a quick recap the functionality of the backend will be pointing the listing all the you know the user the synthetic user in this dashboard it will be a function a normal select all thing and then While clicking on the new user, it will be picking the default value. I think there doesn\'t need to be any database. Or we can just have a normal JSON created. We can just create a JSON over here in the, and it will be storing, uh, in our local file only if we want, or maybe in the database. And this data will be, uh, you know, fetching, when the user, when the, and if that, uh, values change, it already been stored in the state like, uh, uh, the input state and if your admin takes on create, the updated value will be creating a new row in the super base.\n\n52:05 - Unidentified Speaker \nYeah.\n\n52:07 - Jorge Lewis \nYeah, so the flow of... Okay, so actually let\'s discuss quickly the flow after I click the create button when I create a new synthetic user. What should happen is that... Let me think actually.\n\n52:26 - Jorge Lewis \nSo instead of 10 because I think that\'s too long, because imagine this, if Kuen wants to simulate one month of the user interacting with a bot, is too 10 long, that\'ll be 300 minutes. So obviously if we could, we\'d make it instantly. We\'d make it, you click create synthetic user and it has one month or 10 months of data, of conversation data done, but the LLMs are too slow, so how do we figure out how do we figure that out based\n\n53:06 - Hasnain sayyed \non data length or based on time interval these are two options I feel but like the number of questions interval Like number of questions asked by the synthetic user, we can also point that as well. Like it won\'t exceed 10 questions, maybe.\n\n53:31 - Jorge Lewis \nSo for time interval, I like time interval more, but what\'s the lowest we can set it at? Because one minute, I don\'t think they can have enough messages. Maybe?\n\n53:42 - Unidentified Speaker \nYeah, right.\n\n53:48 - Jorge Lewis \nWe can play around with the number. We can set it later. Also, one concern I have that I\n######################\nOutput:'}
02:07:12,393 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:12,398 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "nain sayyed \nGot it.\n\n47:21 - Jorge Lewis \nSo for example, the objective, when it's default, could literally be nothing. We just tell the bot who it is and what it's doing, and we let it, like, kind of just, you know, we tell it, pretend you're a person that's trying to achieve this goal, and you're chatting, you're trying to improve your life with a chatbot, with a life coach here. So this is their profile information that they set, okay. So this, I guess this can be default as well. We can just set, maybe we pre-fill all of these with the default information and then so that Kuen can make a lot of new users fast. And if he wants to change it, then he can.\n\n48:07 - Jorge Lewis \nAnd maybe, this is just an idea, no clue, temperature.\n\n48:26 - Jorge Lewis \nI'm like that.\n\n48:32 - Hasnain sayyed \nBut yes, we have to create a new column. Yes, for every user for the temperature if you want.\n\n48:42 - Jorge Lewis \nThat will be dynamic for each create.\n\n48:49 - Jorge Lewis \nSo is it is it all good or? Yeah, yeah.\n\n48:58 - Jorge Lewis \nOh, cool. Let's go, let's go into, uh, working on that.\n\n49:04 - Hasnain sayyed \nGot it. So which part, uh, should we start the first, uh, the UI, AI work?\n\n49:14 - Jorge Lewis \nUm, so the UI, we'll leave it to a front end. Have you worked with spells?\n\n49:22 - Hasnain sayyed \nUh, no, actually I am proficient in react next. Yeah.\n\n49:34 - Jorge Lewis \nYeah, we'll run that for now. We can worry about the backend. All of this here can be done just by creating new, we can set all this data with just doing it in Superbase. So these here, so actually this profile information is sets, this is already from, that's already in the table. This is new, and this is new.\n\n49:58 - Jorge Lewis \nHmm.\n\n49:59 - Jorge Lewis \nRight. I'm sure. Correct.\n\n50:02 - Hasnain sayyed \nSo these are all new ones, but, uh, if you create the temperature, uh, uh, additional point of here, so it will affect the real user or else we have to, uh, set like, uh, if, uh, the condition, like if I did a synthetic user, then it will be, uh, getting from the database or else, uh, the default temperature of all the real user will be like that.\n\n50:27 - Jorge Lewis \nYeah, I think so, yeah. So, in the call, in the function that does... I think it's just called run, actually. In that function, we can take in a parameter saying synthetic or not, and then anywhere in the code we can access that variable.\n\n50:48 - Hasnain sayyed \nOkay, so...\n\n50:48 - Jorge Lewis \nSo, I'll leave it up to you.\n\n50:55 - Hasnain sayyed \nthe basic thing here if I am just a quick recap the functionality of the backend will be pointing the listing all the you know the user the synthetic user in this dashboard it will be a function a normal select all thing and then While clicking on the new user, it will be picking the default value. I think there doesn't need to be any database. Or we can just have a normal JSON created. We can just create a JSON over here in the, and it will be storing, uh, in our local file only if we want, or maybe in the database. And this data will be, uh, you know, fetching, when the user, when the, and if that, uh, values change, it already been stored in the state like, uh, uh, the input state and if your admin takes on create, the updated value will be creating a new row in the super base.\n\n52:05 - Unidentified Speaker \nYeah.\n\n52:07 - Jorge Lewis \nYeah, so the flow of... Okay, so actually let's discuss quickly the flow after I click the create button when I create a new synthetic user. What should happen is that... Let me think actually.\n\n52:26 - Jorge Lewis \nSo instead of 10 because I think that's too long, because imagine this, if Kuen wants to simulate one month of the user interacting with a bot, is too 10 long, that'll be 300 minutes. So obviously if we could, we'd make it instantly. We'd make it, you click create synthetic user and it has one month or 10 months of data, of conversation data done, but the LLMs are too slow, so how do we figure out how do we figure that out based\n\n53:06 - Hasnain sayyed \non data length or based on time interval these are two options I feel but like the number of questions interval Like number of questions asked by the synthetic user, we can also point that as well. Like it won't exceed 10 questions, maybe.\n\n53:31 - Jorge Lewis \nSo for time interval, I like time interval more, but what's the lowest we can set it at? Because one minute, I don't think they can have enough messages. Maybe?\n\n53:42 - Unidentified Speaker \nYeah, right.\n\n53:48 - Jorge Lewis \nWe can play around with the number. We can set it later. Also, one concern I have that I"}
02:07:12,399 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:12,400 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:12,402 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: So that\'s what I\'m telling. We have to create a function. So then we can start with that.\n\n25:51 - Unidentified Speaker \nOkay.\n\n25:53 - Jorge Lewis \nYeah, keep going. Which one? We\'re going to have to probably work and make, yeah.\n\n26:04 - Jorge Lewis \nYour voice is breaking. We\'re going to, we\'re going to have to work.\n\n26:09 - Jorge Lewis \nNo, it\'s cause I think, I think there\'s a bit of a delay, so we keep cutting each other, but we\'re going to have to work on super base probably to create some manual things.\n\n26:18 - Jorge Lewis \nOkay.\n\n26:22 - Jorge Lewis \nAll right. So let\'s open the project. Start your screen share. Do you use this code or VS code?\n\n26:31 - Jorge Lewis \nOkay, cool. Can you share a live share link?\n\n26:35 - Hasnain sayyed \nOkay, should I open that app project or? Yeah, yeah. Okay.\n\n26:46 - Hasnain sayyed \nJust a second. I just pulled the latest one.\n\n27:03 - Hasnain sayyed \nOn which branch should I pull?\n\n27:13 - Jorge Lewis \nJust a second.\n\n27:18 - Jorge Lewis \nProbably alpha. I don\'t know.\n\n27:21 - Hasnain sayyed \nJust a second.\n\n28:19 - Hasnain sayyed \nYes.\n\n28:25 - Hasnain sayyed \nI\'m now in alpha right now.\n\n28:32 - Hasnain sayyed \nDo you mind sharing your screen, by the way?\n\n28:34 - Hasnain sayyed \nYeah, yeah, sure.\n\n28:41 - Jorge Lewis \nShow the whole screen so I can see the web server as well as the super-based things you\'re doing.\n\n29:24 - Hasnain sayyed \nSo first in the super base thing.\n\n29:34 - Hasnain sayyed \nShould we create the function to dynamically create this synthetic user or first we should manually interrupt the thing or what else?\n\n29:48 - Jorge Lewis \nSo to start off, since that\'s kind of not the creating a synthetic user is part of what we can do, but I think we should start off with making a synthetic user and then go from there. But, but we have to think, yeah.\n\n30:07 - Jorge Lewis \nSo let\'s create one in the super base first.\n\n30:16 - Hasnain sayyed \nSo we have to create a new column for that, right? Because we don\'t have to merge the real users with the synthetic one.\n\n30:29 - Jorge Lewis \nOr what say?\n\n30:30 - Hasnain sayyed \nThat\'s what I was thinking as well.\n\n30:32 - Hasnain sayyed \nor just create a column here a new table or a new column right the column will identify like a real user or a synthetic user what say exactly what I was saying but my concern is that this table is\n\n30:49 - Jorge Lewis \nlinked to the chat one the id is linked to if you can see the um no it\'s linked to the users table that superbase uses for authentication So we can create a new profiles and you try to.\n\n31:12 - Jorge Lewis \nIf you tried to create a new row, it won\'t work like it because you need the ID needs to be linked to a insert the green button near the top.\n\n31:31 - Jorge Lewis \nthe green insert button above ID. I can draw on your screen, I think, right? No, let me see. I\'m trying to see how I can color. Oh, you have it there.\n\n31:51 - Jorge Lewis \nOh, here we go.\n\n32:01 - Jorge Lewis \nHmm, I guess only you can.\n\n32:07 - Jorge Lewis \nBut do you see the insert button? It\'s green, near the top.\n\n32:17 - Jorge Lewis \nInsert button? Yeah.\n\n32:18 - Jorge Lewis \nA little bit left.\n\n32:21 - Unidentified Speaker \nYeah.\n\n32:22 - Jorge Lewis \nTry to insert row. And you\'ll see that the ID has a foreign key relation to the users table, which means that unless we create a new user in the users table using super-based authentication, we can\'t create a new row in this table. So that\'s going to prevent us from creating synthetic users like we might want to with that.\n\n32:48 - Jorge Lewis \nSo like you proposed, I think we\'re going to have to make a new table. And even if we can later add just a column in the profile table, it takes five minutes, right? So it\'s better to kind of just start. So let\'s make a new table. Synthetic user or synthetic profile maybe to keep it the same.\n\n33:21 - Hasnain sayyed \nShould I off this RLS, the rule level security because I think it\'s disabled. Yeah, turn it off, turn it off.\n\n33:33 - Jorge Lewis \nWe don\'t want to, it\'ll be, it\'ll be annoying. It just, the best practice is before you go to production, you want to turn all those on, but\n\n33:41 - Jorge Lewis \nHmm. Correct.\n\n33:45 - Hasnain sayyed \nSo the, attributes will be, ID is already there, created at.\n\n33:54 - Jorge Lewis \nSo this is going to be the same as, um, actually we kind of did a little bit. We need the name, personality, or anything.\n\n34:05 - Hasnain\n######################\nOutput:'}
02:07:12,402 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:12,406 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "So that's what I'm telling. We have to create a function. So then we can start with that.\n\n25:51 - Unidentified Speaker \nOkay.\n\n25:53 - Jorge Lewis \nYeah, keep going. Which one? We're going to have to probably work and make, yeah.\n\n26:04 - Jorge Lewis \nYour voice is breaking. We're going to, we're going to have to work.\n\n26:09 - Jorge Lewis \nNo, it's cause I think, I think there's a bit of a delay, so we keep cutting each other, but we're going to have to work on super base probably to create some manual things.\n\n26:18 - Jorge Lewis \nOkay.\n\n26:22 - Jorge Lewis \nAll right. So let's open the project. Start your screen share. Do you use this code or VS code?\n\n26:31 - Jorge Lewis \nOkay, cool. Can you share a live share link?\n\n26:35 - Hasnain sayyed \nOkay, should I open that app project or? Yeah, yeah. Okay.\n\n26:46 - Hasnain sayyed \nJust a second. I just pulled the latest one.\n\n27:03 - Hasnain sayyed \nOn which branch should I pull?\n\n27:13 - Jorge Lewis \nJust a second.\n\n27:18 - Jorge Lewis \nProbably alpha. I don't know.\n\n27:21 - Hasnain sayyed \nJust a second.\n\n28:19 - Hasnain sayyed \nYes.\n\n28:25 - Hasnain sayyed \nI'm now in alpha right now.\n\n28:32 - Hasnain sayyed \nDo you mind sharing your screen, by the way?\n\n28:34 - Hasnain sayyed \nYeah, yeah, sure.\n\n28:41 - Jorge Lewis \nShow the whole screen so I can see the web server as well as the super-based things you're doing.\n\n29:24 - Hasnain sayyed \nSo first in the super base thing.\n\n29:34 - Hasnain sayyed \nShould we create the function to dynamically create this synthetic user or first we should manually interrupt the thing or what else?\n\n29:48 - Jorge Lewis \nSo to start off, since that's kind of not the creating a synthetic user is part of what we can do, but I think we should start off with making a synthetic user and then go from there. But, but we have to think, yeah.\n\n30:07 - Jorge Lewis \nSo let's create one in the super base first.\n\n30:16 - Hasnain sayyed \nSo we have to create a new column for that, right? Because we don't have to merge the real users with the synthetic one.\n\n30:29 - Jorge Lewis \nOr what say?\n\n30:30 - Hasnain sayyed \nThat's what I was thinking as well.\n\n30:32 - Hasnain sayyed \nor just create a column here a new table or a new column right the column will identify like a real user or a synthetic user what say exactly what I was saying but my concern is that this table is\n\n30:49 - Jorge Lewis \nlinked to the chat one the id is linked to if you can see the um no it's linked to the users table that superbase uses for authentication So we can create a new profiles and you try to.\n\n31:12 - Jorge Lewis \nIf you tried to create a new row, it won't work like it because you need the ID needs to be linked to a insert the green button near the top.\n\n31:31 - Jorge Lewis \nthe green insert button above ID. I can draw on your screen, I think, right? No, let me see. I'm trying to see how I can color. Oh, you have it there.\n\n31:51 - Jorge Lewis \nOh, here we go.\n\n32:01 - Jorge Lewis \nHmm, I guess only you can.\n\n32:07 - Jorge Lewis \nBut do you see the insert button? It's green, near the top.\n\n32:17 - Jorge Lewis \nInsert button? Yeah.\n\n32:18 - Jorge Lewis \nA little bit left.\n\n32:21 - Unidentified Speaker \nYeah.\n\n32:22 - Jorge Lewis \nTry to insert row. And you'll see that the ID has a foreign key relation to the users table, which means that unless we create a new user in the users table using super-based authentication, we can't create a new row in this table. So that's going to prevent us from creating synthetic users like we might want to with that.\n\n32:48 - Jorge Lewis \nSo like you proposed, I think we're going to have to make a new table. And even if we can later add just a column in the profile table, it takes five minutes, right? So it's better to kind of just start. So let's make a new table. Synthetic user or synthetic profile maybe to keep it the same.\n\n33:21 - Hasnain sayyed \nShould I off this RLS, the rule level security because I think it's disabled. Yeah, turn it off, turn it off.\n\n33:33 - Jorge Lewis \nWe don't want to, it'll be, it'll be annoying. It just, the best practice is before you go to production, you want to turn all those on, but\n\n33:41 - Jorge Lewis \nHmm. Correct.\n\n33:45 - Hasnain sayyed \nSo the, attributes will be, ID is already there, created at.\n\n33:54 - Jorge Lewis \nSo this is going to be the same as, um, actually we kind of did a little bit. We need the name, personality, or anything.\n\n34:05 - Hasnain"}
02:07:12,408 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'s just a boolean template.\n\n1:13:17 - Jorge Lewis \nYeah false okay, so So we have this here const ID is So we need to get this ID from a We need to get this ID from SuperBase.\n\n1:13:39 - Hasnain sayyed \nYeah, so just right here, maybe.\n\n1:13:48 - Jorge Lewis \nSo for now, let\'s use a hard-coded ID. So I\'m going to go into SuperBase and copy one from the correct tables.\n\n1:14:03 - Hasnain sayyed \nJust paste over here.\n\n1:14:13 - Hasnain sayyed \nAnd it will be synthetic user.\n\n1:14:23 - Hasnain sayyed \nSynthetic profile, sorry.\n\n1:14:33 - Jorge Lewis \nAll right, so I\'m going to copy this one.\n\n1:14:50 - Jorge Lewis \nOh, no, this is just, yeah.\n\n1:15:00 - Jorge Lewis \nI don\'t know how you guys don\'t use super base. I mean, I\'ll compile it.\n\n1:15:09 - Jorge Lewis \nProfile for, okay, so. Okay, so let\'s make a new file that generates a message. Message, yes. And then here we can just do prompt run.\n\n1:15:50 - Jorge Lewis \nAll right, so I\'ve made just a simple run function and, or let me actually just.\n\n1:16:00 - Jorge Lewis \nAnd then, okay.\n\n1:16:17 - Jorge Lewis \nSorry, I\'m messing up with your if code.\n\n1:16:26 - Unidentified Speaker \nWhy?\n\n1:16:27 - Jorge Lewis \nOh, are you error tracking or?\n\n1:16:42 - Hasnain sayyed \nShould I add this data types like synthetic user in the database.types? So this error will be gone.\n\n1:16:56 - Jorge Lewis \nLet me, I\'m not seeing your screen. Over here. Yes. I don\'t have some of the highlighting because I\'m on your live share.\n\n1:17:10 - Jorge Lewis \nGenerate the new types.\n\n1:17:13 - Jorge Lewis \nYes.\n\n1:17:15 - Jorge Lewis \nThat\'s a good idea.\n\n1:17:28 - Jorge Lewis \nIf there\'s only one super base call in the script or in the code, you don\'t want to name them. You can just leave them. So this is pretty, should be pretty obvious, I think.\n\n1:17:44 - Unidentified Speaker \nBye!\n\n1:18:18 - Jorge Lewis \nIt\'s now gone.\n\n1:19:11 - Hasnain sayyed \nWe have to create an agent which passes this message.\n\n1:19:18 - Hasnain sayyed \nOkay, yeah, it\'s generate message is there.\n\n1:19:30 - Jorge Lewis \nI\'m not getting all of the error highlighting that you are by the way.\n\n1:20:48 - Hasnain sayyed \nWhat are we creating next?\n\n1:21:06 - Jorge Lewis \nNext is.\n\n1:21:16 - Jorge Lewis \nCould you keep sharing your screen? Because it was quite helpful.\n\n1:21:44 - Jorge Lewis \nOkay, so we\'re going to, what\'s the statement? So we have a message.\n\n1:22:11 - Jorge Lewis \nSo, imagine the message history is no messages, so we\'re going to have the synthetic user generate a message first, and then the AdaptBot will reply to it. We need to wrap all this in a for loop.\n\n1:22:32 - Jorge Lewis \nWhich one? This?\n\n1:22:35 - Jorge Lewis \nSo the synthetic user and the response to that need to be looped if we want to kind of have a conversation. So let\'s say we want to have a conversation of 10 messages.\n\n1:22:46 - Hasnain sayyed \nWe can just do a for loop for So based on the user response, maybe like Sorry, based on the user question, we can point like, yeah, it\'s 10. Or maybe a normal pointer while const let a is equal to 10.\n\n1:23:21 - Jorge Lewis \n2 Use a for loop, no?\n\n1:23:29 - Hasnain sayyed \nMaybe, yes.\n\n1:23:33 - Jorge Lewis \nI can\'t remember the syntax, though, so I\'m going to search it up.\n\n1:23:39 - Jorge Lewis \nFor loop syntax, OK.\n\n1:23:44 - Hasnain sayyed \nIt\'s equal to 0, then 10.\n\n1:23:56 - Hasnain sayyed \nA plus plus.\n\n1:23:57 - Unidentified Speaker \nYeah.\n\n1:23:59 - Hasnain sayyed \nThis is the basic syntax and it will be running 10 times.\n\n1:24:09 - Hasnain sayyed \nThe messages will be passing through this and RES we have to store this thing because the run function is performing actions on this as well.\n\n1:24:35 - Hasnain sayyed \nOkay, we have events.\n\n1:24:44 - Hasnain sayyed \nThe one thing over here is, if you look my screen, yeah, so in the post chat, the events, it is storing the chat in events. So we have to club this ID to the events itself. Because the profile ID is also pointing to events.\n\n1:25:08 - Hasnain sayyed \nWhat do you mean?\n\n1:\n######################\nOutput:'}
02:07:12,409 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:12,414 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "'s just a boolean template.\n\n1:13:17 - Jorge Lewis \nYeah false okay, so So we have this here const ID is So we need to get this ID from a We need to get this ID from SuperBase.\n\n1:13:39 - Hasnain sayyed \nYeah, so just right here, maybe.\n\n1:13:48 - Jorge Lewis \nSo for now, let's use a hard-coded ID. So I'm going to go into SuperBase and copy one from the correct tables.\n\n1:14:03 - Hasnain sayyed \nJust paste over here.\n\n1:14:13 - Hasnain sayyed \nAnd it will be synthetic user.\n\n1:14:23 - Hasnain sayyed \nSynthetic profile, sorry.\n\n1:14:33 - Jorge Lewis \nAll right, so I'm going to copy this one.\n\n1:14:50 - Jorge Lewis \nOh, no, this is just, yeah.\n\n1:15:00 - Jorge Lewis \nI don't know how you guys don't use super base. I mean, I'll compile it.\n\n1:15:09 - Jorge Lewis \nProfile for, okay, so. Okay, so let's make a new file that generates a message. Message, yes. And then here we can just do prompt run.\n\n1:15:50 - Jorge Lewis \nAll right, so I've made just a simple run function and, or let me actually just.\n\n1:16:00 - Jorge Lewis \nAnd then, okay.\n\n1:16:17 - Jorge Lewis \nSorry, I'm messing up with your if code.\n\n1:16:26 - Unidentified Speaker \nWhy?\n\n1:16:27 - Jorge Lewis \nOh, are you error tracking or?\n\n1:16:42 - Hasnain sayyed \nShould I add this data types like synthetic user in the database.types? So this error will be gone.\n\n1:16:56 - Jorge Lewis \nLet me, I'm not seeing your screen. Over here. Yes. I don't have some of the highlighting because I'm on your live share.\n\n1:17:10 - Jorge Lewis \nGenerate the new types.\n\n1:17:13 - Jorge Lewis \nYes.\n\n1:17:15 - Jorge Lewis \nThat's a good idea.\n\n1:17:28 - Jorge Lewis \nIf there's only one super base call in the script or in the code, you don't want to name them. You can just leave them. So this is pretty, should be pretty obvious, I think.\n\n1:17:44 - Unidentified Speaker \nBye!\n\n1:18:18 - Jorge Lewis \nIt's now gone.\n\n1:19:11 - Hasnain sayyed \nWe have to create an agent which passes this message.\n\n1:19:18 - Hasnain sayyed \nOkay, yeah, it's generate message is there.\n\n1:19:30 - Jorge Lewis \nI'm not getting all of the error highlighting that you are by the way.\n\n1:20:48 - Hasnain sayyed \nWhat are we creating next?\n\n1:21:06 - Jorge Lewis \nNext is.\n\n1:21:16 - Jorge Lewis \nCould you keep sharing your screen? Because it was quite helpful.\n\n1:21:44 - Jorge Lewis \nOkay, so we're going to, what's the statement? So we have a message.\n\n1:22:11 - Jorge Lewis \nSo, imagine the message history is no messages, so we're going to have the synthetic user generate a message first, and then the AdaptBot will reply to it. We need to wrap all this in a for loop.\n\n1:22:32 - Jorge Lewis \nWhich one? This?\n\n1:22:35 - Jorge Lewis \nSo the synthetic user and the response to that need to be looped if we want to kind of have a conversation. So let's say we want to have a conversation of 10 messages.\n\n1:22:46 - Hasnain sayyed \nWe can just do a for loop for So based on the user response, maybe like Sorry, based on the user question, we can point like, yeah, it's 10. Or maybe a normal pointer while const let a is equal to 10.\n\n1:23:21 - Jorge Lewis \n2 Use a for loop, no?\n\n1:23:29 - Hasnain sayyed \nMaybe, yes.\n\n1:23:33 - Jorge Lewis \nI can't remember the syntax, though, so I'm going to search it up.\n\n1:23:39 - Jorge Lewis \nFor loop syntax, OK.\n\n1:23:44 - Hasnain sayyed \nIt's equal to 0, then 10.\n\n1:23:56 - Hasnain sayyed \nA plus plus.\n\n1:23:57 - Unidentified Speaker \nYeah.\n\n1:23:59 - Hasnain sayyed \nThis is the basic syntax and it will be running 10 times.\n\n1:24:09 - Hasnain sayyed \nThe messages will be passing through this and RES we have to store this thing because the run function is performing actions on this as well.\n\n1:24:35 - Hasnain sayyed \nOkay, we have events.\n\n1:24:44 - Hasnain sayyed \nThe one thing over here is, if you look my screen, yeah, so in the post chat, the events, it is storing the chat in events. So we have to club this ID to the events itself. Because the profile ID is also pointing to events.\n\n1:25:08 - Hasnain sayyed \nWhat do you mean?\n\n1:"}
02:07:12,535 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:12,537 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: , uh, in the synthetic user, it will be having a chat with, uh, AI agent, right. Uh, and the AI agent code won\'t invoke by itself. We have to, uh, create a flow between, uh, these two, uh, the synthetic and the AI agent. So, uh, in the current folder itself in the AI agent, uh, folder, there is a chat between real user and the AI agent. So the code for the AI agent will similar.\n\n1:07:24 - Unidentified Speaker \nYeah.\n\n1:07:32 - Jorge Lewis \nIn the AI folder, there\'s one function that\'s being called somewhere, run. So inside run.\n\n1:07:43 - Jorge Lewis \nThere\'s one function that\'s been called run. This is to interact with the chatbot. We\'re here, we\'re passing it profile ID, we\'re passing it user message and user examples prompt. Profile ID is the only thing that\'s going to be different.\n\n1:08:05 - Jorge Lewis \nSo in, within synthetic user, what we need to do is somehow call this run function, right? Correct.\n\n1:08:11 - Unidentified Speaker \nCorrect.\n\n1:08:13 - Jorge Lewis \nWe, in essence, we need to call the run function.\n\n1:08:16 - Hasnain sayyed \nSo, and the top layer will just be the like, the edge case function that I have talked like one day, one conversation, like one day, one session, the top layer will be that the edge case condition. And we just have to create a loop over here because in this file, it\'s just a one case scenario, like a one way scenario. It\'s not a loop where it\'s just a HTTP request, like pointing, running this function and getting the return for one conversation. But we have to create a loop kind of thing over here.\n\n1:08:54 - Hasnain sayyed \nBased on time.\n\n1:08:58 - Jorge Lewis \nAs we discussed, 30 seconds or 1 minute.\n\n1:09:09 - Jorge Lewis \nAs I said, we have to reduce the scope right now. We want to focus on one thing right now. When you\'re developing software, if you\'re worrying about all the 30 different things that have to be made, You\'re never going to make one thing. Right now, we want to get a conversation happening between the bot and the user. Then we can worry about adding in time into the code. So we need to isolate small things to make.\n\n1:09:35 - Hasnain sayyed \nShould I copy paste this thing over here?\n\n1:09:42 - Jorge Lewis \nThis function? No, no.\n\n1:09:48 - Hasnain sayyed \nI just have to change this thing. The user message will be not the parameter itself. It will be the previous. We will be getting it from the database or the few short.\n\n1:10:07 - Hasnain sayyed \nWhat do you mean, few short?\n\n1:10:09 - Hasnain sayyed \nThe database, like the prompt that a Q1 is adding from the dashboard.\n\n1:10:18 - Hasnain sayyed \nThe user message will be, in the real use case, will be passed by the real user, right? But in the synthetic user, it doesn\'t have any, like, the user message from the real user. We have to get it from database, which will be in the scenario of future.\n\n1:10:36 - Jorge Lewis \nFor the synthetic user, we should be using a language model. There should be an agent.\n\n1:10:44 - Hasnain sayyed \nOK.\n\n1:10:47 - Hasnain sayyed \nSo based on the- Yeah.\n\n1:10:55 - Jorge Lewis \nBecause we\'re trying to pretend this guy\'s a user. There\'s no reason not to use a language model. We\'re trying to create new data, not reuse old data.\n\n1:11:11 - Jorge Lewis \nGot it.\n\n1:11:13 - Jorge Lewis \nI was just saying- So I\'m going to try to kind of start you off and see if it makes sense. So we have this run function that\'s being called by the dev bot. Let\'s go into the simple dev user. Let\'s import that function.\n\n1:11:34 - Jorge Lewis \nLet me enable my copilot.\n\n1:11:57 - Jorge Lewis \nOh, my co-pilot subscription ended.\n\n1:12:28 - Jorge Lewis \nAnd then here, we know we want to call run. What are the properties?\n\n1:12:41 - Jorge Lewis \nThese are profile ID, so it\'s a string ID. What else?\n\n1:12:53 - Jorge Lewis \nUser message.\n\n1:12:56 - Jorge Lewis \nSo we need to message to do AI generated message.\n\n1:13:07 - Jorge Lewis \nAnd then use example prompts just do hmm. What does that mean?\n\n1:13:12 - Unidentified Speaker \nOh?\n\n1:13:15 - Hasnain sayyed \nIt\'s just a boolean template.\n\n1:13:17 - Jorge Lewis \nYeah false okay, so So we have this here const ID is So we need to get this ID from a We need to get this ID from SuperBase.\n\n1:13:39 - Hasnain sayyed \nYeah, so just right here, maybe.\n\n1:13:48 - Jorge Lewis \nSo for now, let\'s use a hard-coded ID. So I\'m going to go into SuperBase and\n######################\nOutput:'}
02:07:12,537 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:12,540 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ", uh, in the synthetic user, it will be having a chat with, uh, AI agent, right. Uh, and the AI agent code won't invoke by itself. We have to, uh, create a flow between, uh, these two, uh, the synthetic and the AI agent. So, uh, in the current folder itself in the AI agent, uh, folder, there is a chat between real user and the AI agent. So the code for the AI agent will similar.\n\n1:07:24 - Unidentified Speaker \nYeah.\n\n1:07:32 - Jorge Lewis \nIn the AI folder, there's one function that's being called somewhere, run. So inside run.\n\n1:07:43 - Jorge Lewis \nThere's one function that's been called run. This is to interact with the chatbot. We're here, we're passing it profile ID, we're passing it user message and user examples prompt. Profile ID is the only thing that's going to be different.\n\n1:08:05 - Jorge Lewis \nSo in, within synthetic user, what we need to do is somehow call this run function, right? Correct.\n\n1:08:11 - Unidentified Speaker \nCorrect.\n\n1:08:13 - Jorge Lewis \nWe, in essence, we need to call the run function.\n\n1:08:16 - Hasnain sayyed \nSo, and the top layer will just be the like, the edge case function that I have talked like one day, one conversation, like one day, one session, the top layer will be that the edge case condition. And we just have to create a loop over here because in this file, it's just a one case scenario, like a one way scenario. It's not a loop where it's just a HTTP request, like pointing, running this function and getting the return for one conversation. But we have to create a loop kind of thing over here.\n\n1:08:54 - Hasnain sayyed \nBased on time.\n\n1:08:58 - Jorge Lewis \nAs we discussed, 30 seconds or 1 minute.\n\n1:09:09 - Jorge Lewis \nAs I said, we have to reduce the scope right now. We want to focus on one thing right now. When you're developing software, if you're worrying about all the 30 different things that have to be made, You're never going to make one thing. Right now, we want to get a conversation happening between the bot and the user. Then we can worry about adding in time into the code. So we need to isolate small things to make.\n\n1:09:35 - Hasnain sayyed \nShould I copy paste this thing over here?\n\n1:09:42 - Jorge Lewis \nThis function? No, no.\n\n1:09:48 - Hasnain sayyed \nI just have to change this thing. The user message will be not the parameter itself. It will be the previous. We will be getting it from the database or the few short.\n\n1:10:07 - Hasnain sayyed \nWhat do you mean, few short?\n\n1:10:09 - Hasnain sayyed \nThe database, like the prompt that a Q1 is adding from the dashboard.\n\n1:10:18 - Hasnain sayyed \nThe user message will be, in the real use case, will be passed by the real user, right? But in the synthetic user, it doesn't have any, like, the user message from the real user. We have to get it from database, which will be in the scenario of future.\n\n1:10:36 - Jorge Lewis \nFor the synthetic user, we should be using a language model. There should be an agent.\n\n1:10:44 - Hasnain sayyed \nOK.\n\n1:10:47 - Hasnain sayyed \nSo based on the- Yeah.\n\n1:10:55 - Jorge Lewis \nBecause we're trying to pretend this guy's a user. There's no reason not to use a language model. We're trying to create new data, not reuse old data.\n\n1:11:11 - Jorge Lewis \nGot it.\n\n1:11:13 - Jorge Lewis \nI was just saying- So I'm going to try to kind of start you off and see if it makes sense. So we have this run function that's being called by the dev bot. Let's go into the simple dev user. Let's import that function.\n\n1:11:34 - Jorge Lewis \nLet me enable my copilot.\n\n1:11:57 - Jorge Lewis \nOh, my co-pilot subscription ended.\n\n1:12:28 - Jorge Lewis \nAnd then here, we know we want to call run. What are the properties?\n\n1:12:41 - Jorge Lewis \nThese are profile ID, so it's a string ID. What else?\n\n1:12:53 - Jorge Lewis \nUser message.\n\n1:12:56 - Jorge Lewis \nSo we need to message to do AI generated message.\n\n1:13:07 - Jorge Lewis \nAnd then use example prompts just do hmm. What does that mean?\n\n1:13:12 - Unidentified Speaker \nOh?\n\n1:13:15 - Hasnain sayyed \nIt's just a boolean template.\n\n1:13:17 - Jorge Lewis \nYeah false okay, so So we have this here const ID is So we need to get this ID from a We need to get this ID from SuperBase.\n\n1:13:39 - Hasnain sayyed \nYeah, so just right here, maybe.\n\n1:13:48 - Jorge Lewis \nSo for now, let's use a hard-coded ID. So I'm going to go into SuperBase and"}
02:07:16,23 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:16,27 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Hasnain sayyed \nOkay, we have events.\n\n1:24:44 - Hasnain sayyed \nThe one thing over here is, if you look my screen, yeah, so in the post chat, the events, it is storing the chat in events. So we have to club this ID to the events itself. Because the profile ID is also pointing to events.\n\n1:25:08 - Hasnain sayyed \nWhat do you mean?\n\n1:25:10 - Hasnain sayyed \nLike the history, the chat history is being stored in this event table. Yep. So this profile ID has a foreign key in this events.\n\n1:25:27 - Hasnain sayyed \nDoes it?\n\n1:25:28 - Hasnain sayyed \nYeah.\n\n1:25:38 - Hasnain sayyed \nWhere is that?\n\n1:25:41 - Hasnain sayyed \nOk, so it\'s externally storing. I failed. I thought.\n\n1:25:52 - Jorge Lewis \nOK. So it is linked, though. It is linked. Go back to Superbase. There\'s a green icon next to it. That means it\'s linked. That means there\'s a foreign key.\n\n1:26:01 - Jorge Lewis \nSo no, on profile ID, that green icon, that means it\'s linked. No, no, no. Back where you were. Do you see the icon? Yeah, yeah. It\'s a foreign key with profile. So let\'s open up that detail of the column so that we can modify it. Because if it\'s foreign link to profile table, that means we can\'t add events from our synthetic user, which we want to. So let\'s see if we can add a foreign link.\n\n1:26:28 - Jorge Lewis \nYeah, yeah, there we go.\n\n1:26:29 - Unidentified Speaker \nNice.\n\n1:26:31 - Hasnain sayyed \nSelect table profile.\n\n1:26:38 - Jorge Lewis \nOh, yes. Should I save?\n\n1:26:41 - Unidentified Speaker \nYeah.\n\n1:26:47 - Hasnain sayyed \nId is in public. Yes. Cool. Hm.\n\n1:27:09 - Jorge Lewis \nI\'m going to profile ID.\n\n1:27:13 - Jorge Lewis \nInsert or update.\n\n1:27:17 - Jorge Lewis \nWait, save again? I couldn\'t finish reading the error.\n\n1:27:26 - Jorge Lewis \nFile is foreign key constraint.\n\n1:27:37 - Jorge Lewis \nLet me see...\n\n1:27:49 - Jorge Lewis \nBecause if that doesn\'t work, but it should, if that doesn\'t work...\n\n1:27:55 - Jorge Lewis \nI think the problem is that there\'s already items in that...\n\n1:28:09 - Jorge Lewis \nThere\'s already items in the table, which means that it can\'t switch it. So what we have to do is either delete all the items. Is that OK? Can we do that?\n\n1:28:32 - Hasnain sayyed \nYes, or else we can\'t edit this thing. Can\'t edit the value.\n\n1:28:40 - Jorge Lewis \nUm, so the only thing is if Kuhn is testing it, but I don\'t think he is. So let\'s just delete everything.\n\n1:28:47 - Hasnain sayyed \nAnd if he says, why did you delete everything that we say in the synthetic profile, uh, we can delete and we can check, uh, if it\'s added because I feel, uh, the ID is similar, uh, but that doesn\'t the case.\n\n1:29:10 - Hasnain sayyed \nlet me delete this and try in the synthetic.\n\n1:29:14 - Jorge Lewis \nNo, the problem was because every row in the, or every row in the events table was linked, was a foreign key link to the profile ID. The structure of the cell was a foreign key link to profile ID. It was not foreign key. I wasn\'t a foreign key link to profile ID or, um, Uh, forward key to the profile ID or the synthetic profile ID. So now it is because I deleted all the events.\n\n1:29:44 - Unidentified Speaker \nOkay.\n\n1:29:44 - Jorge Lewis \nSo now we shouldn\'t have an issue with it.\n\n1:30:33 - Hasnain sayyed \nOkay, so we can copy this supervisor agent code over here, because whoa, in this file, what say there\'s there\'s Sorry, I was just looking at the code.\n\n1:31:02 - Jorge Lewis \nThere\'s a lot of, there\'s a prompt. So, okay. I see. Huh? So you know how, you know that we\'re exposing the prompts on the front end, right?\n\n1:31:13 - Hasnain sayyed \nHmm.\n\n1:31:15 - Jorge Lewis \nYeah. So, so I saw that under supervisor, there is a lot of, there is, um, his system. What is this? Yeah. So, so if you follow me, Hmm. So here we give it its prompts here, but then we\'re also giving it more. This should be, we should try to, this is kind of as a backlog. I know this is probably temporary, but there should be a backlog for somebody to migrate it to the front end because we want everything, all the prompts to be exposed to the front end. So yeah, we need to.\n\n1:31:55 - Hasnain sayyed \nOn\n######################\nOutput:'}
02:07:16,27 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:16,31 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Hasnain sayyed \nOkay, we have events.\n\n1:24:44 - Hasnain sayyed \nThe one thing over here is, if you look my screen, yeah, so in the post chat, the events, it is storing the chat in events. So we have to club this ID to the events itself. Because the profile ID is also pointing to events.\n\n1:25:08 - Hasnain sayyed \nWhat do you mean?\n\n1:25:10 - Hasnain sayyed \nLike the history, the chat history is being stored in this event table. Yep. So this profile ID has a foreign key in this events.\n\n1:25:27 - Hasnain sayyed \nDoes it?\n\n1:25:28 - Hasnain sayyed \nYeah.\n\n1:25:38 - Hasnain sayyed \nWhere is that?\n\n1:25:41 - Hasnain sayyed \nOk, so it's externally storing. I failed. I thought.\n\n1:25:52 - Jorge Lewis \nOK. So it is linked, though. It is linked. Go back to Superbase. There's a green icon next to it. That means it's linked. That means there's a foreign key.\n\n1:26:01 - Jorge Lewis \nSo no, on profile ID, that green icon, that means it's linked. No, no, no. Back where you were. Do you see the icon? Yeah, yeah. It's a foreign key with profile. So let's open up that detail of the column so that we can modify it. Because if it's foreign link to profile table, that means we can't add events from our synthetic user, which we want to. So let's see if we can add a foreign link.\n\n1:26:28 - Jorge Lewis \nYeah, yeah, there we go.\n\n1:26:29 - Unidentified Speaker \nNice.\n\n1:26:31 - Hasnain sayyed \nSelect table profile.\n\n1:26:38 - Jorge Lewis \nOh, yes. Should I save?\n\n1:26:41 - Unidentified Speaker \nYeah.\n\n1:26:47 - Hasnain sayyed \nId is in public. Yes. Cool. Hm.\n\n1:27:09 - Jorge Lewis \nI'm going to profile ID.\n\n1:27:13 - Jorge Lewis \nInsert or update.\n\n1:27:17 - Jorge Lewis \nWait, save again? I couldn't finish reading the error.\n\n1:27:26 - Jorge Lewis \nFile is foreign key constraint.\n\n1:27:37 - Jorge Lewis \nLet me see...\n\n1:27:49 - Jorge Lewis \nBecause if that doesn't work, but it should, if that doesn't work...\n\n1:27:55 - Jorge Lewis \nI think the problem is that there's already items in that...\n\n1:28:09 - Jorge Lewis \nThere's already items in the table, which means that it can't switch it. So what we have to do is either delete all the items. Is that OK? Can we do that?\n\n1:28:32 - Hasnain sayyed \nYes, or else we can't edit this thing. Can't edit the value.\n\n1:28:40 - Jorge Lewis \nUm, so the only thing is if Kuhn is testing it, but I don't think he is. So let's just delete everything.\n\n1:28:47 - Hasnain sayyed \nAnd if he says, why did you delete everything that we say in the synthetic profile, uh, we can delete and we can check, uh, if it's added because I feel, uh, the ID is similar, uh, but that doesn't the case.\n\n1:29:10 - Hasnain sayyed \nlet me delete this and try in the synthetic.\n\n1:29:14 - Jorge Lewis \nNo, the problem was because every row in the, or every row in the events table was linked, was a foreign key link to the profile ID. The structure of the cell was a foreign key link to profile ID. It was not foreign key. I wasn't a foreign key link to profile ID or, um, Uh, forward key to the profile ID or the synthetic profile ID. So now it is because I deleted all the events.\n\n1:29:44 - Unidentified Speaker \nOkay.\n\n1:29:44 - Jorge Lewis \nSo now we shouldn't have an issue with it.\n\n1:30:33 - Hasnain sayyed \nOkay, so we can copy this supervisor agent code over here, because whoa, in this file, what say there's there's Sorry, I was just looking at the code.\n\n1:31:02 - Jorge Lewis \nThere's a lot of, there's a prompt. So, okay. I see. Huh? So you know how, you know that we're exposing the prompts on the front end, right?\n\n1:31:13 - Hasnain sayyed \nHmm.\n\n1:31:15 - Jorge Lewis \nYeah. So, so I saw that under supervisor, there is a lot of, there is, um, his system. What is this? Yeah. So, so if you follow me, Hmm. So here we give it its prompts here, but then we're also giving it more. This should be, we should try to, this is kind of as a backlog. I know this is probably temporary, but there should be a backlog for somebody to migrate it to the front end because we want everything, all the prompts to be exposed to the front end. So yeah, we need to.\n\n1:31:55 - Hasnain sayyed \nOn"}
02:07:16,99 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:16,100 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: :23 - Jorge Lewis \nYeah, so you can share your whole screen. I can follow along with the docs that you\'re looking at.\n\n20:29 - Jorge Lewis \nOK.\n\n20:32 - Will Vincent Parrone \nWait, let me just clean up my tabs.\n\n20:39 - Will Vincent Parrone \nThere we go, all nice and clean. Mm-hmm.\n\n20:51 - Will Vincent Parrone \nStop presenting.\n\n20:58 - Will Vincent Parrone \nOK. Let\'s test this on superbase. Superbase hot documentation.\n\n21:18 - Will Vincent Parrone \nWait.\n\n21:20 - Will Vincent Parrone \nIf we\'re going to be including multiple ways to sign in, then here in the architecture, the sign-in page should have multiple pages, right? Like sign-in. There\'s going to be a sign-in page. And then if, let\'s say, the user opts for an OTP, well, I\'m going to be creating another OTP page.\n\n21:46 - Jorge Lewis \nYeah. Let me share with you the code of the other project of Aetina where we did the Google authentication. We did Google and GitHub authentication for that project.\n\n21:56 - Will Vincent Parrone \nOh, okay.\n\n22:02 - Jorge Lewis \nDo you have access to the Aetina repository?\n\n22:07 - Will Vincent Parrone \nI think I have access already to... Wait, I\'m just going to be yanking this.\n\n22:17 - Will Vincent Parrone \nOh yeah, I think I have access to this 13 repositories already. All right, perfect. Let me double check. I might be wrong.\n\n22:28 - Jorge Lewis \nI sent you a link as well if you need it.\n\n22:36 - Jorge Lewis \nAnd Discord, sorry.\n\n22:42 - Will Vincent Parrone \nAh, here we go.\n\n22:46 - Will Vincent Parrone \nRepositories, Aitino.\n\n22:50 - Will Vincent Parrone \nHere we go. This is a public? Okay.\n\n22:53 - Jorge Lewis \nOh, it\'s public. Do you have access to... Oh, actually, no, you just need to read it, yeah?\n\n23:03 - Jorge Lewis \nSo, yeah, I don\'t know...\n\n23:11 - Jorge Lewis \nMy God, stop.\n\n23:14 - Will Vincent Parrone \nAh, here we go.\n\n23:19 - Will Vincent Parrone \nI will data form form that register.\n\n23:34 - Jorge Lewis \nHow about this? Um, so it\'s this, this off, it takes a lot of learning. And I think the pair programming sessions while sometimes you probably do want to do learning together. I think a more efficient, especially since we\'re just starting off with these sessions, is by actually writing some code. So I think what we can do is we can work on the, remember that to-do toggle, or that done toggle that I told you about on Peres, the Read.AI project? Could we work on that instead?\n\n23:59 - Will Vincent Parrone \nOh yeah, wait, wait, wait.\n\n24:02 - Will Vincent Parrone \nLet me pull it then. Repositories.\n\n24:09 - Will Vincent Parrone \nRead.AI tool.\n\n24:15 - Will Vincent Parrone \nYeah, are you okay with extending it, like, 15 minutes, given the, you know?\n\n24:19 - Jorge Lewis \nYeah, yeah, for sure. I should be able to. I just have a couple meetings with some people, but it should be good, if you want.\n\n24:30 - Will Vincent Parrone \nOkay.\n\n24:33 - Will Vincent Parrone \nReddit, tool, tmux, new, s, reddit, tool, tntm, install, And then, no package manage, oh yeah, right, right, cduel.\n\n25:04 - Will Vincent Parrone \nOh, wait, are we using, what are we using here?\n\n25:14 - Will Vincent Parrone \nIn order for me to test this app properly, I have to do some CSRF.\n\n25:29 - Will Vincent Parrone \nShow config false.\n\n25:42 - Will Vincent Parrone \nRun dev. Nope.\n\n25:46 - Will Vincent Parrone \nRun dev.\n\n25:49 - Jorge Lewis \nVery annoyed of you.\n\n25:54 - Will Vincent Parrone \nHuh.\n\n25:55 - Will Vincent Parrone \nUnexpected token starting dev server. Okay, got it.\n\n26:03 - Will Vincent Parrone \nAnd then we\'re gonna do something in Nginx.\n\n26:07 - Will Vincent Parrone \nHuh.\n\n26:09 - Will Vincent Parrone \nStarting dev server.\n\n26:18 - Will Vincent Parrone \nNew GitHub copilot was found.\n\n26:23 - Will Vincent Parrone \nOkay, I\'ll just quit everything.\n\n26:25 - Unidentified Speaker \nYep.\n\n26:29 - Will Vincent Parrone \nClear, clear.\n\n26:34 - Will Vincent Parrone \nWhat\'s wrong again?\n\n26:46 - Will Vincent Parrone \nsvelte.config.js, delete it.\n\n26:52 - Will Vincent Parrone \nHere we go.\n\n26:57 - Will Vincent Parrone \nAnd then something within the nginx file, sudo vim etc nginx. It\'s still wrong.\n\n27:09 - Will Vincent Parrone \nIs there no show config? I might have I might have CSRFs.\n\n27:31 - Will Vincent Parrone \nOh, check origin.\n\n27:33 - Jorge Lewis \nWhat\'s the CSRF? I\'ve never seen it before.\n\n27:37 - Will Vincent Parrone \nIt\'s basically the course, it\'s course related because I\'m not\n######################\nOutput:'}
02:07:16,101 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:16,104 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ":23 - Jorge Lewis \nYeah, so you can share your whole screen. I can follow along with the docs that you're looking at.\n\n20:29 - Jorge Lewis \nOK.\n\n20:32 - Will Vincent Parrone \nWait, let me just clean up my tabs.\n\n20:39 - Will Vincent Parrone \nThere we go, all nice and clean. Mm-hmm.\n\n20:51 - Will Vincent Parrone \nStop presenting.\n\n20:58 - Will Vincent Parrone \nOK. Let's test this on superbase. Superbase hot documentation.\n\n21:18 - Will Vincent Parrone \nWait.\n\n21:20 - Will Vincent Parrone \nIf we're going to be including multiple ways to sign in, then here in the architecture, the sign-in page should have multiple pages, right? Like sign-in. There's going to be a sign-in page. And then if, let's say, the user opts for an OTP, well, I'm going to be creating another OTP page.\n\n21:46 - Jorge Lewis \nYeah. Let me share with you the code of the other project of Aetina where we did the Google authentication. We did Google and GitHub authentication for that project.\n\n21:56 - Will Vincent Parrone \nOh, okay.\n\n22:02 - Jorge Lewis \nDo you have access to the Aetina repository?\n\n22:07 - Will Vincent Parrone \nI think I have access already to... Wait, I'm just going to be yanking this.\n\n22:17 - Will Vincent Parrone \nOh yeah, I think I have access to this 13 repositories already. All right, perfect. Let me double check. I might be wrong.\n\n22:28 - Jorge Lewis \nI sent you a link as well if you need it.\n\n22:36 - Jorge Lewis \nAnd Discord, sorry.\n\n22:42 - Will Vincent Parrone \nAh, here we go.\n\n22:46 - Will Vincent Parrone \nRepositories, Aitino.\n\n22:50 - Will Vincent Parrone \nHere we go. This is a public? Okay.\n\n22:53 - Jorge Lewis \nOh, it's public. Do you have access to... Oh, actually, no, you just need to read it, yeah?\n\n23:03 - Jorge Lewis \nSo, yeah, I don't know...\n\n23:11 - Jorge Lewis \nMy God, stop.\n\n23:14 - Will Vincent Parrone \nAh, here we go.\n\n23:19 - Will Vincent Parrone \nI will data form form that register.\n\n23:34 - Jorge Lewis \nHow about this? Um, so it's this, this off, it takes a lot of learning. And I think the pair programming sessions while sometimes you probably do want to do learning together. I think a more efficient, especially since we're just starting off with these sessions, is by actually writing some code. So I think what we can do is we can work on the, remember that to-do toggle, or that done toggle that I told you about on Peres, the Read.AI project? Could we work on that instead?\n\n23:59 - Will Vincent Parrone \nOh yeah, wait, wait, wait.\n\n24:02 - Will Vincent Parrone \nLet me pull it then. Repositories.\n\n24:09 - Will Vincent Parrone \nRead.AI tool.\n\n24:15 - Will Vincent Parrone \nYeah, are you okay with extending it, like, 15 minutes, given the, you know?\n\n24:19 - Jorge Lewis \nYeah, yeah, for sure. I should be able to. I just have a couple meetings with some people, but it should be good, if you want.\n\n24:30 - Will Vincent Parrone \nOkay.\n\n24:33 - Will Vincent Parrone \nReddit, tool, tmux, new, s, reddit, tool, tntm, install, And then, no package manage, oh yeah, right, right, cduel.\n\n25:04 - Will Vincent Parrone \nOh, wait, are we using, what are we using here?\n\n25:14 - Will Vincent Parrone \nIn order for me to test this app properly, I have to do some CSRF.\n\n25:29 - Will Vincent Parrone \nShow config false.\n\n25:42 - Will Vincent Parrone \nRun dev. Nope.\n\n25:46 - Will Vincent Parrone \nRun dev.\n\n25:49 - Jorge Lewis \nVery annoyed of you.\n\n25:54 - Will Vincent Parrone \nHuh.\n\n25:55 - Will Vincent Parrone \nUnexpected token starting dev server. Okay, got it.\n\n26:03 - Will Vincent Parrone \nAnd then we're gonna do something in Nginx.\n\n26:07 - Will Vincent Parrone \nHuh.\n\n26:09 - Will Vincent Parrone \nStarting dev server.\n\n26:18 - Will Vincent Parrone \nNew GitHub copilot was found.\n\n26:23 - Will Vincent Parrone \nOkay, I'll just quit everything.\n\n26:25 - Unidentified Speaker \nYep.\n\n26:29 - Will Vincent Parrone \nClear, clear.\n\n26:34 - Will Vincent Parrone \nWhat's wrong again?\n\n26:46 - Will Vincent Parrone \nsvelte.config.js, delete it.\n\n26:52 - Will Vincent Parrone \nHere we go.\n\n26:57 - Will Vincent Parrone \nAnd then something within the nginx file, sudo vim etc nginx. It's still wrong.\n\n27:09 - Will Vincent Parrone \nIs there no show config? I might have I might have CSRFs.\n\n27:31 - Will Vincent Parrone \nOh, check origin.\n\n27:33 - Jorge Lewis \nWhat's the CSRF? I've never seen it before.\n\n27:37 - Will Vincent Parrone \nIt's basically the course, it's course related because I'm not"}
02:07:16,129 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:16,131 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: .\n\n18:32 - Jorge Lewis \nOh, so what we also need to do, which is quite important, is simulating multiple days because the chapel actually uses time.\n\n18:47 - Jorge Lewis \nWe need to make sure that... Because if they just keep chatting, there won\'t be, for example, a new check-in, right? Because check-ins are made on a day.\n\n18:58 - Jorge Lewis \nWe need a way to...\n\n19:07 - Hasnain sayyed \na way to simulate time to control time based on time interval we can have the chatting with the synthetic like per day or one hour two hour maybe maybe even like per 10 minutes right oh yeah 10 minutes Um...\n\n19:59 - Hasnain sayyed \nBut over here, every synthetic user will have a different kind of personality, right? Like the few short.\n\n20:08 - Jorge Lewis \nSo I don\'t understand that part. I don\'t, I don\'t think so. Can you, can you kind of keep going?\n\n20:13 - Hasnain sayyed \nYeah. So, so like if admin has the capability to create multiple synthetic users, so each user which is created will have a similar kind of personality or like the talking or the chatting way, like the few shots that we are giving to each synthetic user, like the history or data or each synthetic user will have a different kind of knowledge.\n\n20:43 - Jorge Lewis \nUm, they, they should be mostly the same. So like, um, let me come up a little wireframe here. How do I, So we have, so we can give it name.\n\n21:09 - Hasnain sayyed \nWe can give it personality.\n\n21:14 - Jorge Lewis \nWe can give it goal. It\'s objective. So this, just a little note.\n\n21:25 - Jorge Lewis \nObjective is a behavior of adapt that the synthetic user is trying to test or exploit. What else?\n\n22:06 - Jorge Lewis \nI guess the profile information, so just the stuff that\'s in the super base in the profile table. So every user has, so we need to assign it like things like it\'s goal.\n\n22:32 - Jorge Lewis \nLet me just check. Ah, I\'m going to have to sign in. But you get what I mean. Within the profile information, there\'s their goal, their Y, weight, height.\n\n22:57 - Jorge Lewis \nBasic onboarding.\n\n22:59 - Jorge Lewis \nYeah, like all the information we gather from the onboarding, exactly. So what else?\n\n23:06 - Jorge Lewis \nI guess it\'s a list that we can copy from onboarding. So I think with that, there\'s probably going to be things that pop up that we can\'t see right now, but I think we might as well get started in this development. There\'s some things we can start on.\n\n23:25 - Jorge Lewis \nYeah.\n\n23:30 - Jorge Lewis \nSo one thing, since we\'re working on the AI stuff only, for creating synthetics users, we can, since we don\'t want to work on any of the front end, we can just use directly in super base. We can manually create a table and manual create rows. All right. So I\'ll hand it off to you. Yeah. So we\'ll, There\'s different ways pair programming sessions work. You can do like pilot driver or what is it? Driver. I don\'t know, but what I\'m going to do is I\'m going to let you lead the way and I\'m going to kind of chime in here and there.\n\n24:14 - Hasnain sayyed \nOkay. So, uh, what things should I start with? Like\n\n24:22 - Hasnain sayyed \nCan we just create the flow like the first we will be working on this, then this, then this, because there are multiple things in this module.\n\n24:38 - Jorge Lewis \nLet\'s create a very basic system. So what do we need in order to simulate a conversation? What is the requirement?\n\n24:47 - Hasnain sayyed \nThe first thing is data, of course, because, uh, it is a fake user, first of all. So, uh, the table that you have created, we need that then the prompt, uh, the basic few short, like, uh, the knowledge, uh, on the basis of which the fake user will chat with the agent. So that\'s the main thing. And, uh, uh, the function functionality, like, uh, to automate this thing, uh, because, uh, the API only hits when, uh, event on click event will trigger. So we have to create a functionality for that. Uh, so that, uh, on each day, 10 minutes.\n\n25:24 - Jorge Lewis \nThe, the, the one where we, because the user we\'re not, we don\'t have a real user anymore. We\'re not sending a message. So we have our AI system and we have the user, but we probably use it more. So we\'re going to have to replace it with the synthetic user.\n\n25:43 - Hasnain sayyed \nYeah, correct. So that\'s what I\'m telling. We have to create a function. So then we can start with that.\n\n25:51 - Unidentified Speaker \nOkay.\n\n25:53 - Jorge Lewis \nYeah, keep going. Which one? We\'re going to have to probably work and make, yeah.\n\n26:04 - Jorge Lewis \nYour voice is breaking. We\'re going to, we\'re going to have to work.\n\n26:09 - Jorge Lewis \nNo, it\'s cause I think\n######################\nOutput:'}
02:07:16,132 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:16,136 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ".\n\n18:32 - Jorge Lewis \nOh, so what we also need to do, which is quite important, is simulating multiple days because the chapel actually uses time.\n\n18:47 - Jorge Lewis \nWe need to make sure that... Because if they just keep chatting, there won't be, for example, a new check-in, right? Because check-ins are made on a day.\n\n18:58 - Jorge Lewis \nWe need a way to...\n\n19:07 - Hasnain sayyed \na way to simulate time to control time based on time interval we can have the chatting with the synthetic like per day or one hour two hour maybe maybe even like per 10 minutes right oh yeah 10 minutes Um...\n\n19:59 - Hasnain sayyed \nBut over here, every synthetic user will have a different kind of personality, right? Like the few short.\n\n20:08 - Jorge Lewis \nSo I don't understand that part. I don't, I don't think so. Can you, can you kind of keep going?\n\n20:13 - Hasnain sayyed \nYeah. So, so like if admin has the capability to create multiple synthetic users, so each user which is created will have a similar kind of personality or like the talking or the chatting way, like the few shots that we are giving to each synthetic user, like the history or data or each synthetic user will have a different kind of knowledge.\n\n20:43 - Jorge Lewis \nUm, they, they should be mostly the same. So like, um, let me come up a little wireframe here. How do I, So we have, so we can give it name.\n\n21:09 - Hasnain sayyed \nWe can give it personality.\n\n21:14 - Jorge Lewis \nWe can give it goal. It's objective. So this, just a little note.\n\n21:25 - Jorge Lewis \nObjective is a behavior of adapt that the synthetic user is trying to test or exploit. What else?\n\n22:06 - Jorge Lewis \nI guess the profile information, so just the stuff that's in the super base in the profile table. So every user has, so we need to assign it like things like it's goal.\n\n22:32 - Jorge Lewis \nLet me just check. Ah, I'm going to have to sign in. But you get what I mean. Within the profile information, there's their goal, their Y, weight, height.\n\n22:57 - Jorge Lewis \nBasic onboarding.\n\n22:59 - Jorge Lewis \nYeah, like all the information we gather from the onboarding, exactly. So what else?\n\n23:06 - Jorge Lewis \nI guess it's a list that we can copy from onboarding. So I think with that, there's probably going to be things that pop up that we can't see right now, but I think we might as well get started in this development. There's some things we can start on.\n\n23:25 - Jorge Lewis \nYeah.\n\n23:30 - Jorge Lewis \nSo one thing, since we're working on the AI stuff only, for creating synthetics users, we can, since we don't want to work on any of the front end, we can just use directly in super base. We can manually create a table and manual create rows. All right. So I'll hand it off to you. Yeah. So we'll, There's different ways pair programming sessions work. You can do like pilot driver or what is it? Driver. I don't know, but what I'm going to do is I'm going to let you lead the way and I'm going to kind of chime in here and there.\n\n24:14 - Hasnain sayyed \nOkay. So, uh, what things should I start with? Like\n\n24:22 - Hasnain sayyed \nCan we just create the flow like the first we will be working on this, then this, then this, because there are multiple things in this module.\n\n24:38 - Jorge Lewis \nLet's create a very basic system. So what do we need in order to simulate a conversation? What is the requirement?\n\n24:47 - Hasnain sayyed \nThe first thing is data, of course, because, uh, it is a fake user, first of all. So, uh, the table that you have created, we need that then the prompt, uh, the basic few short, like, uh, the knowledge, uh, on the basis of which the fake user will chat with the agent. So that's the main thing. And, uh, uh, the function functionality, like, uh, to automate this thing, uh, because, uh, the API only hits when, uh, event on click event will trigger. So we have to create a functionality for that. Uh, so that, uh, on each day, 10 minutes.\n\n25:24 - Jorge Lewis \nThe, the, the one where we, because the user we're not, we don't have a real user anymore. We're not sending a message. So we have our AI system and we have the user, but we probably use it more. So we're going to have to replace it with the synthetic user.\n\n25:43 - Hasnain sayyed \nYeah, correct. So that's what I'm telling. We have to create a function. So then we can start with that.\n\n25:51 - Unidentified Speaker \nOkay.\n\n25:53 - Jorge Lewis \nYeah, keep going. Which one? We're going to have to probably work and make, yeah.\n\n26:04 - Jorge Lewis \nYour voice is breaking. We're going to, we're going to have to work.\n\n26:09 - Jorge Lewis \nNo, it's cause I think"}
02:07:16,147 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:16,149 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: practice is before you go to production, you want to turn all those on, but\n\n33:41 - Jorge Lewis \nHmm. Correct.\n\n33:45 - Hasnain sayyed \nSo the, attributes will be, ID is already there, created at.\n\n33:54 - Jorge Lewis \nSo this is going to be the same as, um, actually we kind of did a little bit. We need the name, personality, or anything.\n\n34:05 - Hasnain sayyed \nCan you copy paste over here? It will be fast. Like the name of columns, because it needs to be similar.\n\n34:18 - Jorge Lewis \nThe, um, I\'m still trying to sign into the super basic account. Um, does super base have like sign in with, uh, Google?\n\n34:33 - Jorge Lewis \nYeah, yeah, it has.\n\n34:37 - Jorge Lewis \nYeah, that\'s exactly, but I can\'t see it.\n\n34:41 - Jorge Lewis \nUm, no, I mean like, it\'s its own platform.\n\n34:52 - Hasnain sayyed \nOh, so I don\'t think so.\n\n35:07 - Hasnain sayyed \nOr else I can copy paste over here.\n\n35:10 - Jorge Lewis \nUm, Oh, there we go. I\'m in. Nice.\n\n35:41 - Hasnain sayyed \nI\'m just writing the column attribute. So I just copy paste.\n\n35:51 - Jorge Lewis \nWhat I want to note on though, what I want to note on is that this synthetic user for example first name and last name hmm they don\'t need to be separate I think what do you think like or actually\n\n36:09 - Hasnain sayyed \nhuh actually no they do yeah I think it needs to be identical to the profile table yeah yeah um Because the functions, uh, if they\'re going to be using the first name, it\'s not using, uh, it\'s needs to be similar because there will be other, uh, the data is null. Okay.\n\n36:32 - Jorge Lewis \nYeah, exactly. So what I\'ve also noticed though, is that the code right now is using, um, is using the profiles table, right? So if we want to make it use the Profiles table or the synthetic user table without having to rewrite all the code Should we use like an if state like should we in the request to call the AI? That we probably need to add a parameter or something like synthetic so that we can add an add a an if operation so like if this is synthetic use the The synthetic table does that make sense?\n\n37:10 - Hasnain sayyed \nYeah. Yeah, I What I am thinking is, while the first flow, the Q1 created the synthetic user, then we have to create an external function which gets the ability for that agent, the synthetic user, to automatically chat with the agent. So we have to create that function. And the graph will be same, of course. The flow and the graph, the functions will be same. We just have to create a functionality that will automate the synthetic user to pass the message or the prompt or whatever, the query. Automatically, once it has received the agent response, then the user will automatically send That\'s the main rule over here. Because this is just a data. Sorry, I just clicked on Zoom. Yeah. So this is just, uh, you know, uh, the character or the character building thing. We can say, Oh, one thing we can do, we can, uh, I can just discard here. I can just come here. Uh, should I download this? Should I download this in CSV and directly, you know, or create a new table like the synthetic and import that thing? It will be much more easier.\n\n38:31 - Jorge Lewis \nYeah. And then, um, and then just modify from there.\n\n38:35 - Hasnain sayyed \nYeah. Yeah. It\'s easy then because manually entering will take much more time.\n\n38:45 - Hasnain sayyed \nYeah. And just let\'s see CSV.\n\n38:52 - Hasnain sayyed \nOkay. I just need to drop you.\n\n38:59 - Hasnain sayyed \nOkay. It has come here.\n\n39:01 - Unidentified Speaker \nSave.\n\n39:13 - Hasnain sayyed \nUh, the primary key will be the ID, right? And yes, save.\n\n39:21 - Jorge Lewis \nCan I see the, the, the prop, the columns like that? You scroll down a little bit.\n\n39:33 - Hasnain sayyed \nYeah. We can create, uh, it\'s adding the column.\n\n39:38 - Jorge Lewis \nThe ID should be you, you ID.\n\n39:44 - Jorge Lewis \nOK.\n\n39:44 - Jorge Lewis \nI think it\'s a little bit too late, but\n\n39:50 - Hasnain sayyed \nIt has added. OK. We can edit here.\n\n40:04 - Hasnain sayyed \nI think it won\'t change now.\n\n40:07 - Jorge Lewis \nYeah, that\'s what I thought.\n\n40:12 - Hasnain sayyed \nCome on, come on, come on.\n\n40:13 - Hasnain sayyed \nYeah. I think it\'s updated. Yes. It\'s updated.\n\n40:20 - Unidentified Speaker \nLuckily.\n\n40:21 - Jorge Lewis \nAll right, cool. Um, okay. So that\'s, that\'s nice. All that done. And now we can, we can, I think we can delete all except maybe two\n######################\nOutput:'}
02:07:16,149 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:16,156 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "practice is before you go to production, you want to turn all those on, but\n\n33:41 - Jorge Lewis \nHmm. Correct.\n\n33:45 - Hasnain sayyed \nSo the, attributes will be, ID is already there, created at.\n\n33:54 - Jorge Lewis \nSo this is going to be the same as, um, actually we kind of did a little bit. We need the name, personality, or anything.\n\n34:05 - Hasnain sayyed \nCan you copy paste over here? It will be fast. Like the name of columns, because it needs to be similar.\n\n34:18 - Jorge Lewis \nThe, um, I'm still trying to sign into the super basic account. Um, does super base have like sign in with, uh, Google?\n\n34:33 - Jorge Lewis \nYeah, yeah, it has.\n\n34:37 - Jorge Lewis \nYeah, that's exactly, but I can't see it.\n\n34:41 - Jorge Lewis \nUm, no, I mean like, it's its own platform.\n\n34:52 - Hasnain sayyed \nOh, so I don't think so.\n\n35:07 - Hasnain sayyed \nOr else I can copy paste over here.\n\n35:10 - Jorge Lewis \nUm, Oh, there we go. I'm in. Nice.\n\n35:41 - Hasnain sayyed \nI'm just writing the column attribute. So I just copy paste.\n\n35:51 - Jorge Lewis \nWhat I want to note on though, what I want to note on is that this synthetic user for example first name and last name hmm they don't need to be separate I think what do you think like or actually\n\n36:09 - Hasnain sayyed \nhuh actually no they do yeah I think it needs to be identical to the profile table yeah yeah um Because the functions, uh, if they're going to be using the first name, it's not using, uh, it's needs to be similar because there will be other, uh, the data is null. Okay.\n\n36:32 - Jorge Lewis \nYeah, exactly. So what I've also noticed though, is that the code right now is using, um, is using the profiles table, right? So if we want to make it use the Profiles table or the synthetic user table without having to rewrite all the code Should we use like an if state like should we in the request to call the AI? That we probably need to add a parameter or something like synthetic so that we can add an add a an if operation so like if this is synthetic use the The synthetic table does that make sense?\n\n37:10 - Hasnain sayyed \nYeah. Yeah, I What I am thinking is, while the first flow, the Q1 created the synthetic user, then we have to create an external function which gets the ability for that agent, the synthetic user, to automatically chat with the agent. So we have to create that function. And the graph will be same, of course. The flow and the graph, the functions will be same. We just have to create a functionality that will automate the synthetic user to pass the message or the prompt or whatever, the query. Automatically, once it has received the agent response, then the user will automatically send That's the main rule over here. Because this is just a data. Sorry, I just clicked on Zoom. Yeah. So this is just, uh, you know, uh, the character or the character building thing. We can say, Oh, one thing we can do, we can, uh, I can just discard here. I can just come here. Uh, should I download this? Should I download this in CSV and directly, you know, or create a new table like the synthetic and import that thing? It will be much more easier.\n\n38:31 - Jorge Lewis \nYeah. And then, um, and then just modify from there.\n\n38:35 - Hasnain sayyed \nYeah. Yeah. It's easy then because manually entering will take much more time.\n\n38:45 - Hasnain sayyed \nYeah. And just let's see CSV.\n\n38:52 - Hasnain sayyed \nOkay. I just need to drop you.\n\n38:59 - Hasnain sayyed \nOkay. It has come here.\n\n39:01 - Unidentified Speaker \nSave.\n\n39:13 - Hasnain sayyed \nUh, the primary key will be the ID, right? And yes, save.\n\n39:21 - Jorge Lewis \nCan I see the, the, the prop, the columns like that? You scroll down a little bit.\n\n39:33 - Hasnain sayyed \nYeah. We can create, uh, it's adding the column.\n\n39:38 - Jorge Lewis \nThe ID should be you, you ID.\n\n39:44 - Jorge Lewis \nOK.\n\n39:44 - Jorge Lewis \nI think it's a little bit too late, but\n\n39:50 - Hasnain sayyed \nIt has added. OK. We can edit here.\n\n40:04 - Hasnain sayyed \nI think it won't change now.\n\n40:07 - Jorge Lewis \nYeah, that's what I thought.\n\n40:12 - Hasnain sayyed \nCome on, come on, come on.\n\n40:13 - Hasnain sayyed \nYeah. I think it's updated. Yes. It's updated.\n\n40:20 - Unidentified Speaker \nLuckily.\n\n40:21 - Jorge Lewis \nAll right, cool. Um, okay. So that's, that's nice. All that done. And now we can, we can, I think we can delete all except maybe two"}
02:07:16,294 httpx INFO HTTP Request: POST https://startino-eastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 401 Unauthorized"
02:07:16,295 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: And the milestones are pretty much a way to motivate the user. So it\'s the mentor, when the user checks in, the user says, hey, the mentor can ask during the daily check-in, Have you done your walk today? And the user says, yes, I walked 10 kilometers. And the milestone should be kind of automatic, saying there\'s just a condition for each milestone. So for example, one milestone can be user walked 1,000 kilometers, for example, over a number of days. So we present to the user saying, hey, you\'ve reached a new milestone. You\'ve walked 1,000 kilometers. That\'s like walking from France to Italy.\n\n11:56 - Jorge Lewis \nYeah, one key aspect of making it very visual, the milestone. So not just, oh, you walked a thousand kilometers, like that doesn\'t mean anything. But instead of telling them they walked from France to Italy, that\'s like, oh, wow.\n\n12:07 - Unidentified Speaker \nSo.\n\n12:11 - Jorge Lewis \nOh, yeah, I hope that gives a good idea on the system, so.\n\n12:17 - Jorge Lewis \nSo what the system needs to accomplish is generate synthetic conversations so that admins can use them to improve the system through the prompts and adding reviews. The reviews is just a few-shot prompting. Are you familiar with them?\n\n12:31 - Jorge Lewis \nYeah.\n\n12:31 - Jorge Lewis \nHave you seen them before?\n\n12:33 - Jorge Lewis \nYeah.\n\n12:35 - Jorge Lewis \nSo it\'s just a few-shot prompting.\n\n12:39 - Jorge Lewis \nSo what we need to do, one complication is that we probably don\'t, well, hmm. Okay, no. So what this is going to entail is we need to create a, what do we call it? A synthetic user.\n\n13:06 - Jorge Lewis \nSo someone needs the ability.\n\n13:11 - Jorge Lewis \nAdmin needs the capability to create new synthetic users.\n\n13:25 - Jorge Lewis \nI got an idea what you are trying to say.\n\n13:26 - Hasnain sayyed \nSo synthetic user is basically a topic based thing, for example, based on different scenarios, the synthetic agent, you know, we can embed the few short and the prompts dynamically to that topic only. And the admin has the capability to create multiple synthetic agents. Is that what you are trying to point?\n\n14:08 - Jorge Lewis \nOkay, so I don\'t think so.\n\n14:10 - Hasnain sayyed \nI mean, you know, the URL for the project Like I just want to know what capabilities the synthetic user will have. Just simple.\n\n14:27 - Jorge Lewis \nOkay. So the synthetic user is all the synthetic users job or the synthetic user is really just the fake user, right? Does that make sense?\n\n14:37 - Jorge Lewis \nOh yeah. Makes sense.\n\n14:39 - Jorge Lewis \nBut so his old, his end goal for the synthetic user is to pretend to be a user and generates a, a synthetic conversation. So synthetic data. Okay. But there\'s some things, so for example, I want to, let me share my screen actually.\n\n15:09 - Jorge Lewis \nCan you see?\n\n15:10 - Jorge Lewis \nYeah, I can see.\n\n15:11 - Jorge Lewis \nDo you know the URL to the app?\n\n15:16 - Hasnain sayyed \nYes.\n\n15:30 - Hasnain sayyed \nSo let\'s send you.\n\n15:32 - Hasnain sayyed \nOh, yes, please.\n\n15:34 - Hasnain sayyed \nSend in the chat.\n\n15:43 - Jorge Lewis \nOkay. So, so here, wow, that\'s a lot of users. Um, so here is, is this is like kind of a, just a temporary kind of page for selecting a user where after we use user authentication, will be gone. But what I was thinking is, since these are all users, or actually, no this should probably be in the admin panel. So you see how I have to select profile when I want to modify the prompts.\n\n16:22 - Jorge Lewis \nSo what I\'m thinking we do is somewhere on the sidebar, we can have a page called simulation. And in that simulation, we have a button. We can configure the synthetic user. So a synthetic user can have the properties of this. So we can tell it its main objective to test, and then What else? We can just give it some background, like personality. Or give it a user profile. Or goal, maybe.\n\n17:20 - Jorge Lewis \nYeah, so this is the goal, the main objective. So this can also be, This can be generic.\n\n17:36 - Jorge Lewis \nSo just no goal.\n\n17:41 - Jorge Lewis \nA synthetic user needs the prompt, it needs to understand, or we need to tell it who it is. So it\'s a user, or you are chatting with a life coach bot, you know, and tell it the thing. So we need to give it, tell it who it is and what.\n\n18:13 - Jorge Lewis \nYou are the person So, uh, hardships might be.\n\n18:32 - Jorge Lewis \nOh, so what we also need to do, which is quite important, is simulating multiple days because the chapel actually uses time.\n\n18:47 - Jorge Lewis \nWe need to make sure that... Because if they just keep chatting, there won\'t be, for example, a new check-in, right? Because check-ins are made on a day.\n\n18:58 - Jorge Lewis \nWe need a way to...\n\n19:07 - Hasnain\n######################\nOutput:'}
02:07:16,296 root ERROR error extracting graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\graph\extractors\graph\graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 49, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\base\base_llm.py", line 53, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\llm\openai\openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\resources\chat\completions.py", line 1339, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1816, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1510, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\openai\_base_client.py", line 1611, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}
02:07:16,299 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "And the milestones are pretty much a way to motivate the user. So it's the mentor, when the user checks in, the user says, hey, the mentor can ask during the daily check-in, Have you done your walk today? And the user says, yes, I walked 10 kilometers. And the milestone should be kind of automatic, saying there's just a condition for each milestone. So for example, one milestone can be user walked 1,000 kilometers, for example, over a number of days. So we present to the user saying, hey, you've reached a new milestone. You've walked 1,000 kilometers. That's like walking from France to Italy.\n\n11:56 - Jorge Lewis \nYeah, one key aspect of making it very visual, the milestone. So not just, oh, you walked a thousand kilometers, like that doesn't mean anything. But instead of telling them they walked from France to Italy, that's like, oh, wow.\n\n12:07 - Unidentified Speaker \nSo.\n\n12:11 - Jorge Lewis \nOh, yeah, I hope that gives a good idea on the system, so.\n\n12:17 - Jorge Lewis \nSo what the system needs to accomplish is generate synthetic conversations so that admins can use them to improve the system through the prompts and adding reviews. The reviews is just a few-shot prompting. Are you familiar with them?\n\n12:31 - Jorge Lewis \nYeah.\n\n12:31 - Jorge Lewis \nHave you seen them before?\n\n12:33 - Jorge Lewis \nYeah.\n\n12:35 - Jorge Lewis \nSo it's just a few-shot prompting.\n\n12:39 - Jorge Lewis \nSo what we need to do, one complication is that we probably don't, well, hmm. Okay, no. So what this is going to entail is we need to create a, what do we call it? A synthetic user.\n\n13:06 - Jorge Lewis \nSo someone needs the ability.\n\n13:11 - Jorge Lewis \nAdmin needs the capability to create new synthetic users.\n\n13:25 - Jorge Lewis \nI got an idea what you are trying to say.\n\n13:26 - Hasnain sayyed \nSo synthetic user is basically a topic based thing, for example, based on different scenarios, the synthetic agent, you know, we can embed the few short and the prompts dynamically to that topic only. And the admin has the capability to create multiple synthetic agents. Is that what you are trying to point?\n\n14:08 - Jorge Lewis \nOkay, so I don't think so.\n\n14:10 - Hasnain sayyed \nI mean, you know, the URL for the project Like I just want to know what capabilities the synthetic user will have. Just simple.\n\n14:27 - Jorge Lewis \nOkay. So the synthetic user is all the synthetic users job or the synthetic user is really just the fake user, right? Does that make sense?\n\n14:37 - Jorge Lewis \nOh yeah. Makes sense.\n\n14:39 - Jorge Lewis \nBut so his old, his end goal for the synthetic user is to pretend to be a user and generates a, a synthetic conversation. So synthetic data. Okay. But there's some things, so for example, I want to, let me share my screen actually.\n\n15:09 - Jorge Lewis \nCan you see?\n\n15:10 - Jorge Lewis \nYeah, I can see.\n\n15:11 - Jorge Lewis \nDo you know the URL to the app?\n\n15:16 - Hasnain sayyed \nYes.\n\n15:30 - Hasnain sayyed \nSo let's send you.\n\n15:32 - Hasnain sayyed \nOh, yes, please.\n\n15:34 - Hasnain sayyed \nSend in the chat.\n\n15:43 - Jorge Lewis \nOkay. So, so here, wow, that's a lot of users. Um, so here is, is this is like kind of a, just a temporary kind of page for selecting a user where after we use user authentication, will be gone. But what I was thinking is, since these are all users, or actually, no this should probably be in the admin panel. So you see how I have to select profile when I want to modify the prompts.\n\n16:22 - Jorge Lewis \nSo what I'm thinking we do is somewhere on the sidebar, we can have a page called simulation. And in that simulation, we have a button. We can configure the synthetic user. So a synthetic user can have the properties of this. So we can tell it its main objective to test, and then What else? We can just give it some background, like personality. Or give it a user profile. Or goal, maybe.\n\n17:20 - Jorge Lewis \nYeah, so this is the goal, the main objective. So this can also be, This can be generic.\n\n17:36 - Jorge Lewis \nSo just no goal.\n\n17:41 - Jorge Lewis \nA synthetic user needs the prompt, it needs to understand, or we need to tell it who it is. So it's a user, or you are chatting with a life coach bot, you know, and tell it the thing. So we need to give it, tell it who it is and what.\n\n18:13 - Jorge Lewis \nYou are the person So, uh, hardships might be.\n\n18:32 - Jorge Lewis \nOh, so what we also need to do, which is quite important, is simulating multiple days because the chapel actually uses time.\n\n18:47 - Jorge Lewis \nWe need to make sure that... Because if they just keep chatting, there won't be, for example, a new check-in, right? Because check-ins are made on a day.\n\n18:58 - Jorge Lewis \nWe need a way to...\n\n19:07 - Hasnain"}
02:07:16,313 datashaper.workflow.workflow INFO executing verb merge_graphs
02:07:16,326 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
02:07:16,670 graphrag.index.run INFO Running workflow: create_summarized_entities...
02:07:16,670 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
02:07:16,671 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
02:07:16,697 datashaper.workflow.workflow INFO executing verb summarize_descriptions
02:07:16,709 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
02:07:17,86 graphrag.index.run INFO Running workflow: create_base_entity_graph...
02:07:17,86 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
02:07:17,87 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
02:07:17,115 datashaper.workflow.workflow INFO executing verb cluster_graph
02:07:17,115 graphrag.index.verbs.graph.clustering.cluster_graph WARNING Graph has no nodes
02:07:17,121 datashaper.workflow.workflow ERROR Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\datashaper\workflow\workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\verbs\graph\clustering\cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
    ~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\indexers\utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
02:07:17,128 graphrag.index.reporting.file_workflow_callbacks INFO Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key details=None
02:07:17,128 graphrag.index.run ERROR error running workflow create_base_entity_graph
Traceback (most recent call last):
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\run.py", line 325, in run_pipeline
    result = await workflow.run(context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\datashaper\workflow\workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\datashaper\workflow\workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\graphrag\index\verbs\graph\clustering\cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
    ~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "C:\Users\antop\Documents\Development\congent\.venv\Lib\site-packages\pandas\core\indexers\utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
02:07:17,132 graphrag.index.reporting.file_workflow_callbacks INFO Error running pipeline! details=None
02:07:17,175 graphrag.index.cli ERROR Errors occurred during the pipeline run, see logs for more details.
