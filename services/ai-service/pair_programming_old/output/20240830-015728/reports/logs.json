{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n", "source": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Entity Extraction Error", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 122, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 161, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n", "source": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "details": {"doc_index": 0, "text": ". Then I switched to Python. And made 2-3 projects.\n\n55:25 - Biwas bhandari \nAnd that guy messaged.\n\n55:27 - Biwas bhandari \nDid you do any internship work? Not internship, I did both remote work. They were from Nepal, but they stayed in San Francisco. America.\n\n55:41 - Biwas bhandari \nThey gave me the job.\n\n55:43 - Biwas bhandari \nSo, I did it.\n\n55:45 - Biwas bhandari \nLang Graph.\n\n55:46 - Biwas bhandari \nI haven't used it much. I've only used it in LangChain. Agent. Banana. Router. That's it. First time using Lang Graph.\n\n55:56 - Unidentified Speaker \nBut it's good. Yeah.\n\n56:00 - Chinmay Pandya \nWe'll figure it out.\n\n56:01 - Chinmay Pandya \nThere's no new code.\n\n56:03 - Chinmay Pandya \nIt's just LangChain. But the graph and nodes are different.\n\n56:10 - Chinmay Pandya \nok bro, let's meet tomorrow ok, today I am working on the collector now my quota is over so I will start again tomorrow morning if there is any quota, I will do it ok, I will try to figure out the collectors do you have the documentation link?\n\n56:38 - Biwas bhandari \nLangchan's Superverse I haven't used. I was only using MongoDB and MySQL. I'll send you a link.\n\n56:50 - Chinmay Pandya \nI'll send you the documentation link in the Discord chat.\n\n56:56 - Chinmay Pandya \nOkay. Let me know if you have any extra resources.\n\n57:00 - Biwas bhandari \nYeah.\n\n57:13 - Chinmay Pandya \nWhere did it go?\n\n57:23 - Biwas bhandari \nI sent it.\n\n57:24 - Chinmay Pandya \nThis was just a multi-agent. I was also looking at this.\n\n57:29 - Biwas bhandari \nBut it has a router.\n\n57:30 - Chinmay Pandya \nIt doesn't need a router. It has a supervisor in the code too.\n\n57:43 - Biwas bhandari \nusing supervisor, he was also using multi-agent collaboration using supervisor, he was using multi-agent collaboration actually in multi-agent, router is better we'll have to see I'll do it tonight, if there's any error I'll inform you, you can check it in\n\n58:05 - Chinmay Pandya \nthe morning If you figure out something or work on it, let me know. I'm sleeping, when I wake up, you go offline, I'll see.\n\n58:27 - Biwas bhandari \nOkay, bye bye, have a good night."}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n", "source": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\n\n#######\n-Data-\nEntities: [\"JORGE LEWIS\", \"CUAN MULLIGAN\"]\nDescription List: [\"Cuan Mulligan and Jorge Lewis are collaborating on the development of the multi-agent system\", \"Cuan Mulligan and Jorge Lewis are discussing the best ways to handle prompt modifications and deployment\", \"Jorge Lewis and Cuan Mulligan are both participants in the conversation discussing the architecture and functionality of agents\", \"Jorge Lewis and Cuan Mulligan are collaborating on technical tasks and feedback\", \"Jorge Lewis and Cuan Mulligan are collaborating on the project, discussing technical issues and solutions\", \"Jorge Lewis and Cuan Mulligan are discussing project management and communication\", \"Jorge Lewis and Cuan Mulligan are discussing the admin page and the importance of follow-on responsesJorge Lewis and Cuan Mulligan discuss the structure and steps of workshops\", \"Jorge Lewis and Cuan Mulligan discuss the current state of their AI projectJorge Lewis and Cuan Mulligan are participants in a conversation about AI and productivity\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error executing verb \"summarize_descriptions\" in create_summarized_entities: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n              ^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n", "source": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\run.py\", line 325, in run_pipeline\n    result = await workflow.run(context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n              ^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1816, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1510, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\antop\\Documents\\Development\\congent\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1611, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n", "source": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}", "details": null}
